\documentclass[12pt, ]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript

%put a newpage before sections http://blog.dreasgrech.com/2010/01/starting-new-page-with-every-section-in.html
\let\stdsection\section
\renewcommand\section{\newpage\stdsection}

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

\usepackage[margin=3cm]{geometry}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable}
\usepackage{graphicx}
% We will generate all images so they have a width \maxwidth. This means
% that they will get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=\maxwidth]{#1}}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Jim Higson, Kellogg College},
            pdftitle={Oboe.js: An approach to I/O for REST clients which is neither batch nor stream; nor SAX nor DOM},
            colorlinks=true,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}


\title{Oboe.js: An approach to I/O for REST clients which is neither batch nor
stream; nor SAX nor DOM}
\author{Jim Higson, Kellogg College}
\date{November 2013}

\begin{document}

\raggedbottom
\widowpenalties 1 7500
\addtolength{\topskip}{0pt plus 10pt}

\maketitle

\begin{center}
{\large Supervised by Jeremy Gibbons}
\end{center}

\begin{abstract}
A new design is presented for HTTP client libraries which incorporates
HTTP streaming, pattern matching, and incremental parsing, with the aim
of improving performance, fault tolerance, and encouraging a greater
degree of loose coupling between programs. A Javascript client library
capable of progressively parsing JSON resources is presented targeting
both Node.js and web browsers. Loose coupling is particularly considered
in light of the application of Agile methodologies to REST and SOA,
providing a framework in which it is acceptable to partially restructure
the JSON format of a resource while maintaining compatibility with
dependent systems.

A critique is made of current practice under which resources are
entirely retrieved before items of interest are extracted
programmatically. An alternative model is presented allowing the
specification of items of interest using a declarative syntax similar to
JSONPath. The identified items are then provided incrementally while the
resource is still downloading.

In addition to a consideration of performance in absolute terms, the
usability implications of an incremental model are also considered with
regards to developer ergonomics and user perception of performance.
\end{abstract}


{
\clearpage
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{3}
\tableofcontents
}

\clearpage
\listoffigures

\clearpage

\section{Introduction}\label{introduction}

HTTP was originally designed for the transfer of hypertext documents.
REST (Fielding 2000) introduces no fundamentally new methods but extends
the scope of HTTP to include the transfer of arbitrary data. Whereas the
rival technology SOAP (Gudgin et al. 2007) largely disregards HTTP's
principled design by adopting the protocol as a transport on which to
bootstrap its own semantics, REST adopts all of HTTP's core phrasing.
This includes the HTTP methods for fetching, creating and modifying
resources: GET, POST, PUT, PATCH, DELETE, and the locating of resources
using URLs. Under HTTP's original design hierarchical URLs are used to
locate documents without reference to the services which produce them.
REST advances this same naming strategy by likewise using URLs to locate
data resources, not services. As with HTTP, REST is stateless and
therefore cacheable, allowing large-scale content distribution networks
to be built. Because HTTP's inbuilt headers for content type, language
negotiation, and resource expiry are used according to the originally
intended meanings (Fielding et al. 1999), existing intermediaries such
as load balancing proxies, gateways, and caches need make no special
accommodation for REST resources.

Despite REST adopting the mechanisms and semantics of HTTP, whereas
documents received over the web are often interpreted in a streaming
fashion, to date REST resources are not commonly examined in this way.
For most practical cases where we wish to be increase the speed of a
system there is no reasonable distinction between acting \emph{earlier}
and being \emph{quicker}. In the interest of creating efficient software
we should use data at the first possible opportunity: examining content
\emph{while it streams} rather than holding it unexamined until it is
wholly available. The purpose of this dissertation is to explore
tangible benefits which may be realised if we fold HTTP streaming into
the REST paradigm.

Natural languages encourage our thinking to follow patterns that they
easily support (Whorf 1956). This idea has been applied to programming,
for example Ruby is intentionally designed to discourage global
variables by using a less attractive notation (Yukihiro 2003). It may be
useful when exploring new techniques to question which established
constructs are as they are because of languages which unintentionally
suggest that formulation; it is perhaps significant that REST clients
tend to style the calling of remote resources similarly to the call
style of the host programming language. In practice one of two schemas
is generally followed: a synchronous, blocking style in which an
invocation halts execution for the duration of the request before
evaluating to the fetched resource; or an asynchronous, non-blocking
form in which some logic is specified to be applied to the response once
it is available. Languages which promote concurrency though threading
generally consider blocking in a single thread to be acceptable and will
prefer the synchronous mode whereas languages with first class functions
are naturally conversant in callbacks and will prefer asynchronous I/O.
In programming the language limits the patterns that we readily see and
the schemes which map most easily onto our languages are not necessarily
the best possible organisation. For any multi-packet message sent via a
network some parts will arrive before others, at least approximately
in-order, but viewed from inside a language whose phasing encourages
statements to yield single, wholly evaluated results it is comfortable
to conceptualise the REST response as a discrete event. This
establishment of a `limiting comfort' extends to graphical notations
such as UML whose constructs strongly reflect the textual languages of
the day. UML sequence diagrams include the syntax for instantaneously
delivered return values but, despite being commonly used to draw network
data transfer, provide no corresponding notation for a resource whose
data is progressively revealed.

No new computing techniques need be invented before this dissertation
can be implemented. As a minimum it requires an HTTP client which
reveals the response whilst it is in progress and a parser which can
begin to interpret that response before it sees all of it. Nor is it
novel to use these parts together to produce a streaming interpretation.
Every current web browser already implements a similar pattern. Load any
complex webpage -- essentially an aggregation of hypertext and other
resources -- and the HTML will be parsed and displayed incrementally
while it is downloading, with resources such as images requested in
parallel as soon as they are referenced. In the case of progressive JPEG
or SVG\footnote{for quite an obviously visible example of progressive
  SVG loading, try loading this SVG using a recent version of Google
  Chrome:
  \url{http://upload.wikimedia.org/wikipedia/commons/0/04/Marriage_(Same-Sex_Couples)_Bill,_Second_Reading.svg}
  For the perfectionist SVG artist, not just the final image should be
  considered but also the XML source order, for example in this case it
  would be helpful if the outline of the UK appeared first and the
  exploded sections last.} the images themselves will also be presented
incrementally. This incremental display is achieved through software
created for a single purpose, to display web pages. The contribution of
this dissertation is to provide a generic analogue, applicable to any
problem domain.

\subsection{REST aggregation could be
faster}\label{rest-aggregation-could-be-faster}

\begin{figure}[htbp]
\centering
\includegraphics{images/rest_timeline_1.png}
\caption{\textbf{Sequence diagram showing the aggregation of low-level
REST resources by an intermediary.} A client fetches an author's
publication list and then their first three articles. This sequence
represents the most commonly used technique in which the client does not
react util the response is complete. \label{rest_timeline_1}}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{images/rest_timeline_2.png}
\caption{\textbf{Revised aggregation sequence showing a client which
progressively interprets the resources.} Because the arrows in a UML
sequence diagrams draw returned values as a one-off happening rather
than a continuous process, the lighter arrow notation is added to
represent fragments of an incremental response. Each request for an
individual publication is made as soon as its URL can be extracted from
the publications list and once all required links have been read from
the original response it is aborted rather than continuing to download
unnecessary data. \label{rest_timeline_2}}
\end{figure}

Figures \ref{rest_timeline_1} and \ref{rest_timeline_2} comparatively
illustrate how a progressive client may, without adjustments to the
server, be used to produce an aggregated resource sooner. This results
in a moderate improvement in the time taken to show the complete
aggregation but a dramatic improvement in the time to show the first
content. The ability to present the first content as early as possible
is a desirable trait for system usability because it allows the user to
start reading earlier and a progressively rendered display in itself
increases the human perception of speed (Geelhoed et al. 1995). Note
also how the cadence of requests is more steady in Figure
\ref{rest_timeline_2} with four connections opened at roughly equal
intervals rather than a single request followed by a rapid burst of
three. Both clients and servers routinely limit the number of
simultaneous connections per peer so avoiding bursts is further to our
advantage. \hyperref[appendixux5fhttpux5flimits]{Appendix i} lists some
actual limits.

Nodes in an n-tier architecture defy categorisation as `client' or
`server' in a way that is appropriate from all frames of reference. A
node might be labeled as the `server' from the layer below and `client'
from the layer above. Although the ``client software'' labels in the
figures \ref{rest_timeline_1} and \ref{rest_timeline_2} hint at
something running directly on a user's own device, the same benefits
apply if this layer is running remotely. If this layer were generating a
web page on the server-side to be displayed by the client's browser, the
same perceptual speed improvements apply because of HTTP chunked
encoding (Stefanov 2009). If this layer were a remote aggregation
service, starting to write out the aggregated response early provides
much the same benefits to the client able to interpret it progressively
and, even if it is not, the overall delivery remains faster.

\subsection{Stepping outside the big-small
tradeoff}\label{stepping-outside-the-big-small-tradeoff}

Where a domain model contains a series of data from which continuous
ranges are requestable via REST there is often a tradeoff in the client
design with regards to how much should be requested with each call.
Because at any time it shows only a small window into a much larger
model, the social networking site Twitter might be a good example. The
Twitter interface designers adopted a popular interface pattern,
Infinite Scrolling (Ahuvia 2013). Starting from an initial page showing
some finite number of tweets, once the user scrolls and reaches the end
of the list the next batch is automatically requested. When loaded, this
new batch is converted to HTML and added to the bottom of the page.
Applied repeatedly the illusion of an infinitely long page is
maintained, albeit punctuated with pauses whenever new content is
loaded. For the programmers working on this presentation layer there is
a tradeoff between sporadically requesting many tweets, yielding long,
infrequent delays and frequently requesting a few, giving an interface
which stutters momentarily but often.

Progressive loading could render this tradeoff unnecessary by
simultaneously delivering the best of both strategies. In the Twitter
example this could be achieved by making large requests but instead of
deferring all rendering until the request completes, add the individual
tweets to the page as they are incrementally parsed out of the ongoing
response. With a streaming transport, the time taken to receive the
first tweet should not vary depending on the total number that are also
being sent so there is no relationship between the size of the request
and the interval before the interface starts updating.

\subsection{Staying fast on a fallible
network}\label{staying-fast-on-a-fallible-network}

REST operates over networks whose reliability varies widely. On
unreliable networks connections are abruptly dropped and existing HTTP
clients handle unexpected terminations wastefully. Consider the everyday
situation of a person using a smartphone browser to check their email.
Mobile data coverage is often weak outside of major cities (Gill 2013)
so while travelling the signal will be lost and reestablished many
times. The web developer's standard toolkit is structured in a way that
encourages early terminated connections to be considered as wholly
unsuccessful rather than as partially successful. For example, the
popular AJAX library jQuery automatically parses JSON or XML responses
before passing back to the application but given an early disconnection
there is no attempt to hand over the partial response. To the programmer
who knows where to look the partial responses can be extracted as raw
text but handling them involves writing a special case and is not
possible using standard parsers which are not amenable to incomplete
markup. Because of this difficulty the canonical webapp drops partial
messages without inspection. For the user checking her email, even if
90\% of her inbox had been retrieved before the signal was lost, the web
application will behave as if it received none and show her nothing.
Later, when the network is available the inbox will be downloaded from
scratch including the 90\% which has already been successfully
delivered. A more efficient system would allow the 90\% from the aborted
first request to be used straight away and when the signal later returns
fetch only the lost 10\%.

The delivered part of a partially successful message may be used if we
turn away from this polarised view of wholly successful/unsuccessful
requests and conceptualise the message as having many parts which are
useful in themselves, in which the successful delivery of each part is
handled independently without knowing if the next will part will also
arrive. As well as allowing partially successful messages to be used,
seeing the resource as a stream of small parts allows those parts to be
used earlier if they are made available to the application while the
streaming is ongoing. Should an early disconnection occur, the content
delivered up to that point will have already been handled so no special
case is required to salvage it. In most cases the only recovery
necessary will be to make a new request for just the part that was
missed. This approach is not incompatible with a problem domain where
the usefulness of an earlier part is dependent on the correct delivery
of the whole providing optimistic locking is used. In this case earlier
parts may be used immediately but their effect rolled back should the
transfer later fail.

\subsection{Agile methodologies, frequent deployments, and compatibility
today with versions
tomorrow}\label{agile-methodologies-frequent-deployments-and-compatibility-today-with-versions-tomorrow}

In most respects a SOA architecture fits well with the fast release
cycle encouraged by Agile methodologies. Because in SOA we may consider
that all data is local and that the components are loosely coupled and
autonomous, frequent releases of any particular sub-system shouldn't
pose a problem to the correct operation of the whole. In allowing a
design to emerge organically it should be possible for the structure of
resource formats to be realised slowly and iteratively while a greater
understanding of the problem is gained. Unfortunately in practice the
ability to change often is hampered by tools which encourage programming
against rigidly specified formats. If a data consumer is tightly coupled
to the format it consumes it will resist changes to the programs which
produce data in that format. As an anecdote, working in enterprise I
have seen the release of dozens of components cancelled because of a
single unit that failed to meet acceptance criteria. By insisting on
exact data formats, subsystems become tightly coupled and the perfect
environment is created for contagion whereby the updating of any single
unit may only be done as part of the updating of the whole. An effective
response to this problem would be REST clients which are able to use a
resource whilst being only loosely coupled to the overall shape of the
message.

\subsection{Deliverables}\label{deliverables}

To avoid feature creep the scope of the software deliverables is pared
down to the smallest work which can be said to realise the goals of the
project, the guiding principle being that it is preferable to produce a
little well than more badly. Amongst commentators on start-up companies
this is known as a \emph{zoom-in pivot} (Reis 2011 p172) and the work it
produces should be the \emph{Minimum Viable Product} or MVP (Reis 2011
p106-110). It would not be feasible to deliver a full stack so we are
obliged to focus on solutions which interoperate with existing
deployments. To a third party wishing to adopt the technology it is also
more inviting to add small enhancements to the existing architecture
than to action a shift which requires wholesale change.

Although an explicitly streaming server would improve the situation
further, because all network data transfer may be thought of as a
stream, it is not required to start taking advantage of progressive
REST. In the interest of creating something new, whilst HTTP servers
capable of streaming are quite common even if they are not always
programmed as such, there seems to be no published general-purpose,
streaming-receptive REST client library. A streaming client is the MVP
and is the code deliverable of this project.

\subsection{Criteria for success}\label{criteria-for-success}

In evaluating this project we may say it has been a success if
non-trivial improvements in speed can be made without a corresponding
increase in the difficulty of programming the client. This improvement
may be in terms of the absolute total time required to complete a
representative task or in a user's perception of application
responsiveness. Because applications in the target domain are much more
I/O-bound than CPU-bound, optimisation in terms of the execution time of
algorithms will be de-emphasised unless especially egregious.
Additionally, there will be a consideration of how message semantics are
incrementally realised as part of an emergent design. This will include
commentary on if disruption given unanticipated format changes may be
avoided by libraries which encourage data consumers to be loosely
coupled to the formats that they consume.

\section{Background}\label{background}

\begin{figure}[htbp]
\centering
\includegraphics{images/architecture.png}
\caption{\textbf{Labelling nodes in an n-tier architecture}. By Although
network topology is often split about client and server side, for our
purposes categorisation as data, middle, and presentation tier is the
more meaningful distinction. According to this split the client- and
server-side presentation layer serve the same purpose, generating
mark-up based on aggregated data prepared by the middle tier.
\label{architecture}}
\end{figure}

\subsection{The web as an application
platform}\label{the-web-as-an-application-platform}

Application design has historically charted an undulating path pulled by
competing approaches of thick and thin clients. Having evolved from a
document viewing system to the preferred application platform for all
but the most specialised interfaces, the web perpetuates this narrative
by resisting categorisation as either mode.

While the trend is generally towards more client scripting and for many
sites a Javascript runtime is now requisite, there are also
counter-trends. In 2012 Twitter reduced load times to one fifth of their
previous design by moving much of their rendering back to the
server-side, commenting that ``The future is coming and it looks just
like the past'' (Lea 2012). Under this architecture short, fast-loading
pages are generated on the server-side but Javascript also provides
progressive enhancements. Although it does not generate pages anew, the
Javascript must know how to create most of the interface elements so one
weakness of this architecture is that much of the presentation layer
logic must be expressed twice.

Despite client devices taking on responsibilities which would previously
have been performed on a server, there is a limit to how much of the
stack may safely be offloaded in this direction. The client-side
ultimately falls under the control of the user so no important business
decisions should be taken here. A banking site should not allow loan
approval to take place in the browser because for the knowledgeable user
any decision would be possible. Separated from data stores by the public
internet, the client is also a poor place to perform data aggregation or
examine large data sets. In non-trivial applications these restrictions
encourage a middle tier to execute business logic and produce aggregate
data.

While REST may not be the only communications technology employed by an
application architecture, for this project we should examine where REST
client libraries may fit into the picture. REST is used by the
presentation layer to pull data from the middle tier regardless of where
the presentation resides. Likewise, rather than connect to databases
directly, for portability the middle tier will often communicate with a
thin REST layer which wraps the data store. This suggests three uses:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  From web browser to middle tier
\item
  From server-side presentation layer to middle tier
\item
  From middle tier to nodes in the data tier
\end{itemize}

Fortunately, each of these contexts requires a similar performance
profile. The work done is computationally light and answering a request
involves more time waiting than processing. As a part of an interactive
system low latency is important whereas throughput can be increased
relatively cheaply by adding more hardware, especially in a cloud hosted
environment. As demand for the system increases the total work required
grows but the complexity in responding to any one of the requests
remains constant. Although serving any particular request might be done
in series, the workload as a whole is embarrassingly parallelisable.

\subsection{Node.js}\label{node.js}

Node.js (Ryan 2009) is a general purpose tool for executing Javascript
outside of a browser. It has the aim of low-latency I/O and is used
mostly for server applications and command line tools. It is difficult
to judge to what degree Javascript is a distraction from Node's design
as a tool for I/O and to what degree the language defines the platform.

For most imperative languages the thread is the basic unit of
concurrency, whereas Node presents the programmer with a single-threaded
abstraction. Threads are an effective means to share parallel
computation over multiple cores but are less well suited to scheduling
concurrent tasks which are mostly I/O dependent. Safely programming
threads to share mutable objects requires great care and experience,
otherwise the programmer is liable to create race conditions. Consider
for example a Java HTTP aggregator; because we wish to fetch in parallel
each request is assigned to a thread. These `requester' tasks are
computationally simple: make a request, wait for a complete response,
and then participate in a Barrier while the other requesters complete.
Each thread consumes considerable resources but during its multi-second
lifespan requires only a fraction of a millisecond on the CPU. It is
unlikely that any two requests will return closely enough in time to be
processed in parallel, shedding threading's chief advantage, that it may
process simultaneously utilising multiple cores. Even if requests do
return proximately, the actual CPU time required in making an HTTP
request is so short that any concurrent processing is a pyrrhic victory.

Node builds on a model of event-based, asynchronous I/O which was
established by browser Javascript execution. Although Javascript in a
browser may be performing multiple tasks simultaneously, for example
requesting several resources from the server side, it does so from
within a single-threaded virtual machine. Node facilitates concurrency
by managing an event loop of queued tasks and providing exclusively
non-blocking I/O. Unlike Erlang, Node does not swap tasks out
preemptively, it always waits for a task to complete before moving onto
the next. This means that each task must complete quickly to avoid
holding up others. \emph{Prima facie} this might seem like an onerous
requirement to put on the programmer but in practice with only
non-blocking I/O available each task naturally exits quickly without any
special effort. Accidental non-terminating loops or heavy
number-crunching aside, with no reason for a task to wait it is
difficult to write a node program in which the tasks do not complete
quickly. In production environments Node deployments usually take
advantage of multiple cores by creating one Node instance per processor
code. The separate instances act independently and do not normally use
shared RAM.

Each task in Node is simply a Javascript function. Node is able to swap
its single Javascript thread between these tasks efficiently while
providing the programmer with an intuitive interface because of
closures. Utilising closures, the responsibility of maintaining state
between issuing an asynchronous call and receiving the callback is
removed from the programmer by folding the storage invisibly into the
language. This implicit data store requires no syntax and feels so
natural and inevitable that it is often not obvious that the
responsibility exists at all.

Consider the example below. The code schedules three tasks, each of
which are very short and exit quickly allowing Node to finely interlace
them between other concurrent concerns. The \texttt{on} method is used
to attach functions as listeners to streams. However sophisticated and
performant this style of programming, to the developer it is hardly any
more difficult an expression than if blocking I/O were used. It is
certainly harder to make mistakes programming in this way than managing
synchronised access to mutable objects that are shared between threads.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{printResourceToConsole}\NormalTok{(url) \{}

   \OtherTok{http}\NormalTok{.}\FunctionTok{get}\NormalTok{(url)}
      \NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'response'}\NormalTok{, }\KeywordTok{function}\NormalTok{(response)\{}
      
         \CommentTok{// This function will be called when the response starts.}
         \CommentTok{// It logs to the console, adds a listener and quickly }
         \CommentTok{// exits.}
         
         \CommentTok{// Because it is captured by a closure we are able to }
         \CommentTok{// reference the URL parameter after the scope that }
         \CommentTok{// declared it has finished.            }
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"The response has started for"}\NormalTok{, url);}
      
         \OtherTok{response}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'data'}\NormalTok{, }\KeywordTok{function}\NormalTok{(chunk) \{      }
            \CommentTok{// This function is called each time some data is}
            \CommentTok{// received from the HTTP request. The task writes}
            \CommentTok{// the response to the console and quickly exits.}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'Got some response'}\NormalTok{, chunk);}
                   
         \NormalTok{\}).}\FunctionTok{on}\NormalTok{(}\StringTok{'end'}\NormalTok{, }\KeywordTok{function}\NormalTok{()\{}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'The response is complete'}\NormalTok{);}
         \NormalTok{\})}
         
      \NormalTok{\}).}\FunctionTok{on}\NormalTok{(}\StringTok{"error"}\NormalTok{, }\KeywordTok{function}\NormalTok{(e)\{}
         
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"There was an error"}\NormalTok{, }\OtherTok{e}\NormalTok{.}\FunctionTok{message}\NormalTok{);}
      \NormalTok{\});      }
   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"The request has been made"}\NormalTok{);}
\NormalTok{\}   }
\end{Highlighting}
\end{Shaded}

\begin{quote}
``Node Stream API, which is the core I/O abstraction in Node.js (which
is a tool for I/O) is essentially an abstract in/out interface that can
handle any protocol/stream that also happens to be written in
JavaScript.'' (Ogden 2012)
\end{quote}

In Node I/O is performed using a unified data streaming interface
regardless of the source. The streams fit comfortably with the wider
event-driven model by implementing Node's EventEmitter interface, a
generic dispatcher capable of supporting any event type. Although the
abstraction provided by streams is quite a thin layer on top of the host
system's sockets, it forms a powerful and intuitive interface. For many
tasks it is preferable to program in a `plumbing' style by joining one
stream's output to another's input. In the example below a resource from
the internet is written to the local filesystem.

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{http}\NormalTok{.}\FunctionTok{get}\NormalTok{(url)}
   \NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'response'}\NormalTok{, }\KeywordTok{function}\NormalTok{(response)\{}
      \OtherTok{response}\NormalTok{.}\FunctionTok{pipe}\NormalTok{(}\OtherTok{fs}\NormalTok{.}\FunctionTok{createWriteStream}\NormalTok{(pathToFile));}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Following Node's lead, traditionally thread-based environments are
beginning to embrace asynchronous, single-threaded servers. The Netty
project (Netty 2010) can be thought of as roughly an equivalent of Node
for the Java Virtual Machine.

\subsection{JSON and XML data transfer formats}\label{jsonxml}

Both XML and JSON are text based, tree-shaped data formats with human
and machine readability. One of the design goals of XML was to simplify
SGML to the point that a graduate student could implement a full parser
in a week (Eberhart and Fischer 2002 p287). Continuing this arc of
simpler data formats, JSON ``The fat-free alternative to XML'' (Douglas
2009) isolates Javascript's syntax for literal values into a stand-alone
serialisation language. For the graduate tackling JSON parsing the task
is simpler still, being expressible as fifteen context free grammars.

Whereas XML's markup can be traced to document formats, JSON's lineage
is in a programming language. From these roots it isn't surprising that
JSON maps more directly to the metamodel that most programmers think in.
XML parsers produce Elements, Text, Attributes, ProcessingInstruction
which require extra translation before they are convenient to use inside
a programming language. Because JSON already closely resembles how a
programmer would construct a runtime model of their data, fewer steps
are required before using the deserialised form. The JSON nodes:
\emph{strings}, \emph{numbers}, \emph{objects} and \emph{arrays} will in
many cases map directly onto language types and, for loosely typed
languages at least, the parser output bears enough similarity to domain
model objects that it may be used directly without any further
transformation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \DataTypeTok{people}\NormalTok{: [}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'John'}\NormalTok{, }\DataTypeTok{townOrCity}\NormalTok{:}\StringTok{'London'}\NormalTok{\},}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'Jack'}\NormalTok{, }\DataTypeTok{townOrCity}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{\}}
      \NormalTok{\{}\DataTypeTok{townOrCity}\NormalTok{:}\StringTok{'Cambridge'}\NormalTok{, }\DataTypeTok{name}\NormalTok{: }\StringTok{'Sally'}\NormalTok{\}}
   \NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Both JSON and XML are used to serialise orderless constructs but while
expressed as text the encoding is inevitably written according to some
serialisation order. XML specifically states that the order of
attributes is not significant (Bray et al. 2008), JSON has no such
detailed specification but a similar order insignificance seems to be
implied by the JSON object's likeness to Javascript objects whose
iteration order is indeterminate (ECMA 1999, 4.3.3). In the example
above the people objects would probably have been written based on
either a class with two public properties or a hash map. On receiving
this data the text would be demarshalled into similar orderless
structures and that the data found an ordered expression during
transport would be quickly forgotten. When viewing a document as a
stream and interpreting while still incomplete it is easier to
mistakenly react differently according to field order. If nodes from the
example above were used when only the first field has arrived Sally
would find a different handling than John or Jack. Because the
serialisation will contain items which are written to follow an
indeterminate order it will be important to ensure that, despite the
streaming, the REST client does not encourage programming in a way that
gives different results depending on the order that fields are received.

\subsection{Common patterns for connecting to REST
services}\label{common-patterns-for-connecting-to-rest-services}

For languages such as Javascript or Clojure which use a loosely-typed
representation of objects as generic key-value pairs, when a JSON REST
resource is received the output from the parser resembles the normal
object types closely enough that it is acceptable to use it directly
throughout the program. For XML this is not the case in any language and
some marshaling is required. In more strongly typed OO languages such as
Java or C\#, JSON's classless, relatively freeform objects are less
convenient. To smoothly integrate the example JSON from the previous
section, instances of a domain model Person class with methods such as
\texttt{getName()} and \texttt{getLocation()} would have to be
initialised, representing the remote objects no differently than if they
had originated locally. Automatic marshaling generalises this process by
providing a two-way mapping between the domain model and its
serialisation, either completely automatically or based on a declarative
specification. It is common in strongly typed languages for REST client
libraries to automatically demarshal as part of receiving a fetched REST
response. From the programmer's vantage it is as if the domain objects
themselves had been fetched. Another common design pattern intended to
give a degree of isolation between remote resources and the local domain
model is to demarshal automatically only so far as \emph{Data Transfer
Objects} (DTOs). DTOs are instances of classes which implement no logic
other than storage, and from these DTOs an additional layer
programmatically instantiates the local domain model objects. DTOs are
more necessary when using XML. Reading resources encoded as JSON we
might say that the JSON objects are already DTOs.

The degree of marshaling that is used generally changes only the types
of the entities that the REST client library hands over to the
application developer without affecting the overall structure of the
message. Regardless of the exact types, having received the response
model the developer will usually start by locating the pertinent parts
of the response by drilling down into its structure using the
programming language itself.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Java example - programmatic approach to domain model }
\CommentTok{// interrogation}
\CommentTok{// The methods used to drill down to desired components }
\CommentTok{// are all getters: getPeople, getName, and getTown.}
 
\DataTypeTok{void} \FunctionTok{handleResponse}\NormalTok{( RestResponse response ) \{}

   \KeywordTok{for}\NormalTok{( Person p : response.}\FunctionTok{getPeople}\NormalTok{() ) \{}
      \FunctionTok{addPersonToDb}\NormalTok{( p.}\FunctionTok{getName}\NormalTok{(), p.}\FunctionTok{getTown}\NormalTok{() );}
   \NormalTok{\}   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// equivalent Javascript - the programming follows the same basic}
\CommentTok{// process. This time using Javascript's dot operator.}
\KeywordTok{function} \FunctionTok{handleResponse}\NormalTok{( response )\{}

   \OtherTok{response}\NormalTok{.}\OtherTok{people}\NormalTok{.}\FunctionTok{forEach}\NormalTok{( }\KeywordTok{function}\NormalTok{( person )\{}
      \FunctionTok{addPersonToDb}\NormalTok{( }\OtherTok{p}\NormalTok{.}\FunctionTok{name}\NormalTok{, }\OtherTok{p}\NormalTok{.}\FunctionTok{town} \NormalTok{);}
   \NormalTok{\});}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

One weakness of this method for locating resource parts is that the code
making the inspection is coupled to the precise structure of the thing
that it is inspecting. Taking the above example, if the resource being
fetched were later refactored such that the town concept were changed to
a fuller address structure as a street-town-county-country tuple, the
code addressing the structure would also have to change just to continue
to do the same thing. Although this kind of drill-down programming is
commonly practiced and not generally recognised as a code smell,
requiring knock-on changes when an unrelated system is refactored should
perhaps be seen as undesirable in relation to format structures as it
would be elsewhere. DTOs limit the spread of refactoring inside the
client because only the translation from DTO to domain object must be
updated but do not avoid change altogether if a service format is
refactored. In the \emph{Red Queen's race} it took ``all the running you
can do, to keep in the same place''. Ideally a programmer should only
have to expend effort so that their code does something new, or performs
better something that it already did, not to stay still. Following an
object oriented encapsulation of data such that a caller does not have
to concern itself with the data structures behind an interface the
internal implementation may be changed without disruptions to the rest
of the code base. However, when the structure of the inter-object
composition is revised, isolation from the changes is less often
recognised as a desirable trait. A method of programming which truly
embraced extreme programming would allow structural refactoring to occur
without disparate parts having to be modified in parallel.

Extraneous changes also dilute a VCS changelog, making it difficult to
later follow a narrative of updates to the logic expressed by the
program. It is therefore harder to later understand the thinking behind
a change or the reason for the change.

In VirtualStudio, LINQ (Microsoft 2013) which is based on
lambda-calculus and resembles SQL is used to drill-down into data
structures and may also modify the data that is found. However this
style of programming requires the application developer to write
significantly more code than simple programmatic access above so it does
not meet the aims of this project.

Given model interrogation logic which is tightly coupled so that the
model's structure cannot change, one suggested approach is Adaptive OOP
(Lieberherr, Silva-Lepe, and Cun 1994) in which no detailed class
structure is committed to when constructing the object oriented program.
A REST resource could be dynamically configured into an OO model
according to a formal specification in a specialisation that is capable
of answering the desired queries. The model that is constructed would be
sufficient to answer the queries without the programmer having to
suppose any rigid form.

\subsection{JSONPath and XPath selector
languages}\label{jsonpath-and-xpath-selector-languages}

\label{jsonpathxpath}

To address the problem of drilling down to pertinent fragments of a
message without tightly coupling to the format, consider if instead of
programmatically descending step-by-step, a language were used which
allows the right amount of specificity to be given regarding which parts
to select. Certain markup languages come with associated query languages
whose coupling is loose enough that not every node that is descended
through must be specified. The best known is XPATH but there is also
JSONPath, a JSON equivalent (Goessner 2007).

As far as possible, JSONPath's syntax resembles the equivalent
Javascript:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// in Javascript we can get the town of the second person as:}
\KeywordTok{let} \NormalTok{town = }\OtherTok{subject}\NormalTok{.}\FunctionTok{people}\NormalTok{[}\DecValTok{2}\NormalTok{].}\FunctionTok{town}

\CommentTok{// the equivalent JSONPath expression is identical:}
\KeywordTok{let} \NormalTok{townSelector = }\StringTok{"people[2].town"}

\CommentTok{// We would be wise not to write overly-specific selectors.}
\CommentTok{// JSONPath also provides an ancestor notation which is not present}
\CommentTok{// in Javascript:}
\KeywordTok{let} \NormalTok{betterTownSelector = }\StringTok{"people[2]..town"}
\end{Highlighting}
\end{Shaded}

Consider the resource below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \DataTypeTok{people}\NormalTok{: [}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'John'}\NormalTok{, }\DataTypeTok{town}\NormalTok{:}\StringTok{'Oxford'}\NormalTok{\},}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'Jack'}\NormalTok{, }\DataTypeTok{town}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{\}}
      \NormalTok{\{}\DataTypeTok{town}\NormalTok{:}\StringTok{'Cambridge'}\NormalTok{, }\DataTypeTok{name}\NormalTok{: }\StringTok{'Sally'}\NormalTok{\}}
   \NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The JSONPath \texttt{people.*..town} may be applied against the above
JSON and would continue to select correctly if the system were
refactored to the version below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \DataTypeTok{people}\NormalTok{: [}
      \NormalTok{\{  }\DataTypeTok{name}\NormalTok{: }\StringTok{'John'}\NormalTok{, }
         \DataTypeTok{address}\NormalTok{:\{}\DataTypeTok{town}\NormalTok{:}\StringTok{'Oxford'}\NormalTok{, }\DataTypeTok{county}\NormalTok{:}\StringTok{'Oxon'}\NormalTok{, }\DataTypeTok{country}\NormalTok{:}\StringTok{'uk'}\NormalTok{\}}
      \NormalTok{\},}
      \NormalTok{\{  }\DataTypeTok{name}\NormalTok{: }\StringTok{'Jack'}\NormalTok{,}
         \DataTypeTok{address}\NormalTok{:\{}\DataTypeTok{town}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{, }\DataTypeTok{county}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{, }\DataTypeTok{country}\NormalTok{:}\StringTok{'uk'}\NormalTok{\}}
      \NormalTok{\}}
      \NormalTok{\{  }\DataTypeTok{address}\NormalTok{:\{}
            \DataTypeTok{town}\NormalTok{:}\StringTok{'Cambridge'}\NormalTok{, }\DataTypeTok{county}\NormalTok{:}\StringTok{'Cambridgeshire'}\NormalTok{, }
            \DataTypeTok{country}\NormalTok{:}\StringTok{'uk'}
         \NormalTok{\},}
         \DataTypeTok{name}\NormalTok{: }\StringTok{'Sally'}
      \NormalTok{\}}
   \NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Maintaining compatibility with unanticipated format revisions through
selector languages is easier with JSON than XML. The XML metamodel
contains overlapping representations of equivalent entities which a
format being refactored is liable to switch between. Each XML element
has two distinct lists of child nodes, attribute children and node list
children. From one perspective attributes are child nodes of their
parent element but they can alternatively be considered as data stored
in the element. Because of this classification ambiguity an XML document
can't be said to form a single n-way tree. XML attributes may only
contain strings and have a lesser expressivity than child nodes which
allow recursive structure; it is a common refactor to change from
attributes to elements when a scalar value is upgraded to a compound.
XPath selectors written in the most natural way do not track this
change.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{<people>}
   \KeywordTok{<person}\OtherTok{ name=}\StringTok{"John"}\OtherTok{ town=}\StringTok{"Oxford"}\KeywordTok{></person>}
\KeywordTok{</people>}
\end{Highlighting}
\end{Shaded}

The XPath \texttt{//person@town} matches against the XML above but
because of the switch from attribute to child element fails to match
towns in the revised version below.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{<people>}
   \KeywordTok{<person>}
      \KeywordTok{<name>}
         \NormalTok{John}
      \KeywordTok{</name>}
      \KeywordTok{<address>}
         \KeywordTok{<town>}\NormalTok{Oxford}\KeywordTok{</town>} \KeywordTok{<county>}\NormalTok{Oxon}\KeywordTok{</county>}
      \KeywordTok{</address>}
   \KeywordTok{</person>}
\KeywordTok{</people>}
\end{Highlighting}
\end{Shaded}

Reflecting its dual purpose for marking up documents or data, XML also
invites ambiguous interpretation of the whitespace between tags.
Whitespace is usually meaningful for documents but ignorable for data.
Strictly, whitespace text nodes are a part of the document model but in
practice many tree walkers discard them as insignificant. In the XML
above the \texttt{\textless{}person\textgreater{}} element may be
enumerated as either the first or second child of
\texttt{\textless{}people\textgreater{}} depending on whether the
whitespace before it is considered. Likewise, the text inside
\texttt{\textless{}name\textgreater{}} might be \texttt{'John'} or
\texttt{'(newline)(tab)(tab)John'}. Inheriting from its programming
language ancestry, in JSON there is no ambiguity. The space between
tokens is never significant.

Programming against a changing service is always going to present a
moving target but it would be easier to miss with XPATH than with
JSONPath. In the JSON metamodel each node has only one, unambiguous set
of children so the format author is not given a choice of logically
equivalent features that must be addressed through different mechanisms.
If a scalar value is updated to a compound only the node changes, the
addressing of the node is unaffected.

Generally in descriptive hierarchical data there is a trend for
ancestorship to signify the same relationship regardless of the number
of intermediate generations. In the example above, \texttt{town}
transitioned from a child to grandchild of \texttt{person} without
disturbing the implicit `lives in' relationship. In JSONPath the
\texttt{..} operator provides matching through zero or more generations,
unperturbed when extra levels are added. This trend does not hold for
every way that message semantics may be built because it is possible
that an intermediate node on the path from ancestor to descendant will
change the nature of the expressed relationship. A slightly contrived
example might be if we expanded our model to contain fuzzy knowledge:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \StringTok{"people"}\NormalTok{: [}
      \NormalTok{\{  }
         \StringTok{"name"}\NormalTok{:     \{}\StringTok{"isProbably"}\NormalTok{:}\StringTok{"Bob"}\NormalTok{\},}
         \StringTok{"location"}\NormalTok{: \{}\StringTok{"isNearTo"}\NormalTok{:}\StringTok{"Birmingham"}\NormalTok{\}}
      \NormalTok{\}}
   \NormalTok{]   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Considering the general case, it will not be possible to safely track
every refactoring. By necessity a resource consumer should limit their
ambitions to tracking ontology expansions which do not change the
meanings of existing concepts. In practice integration testing against
the beta version of a service will be necessary to be pre-warned of
upcoming, incompatible changes. If an incompatibility is found the
ability to then create an expression which is compatible with a present
and known future version would remain a valuable tool because it
decouples the consumer and provider update schedules, removing the need
for the client to march perfectly in sync with the service.

\subsection{Browser XML HTTP Request
(XHR)}\label{browser-xml-http-request-xhr}

Making HTTP requests from Javascript, commonly termed AJAX, was so
significant in establishing the modern web architecture that it is
sometimes used synonymously with Javascript-rich web applications.
Although AJAX is an acronym for \textbf{A}synchronous
\textbf{J}avascript (\textbf{a}nd) \textbf{X}ML, this reflects the early
millennial enthusiasm for XML as the one true data format and in
practice any textual format may be transferred. During the `browser war'
years web browsers competed by adding non-standard features; Internet
Explorer made AJAX possible in 2000 by exposing Microsoft's Active X
\emph{Xml Http Request} (XHR) class to the Javascript sandbox. This was
widely copied and near equivalents were added to all major browsers. In
2006 the interface was eventually formalised by the W3C (van Kesteren
and Jackson 2006). XHR's slow progresss to standardisation reflected a
period of general stagnation for web standards. HTML4 reached
Recommendation status in 2001 but having subsequently found several
evolutionary dead ends such as XHTML, there would be no major updates
until HTML5 started to gather pace some ten years later.

Despite a reputation for being poorly standardised, as a language
Javascript enjoys consistent implementation. More accurately we would
say that browser APIs exposed to Javascript lack compatibility. Given
this backdrop of vendor extensions and lagging standardisation,
abstraction layers predictably rose in popularity. Various abstractions
competed primarily on developer ergonomics with the popular jQuery and
Prototype.js libraries promoting themselves as \emph{``do more, write
less''} and \emph{``elegant APIs around the clumsy interfaces of
Ajax''}. Written against the unadorned browser, Javascript applications
read as a maze of platform detection and special cases. Once
applications were built using abstractions over the underlying platform
differences they could be written purposefully and programmers were able
to express more complex ideas.

Today JSON is generally the preferred format, especially for resources
transmitted to client-side web applications. Javascript programmers
occupy a privileged position whereby their serialisation format maps
exactly onto the inbuilt types of their programming language. As such
there is never any confusion regarding which object structure to
de-serialise to. Should this advantage seem insubstantial, contrast with
the plethora of confusing and incompatible representations of JSON that
are output by the various Java parsers: JSON's Object better resembles
Java's Map interface than Java Objects, creating linguistic
difficulties, and the confusion between JSON null, Java null, and
Jackson's NullNode\footnote{See
  \url{http://jackson.codehaus.org/1.0.1/javadoc/org/codehaus/jackson/node/NullNode.html}}
is a common cause of errors. Emboldened by certainty regarding
deserialisation, AJAX libraries directly integrate JSON parsers,
providing a call style for working with remote resources so streamlined
as to require hardly any additional effort.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ajax}\NormalTok{(}\StringTok{'http://example.com/people.json'}\NormalTok{, }\KeywordTok{function}\NormalTok{( people ) \{}

   \CommentTok{// The parsing of the people JSON into a javascript object}
   \CommentTok{// feels so natural that it is easy to forget from looking }
   \CommentTok{// at the code that parsing happens at all. }
   
   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'the first person is called'}\NormalTok{, people[}\DecValTok{0}\NormalTok{].}\FunctionTok{name}\NormalTok{);}
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

\subsection{XHRs and streaming}\label{xhrs-and-streaming}

\label{xhrsandstreaming}

Browser abstraction layers brought an improvement in expressivity to web
application programming but were ultimately limited to supporting the
lowest common denominator of available browser abilities. When the call
style above was developed the most popular browser barred access to
in-progress responses so the inevitable conceptualisation was drawn of
the response as a one-time event with no accommodation provided for
progressively delivered data.

The followup standard, XHR2 is now at Working Draft stage (van Kesteren
2012). Given ambitions to build a streaming REST client, of greatest
interest is the progress event:

\begin{quote}
While the download is progressing, queue a task to fire a progress event
named progress about every 50ms or for every byte received, whichever is
least frequent.
\end{quote}

The historic lack of streaming for data fetched using XHR stands
incongruously with the browser as a platform in which almost every other
remote resource is interpreted progressively. Examples include
progressive image formats, HTML, SVG, and video.

The progress event is supported by the latest version of all major
browsers. However, Internet Explorer only added support recently with
version 10 and there is a significant user base remaining on versions 8
and 9.

\subsection{Browser streaming
frameworks}\label{browser-streaming-frameworks}

\label{browserstreamingframeworks}

The web's remit is increasingly widening to encompass scenarios which
would have previously been the domain of native applications. In order
to use live data many current webapps employ frameworks which push
soft-real-time events to the client side. This kind of streaming
intersects only narrowly with the aims of the XHR2 progress event.
Whereas XHR2 enables downloads to be viewed as streams but does not
otherwise disrupt the sequence of HTTP's request-response model,
streaming frameworks facilitate an entirely different sequence, that of
perpetual data. Consider a webmail interface; initially the user's inbox
is downloaded via REST and although a streaming download might be used
to make its display more responsive, the inbox download is a standard
REST call and shares little in common with the push events which follow
to provide instant notification as new messages arrive.

\textbf{Push tables} sidestep the browser's absent data streaming
abilities by leaning on a resource that it can stream: progressive HTML.
On the client a page containing a table is hidden in an off-screen
iframe. The frame's content is served as an HTML page containing a table
that never completes, fed by a connection that never closes. When the
server wishes to push a message to the client it writes a new row to the
table which is then noticed by Javascript monitoring the iframe on the
client. More recently, \textbf{Websockets} provides a standardised
streaming transport on top of HTTP's chunked mode. Websockets requires
browser implementation and cannot be retrofitted to older browsers
through Javascript. It is a promising technology but for the time being
patchy support means it cannot be used without a suitable fallback.

These frameworks do not interoperate at all with REST. Because the
resources they serve never complete they may not be read by a standard
REST client. Unlike REST they also are not amenable to standard HTTP
mechanisms such as caching. A server which writes to an esoteric format
requiring a specific, known, specialised client also feels quite
anti-REST, especially when we consider that the format design reflects
the nature of the transport more so than the resource. This form of
streaming is not, however, entirely alien to a SOA mindset. The data
formats, while not designed primarily for human readability are
nonetheless text based and a person may take a peek inside the system's
plumbing simply by observing the traffic at a particular URL. For push
tables, because the transport is based on a presentation format, an
actual table of the event's properties may be viewed from a browser as
the messages are streamed.

\subsection{Parsing: SAX and DOM}\label{parsing-sax-and-dom}

From the XML world two standard parser types exist, SAX and DOM, with
DOM by far the more popular. Both styles of parsers are also available
for JSON. DOM performs a parse as a single evaluation and returns an
object model representing the whole of the document. Conversely, SAX
parsers are probably better considered as enhanced tokenisers, providing
a very low-level event driven interface that notifies the programmer of
each token separately as it is found. Working with DOM's level of
abstraction the markup syntax is a distant concern whereas for SAX each
element's opening and closing must be noted so the developer may not put
the data's serialisation aside. SAX comes with the advantages that it
may read a document progressively and has lower memory requirements
because it does not store the parsed tree. Correspondingly, it it
popular for embedded systems running on constrained hardware and may be
used to handle documents larger than the available RAM.

Suppose we have some JSON representing people and want to extract the
name of the first person. Given a DOM parser this may be written quite
succinctly:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{nameOfFirstPerson}\NormalTok{( myJsonString ) \{}

   \CommentTok{// All recent browsers provide JSON.parse as standard. }
   \KeywordTok{var} \NormalTok{document = }\OtherTok{JSON}\NormalTok{.}\FunctionTok{parse}\NormalTok{( myJsonString );}
   \KeywordTok{return} \OtherTok{document}\NormalTok{.}\FunctionTok{people}\NormalTok{[}\DecValTok{0}\NormalTok{].}\FunctionTok{name}\NormalTok{; }\CommentTok{// that was easy!}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

To contrast, the equivalent below uses the Javascript Clarinet SAX
parser, expressed in the most natural way for the technology\footnote{For
  an example closer to the real world see
  \url{https://github.com/dscape/clarinet/blob/master/samples/twitter.js}}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{nameOfFirstPerson}\NormalTok{( myJsonString, callbackFunction )\{}


   \KeywordTok{var} \NormalTok{clarinet = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{parser}\NormalTok{(),}
   
       \CommentTok{// With a SAX parser it is the developer's responsibility }
       \CommentTok{// to track where in the document the cursor currently is.}
       \CommentTok{// Several variables are required to maintain this state.        }
       \NormalTok{inPeopleArray = }\KeywordTok{false}\NormalTok{,   }
       \NormalTok{inPersonObject = }\KeywordTok{false}\NormalTok{,}
       \NormalTok{inNameAttribute = }\KeywordTok{false}\NormalTok{,}
       \NormalTok{found = }\KeywordTok{false}\NormalTok{;}
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onopenarray} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \CommentTok{// For brevity we'll cheat by assuming there is only one}
      \CommentTok{// array in the document. In practice this would be overly}
      \CommentTok{// brittle.      }
      \NormalTok{inPeopleArray = }\KeywordTok{true}\NormalTok{; }
   \NormalTok{\};}
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onclosearray} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \NormalTok{inPeopleArray = }\KeywordTok{false}\NormalTok{;}
   \NormalTok{\};   }
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onopenobject} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \NormalTok{inPersonObject = inPeopleArray; }
   \NormalTok{\};}
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{oncloseobject} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \NormalTok{inPersonObject = }\KeywordTok{false}\NormalTok{;}
   \NormalTok{\};   }
      
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onkey} \NormalTok{= }\KeywordTok{function}\NormalTok{(key)\{}
      \NormalTok{inNameAttribute = (inPeopleObject && key == }\StringTok{'name'}\NormalTok{);}
   \NormalTok{\};}

   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onvalue} \NormalTok{= }\KeywordTok{function}\NormalTok{(value)\{}
      \KeywordTok{if}\NormalTok{( !found && inNameAttribute ) \{}
         \CommentTok{// finally!}
         \FunctionTok{callbackFunction}\NormalTok{( value );}
         \NormalTok{found = }\KeywordTok{true}\NormalTok{;}
      \NormalTok{\}}
   \NormalTok{\};      }
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{write}\NormalTok{(myJsonString);   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The developer pays a high price for progressive parsing, the SAX version
is considerably longer and more difficult to read. SAX's low-level
semantics require a lengthy expression and push onto the programmer the
responsibility for managing state regarding the current position in the
document and storing data extracted from previously seen nodes. This
maintenance of state tends to be programmed once per usage rather than
assembled as the composition of reusable parts. The ordering of the code
under SAX is also quite unintuitive; event handlers cover multiple
unrelated cases and each concern spans multiple handlers. This lends to
a style of programming in which separate concerns do not find separate
expression in the code. It is also notable that, unlike DOM, as the
depth of the document being interpreted increases, the length of the
programming required to interpret it also increases, mandating more
state be stored and an increased number of cases be covered per event
handler.

While SAX addresses many of the problems raised in this dissertation,
its unfriendly developer ergonomics have presented too high a barrier
for adoption for all but fringe use cases.

\section{Design and Reflection}\label{design-and-reflection}

The REST workflow is more efficient if we do not wait until we have
everything before we start using the parts that we do have. The main
tool to achieve this is the SAX parser whose model presents poor
developer ergonomics because it is not usually convenient to think on
the markup's level of abstraction. Using SAX, a programmer may only
operate on a convenient abstraction after inferring it from a lengthy
series of callbacks. In terms of ease of use, DOM is generally preferred
because it provides the resource whole and in a convenient form. It is
possible to duplicate this convenience and combine it with progressive
interpretation by removing one restriction: that the node which is given
is always the document root. From a hierarchical markup such as XML or
JSON, when read in order, sub-trees are fully known before we fully know
their parent tree. We may select pertinent parts of a document and
deliver them as fully-formed entities as soon as they are known, without
waiting for the remainder of the document to arrive. This approach
combines most of the desirable properties from SAX and DOM parsers into
a new, hybrid method.

The interesting parts of a document may be identified before it is
complete if we turn the established model for drilling-down inside-out.
Under asynchronous I/O the programmer's callback traditionally receives
the whole resource and then, inside the callback, locates the sub-parts
that are required for a particular task. Inverting this process, the
locating logic currently found inside the callback can be extracted from
it, expressed as a selector language, and used it to declare the cases
in which the callback should be notified. The callback will receive
complete fragments from the response once they have been selected
according to this declaration.

Javascript will be used to implement the software deliverables because
it has good support for non-blocking I/O and covers both environments
where this project will be most useful: web browser and web server.
Focusing on the MVP, parsing will only be implemented for one mark-up
language. Although this technique could be applied to any text-based,
tree-shaped markup, JSON best meets the project goals because it is
widely supported, easy to parse, and defines a single n-way tree, making
it more amenable to selectors which span multiple format versions.

JSONPath is well suited for selecting nodes while the document is being
read because it specifies only constraints on paths and `contains'
relationships. Because of the top-down serialisation order, on
encountering any node in a serialised JSON stream we will have already
seen enough of the prior document to know its full path. JSONPath would
not be so amenable if it expressed sibling relationships because there
is no similar guarantee of having seen other nodes on the same level
when any particular node is encountered. A new implementation of the
language is required because the existing JSONPath library is
implemented only as a means to search through already gathered objects
and is too narrow in applicability to be useful in a streaming context.

Given that we are selecting specifically inside a REST resource it is
unlikely that we will be examining a full model. Rather, the selectors
will be applied to a subset that we requested and was assembled on our
behalf according to parameters that we supplied. We can expect to be
interested in all of the content belonging to a particular category so
search-style selections such as `books costing less than X' are less
useful than queries which identify nodes because of their type and
position such as `all books in the discount set', or, because we know we
are examining \texttt{/books/discount}, simply `all books'. In creating
a new JSONPath implementation the existing language is followed somewhat
loosely, specialising the matching by adding features which are likely
to be useful when detecting entities in REST resources while avoid
unnecessary code by dropping others. Later adding new features to a
language is easier than removing them once a userbase has built up so
where the utility isn't clear the default position is to not include. It
is difficult to anticipate all real-world matching requirements but it
should be possible to identify a core 20\% of features that are likely
to be useful in 80\% of cases. For the time being any functionality
which is not included may be implemented by registering a more
permissive selection and then further filtering programmatically from
inside the callback. Patterns of programmatic filtering which arise from
use in the wild can later mined and added to the selection language.

\subsection{Detecting types in JSON}\label{detecting-types-in-json}

As seen in the `all books' example above, it is intuitive to support
identifying sub-trees according to a categorisation by higher-level
types. JSON markup describes only a few basic types. On a certain level
this is also true for XML -- most nodes are either of type Element or
Text. However, the XML metamodel provides tagnames; essentially, a
built-in type system for subclassifying the elements. JSON has no
similar notion of types beyond the basic constructs: array, object,
string, number. To understand data written in JSON's largely typeless
model it is often useful if we think in terms of a more complex type
system. This imposition of type is the responsibility of the observer
rather than of the observed. The reader of a document is free to choose
the taxonomy they will use to interpret it and this decision will vary
depending on the purposes of the reader. The required specificity of
taxonomy differs by the level of involvement in a field; whereas `watch'
may be a reasonable type for most data consumers, to a horologist it is
likely to be unsatisfactory without further sub-types. To serve
disparate purposes, the JSONPath variant provided for node selection
will have no inbuilt concept of type, the aim being to support
programmers in creating their own.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{<!--  }
\CommentTok{  XML leaves no doubt as to the labels we give to an Element's type }
\CommentTok{  type. Although we might further interpret, this is a 'person'}
\CommentTok{-->}
\KeywordTok{<person}\OtherTok{  name=}\StringTok{'...'}\OtherTok{ gender=}\StringTok{"male"}
\OtherTok{         age=}\StringTok{"45"}\OtherTok{ height=}\StringTok{"175cm"}\OtherTok{ profession=}\StringTok{"architect"}\KeywordTok{>}
\KeywordTok{</person>}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/* JSON meanwhile provides no built-in type concept. }
\CommentTok{   This node's type might be 'thing', 'animal', 'human', 'male',}
\CommentTok{   'man', 'architect', 'artist' or any other of many overlapping}
\CommentTok{   impositions depending on our reason for examining this data}
\CommentTok{*/}
\NormalTok{\{  }\StringTok{"name"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"gender"}\NormalTok{:}\StringTok{"male"}\NormalTok{, }\StringTok{"age"}\NormalTok{:}\StringTok{"45"} 
   \StringTok{"height"}\NormalTok{:}\StringTok{"172cm"} \StringTok{"profession"}\NormalTok{:}\StringTok{"architect"}\NormalTok{>}
\NormalTok{\}         }
\end{Highlighting}
\end{Shaded}

In the absence of node typing beyond categorisation as objects, arrays
and various primitives, the key immediately mapping to an object is
often taken as a loose marker of its type. In the below example we may
impose the the type `address' on two nodes prior to examining their
contents because of the field name which maps to them from the parent
node.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \StringTok{"name"}\NormalTok{: }\StringTok{"..."}
\NormalTok{,  }\StringTok{"residence"}\NormalTok{: \{}
      \StringTok{"address"}\NormalTok{: [}
         \StringTok{"47"}\NormalTok{, }\StringTok{"Cloud street"}\NormalTok{, }\StringTok{"Dreamytown"}
      \NormalTok{]}
   \NormalTok{\}}
\NormalTok{,  }\StringTok{"employer"}\NormalTok{: \{}
      \StringTok{"name"}\NormalTok{: }\StringTok{"Mega ultra-corp"}
   \NormalTok{,  }\StringTok{"address"}\NormalTok{:[}
         \StringTok{"Floor 2"}\NormalTok{, }\StringTok{"The Offices"}\NormalTok{, }\StringTok{"Alvediston"}\NormalTok{, }\StringTok{"Wiltshire"}      
      \NormalTok{]}
   \NormalTok{\}   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This means of imposing type is simply expressed as JSONPath. The
selector \texttt{address} would match all nodes whose parent maps to
them via an address key.

As a loosely typed language, Javascript gives no protection against
lists which store disparate types but by sensible convention this is
avoided. Likewise, in JSON, although type is a loose concept, the items
in a collection will generally be of the same type. From here follows a
sister convention illustrated in the example below, whereby each item
from an array is typed according to the key in the grandparent node
which maps to the array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \StringTok{"residences"}\NormalTok{: \{}
      \StringTok{"addresses"}\NormalTok{: [}
         \NormalTok{[}\StringTok{"10"}\NormalTok{, }\StringTok{"Downing street"}\NormalTok{, }\StringTok{"London"}\NormalTok{]}
      \NormalTok{,  [}\StringTok{"Chequers Court"}\NormalTok{, }\StringTok{"Ellesborough"}\NormalTok{, }\StringTok{"Buckinghamshire"}\NormalTok{]      }
      \NormalTok{,  [}\StringTok{"Beach Hut"}\NormalTok{, }\StringTok{"Secret Island"}\NormalTok{, }\StringTok{"Bahamas"}\NormalTok{]}
      \NormalTok{]}
   \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

In the above markup, \texttt{addresses.*} would correctly identify three
address nodes. The pluralisation of field names such as `address'
becoming `addresses' is common when marshaling from OO languages because
the JSON keys are extracted from getter names which reflect the method's
cardinality: \texttt{public Address getAddress()} or
\texttt{public List\textless{}Address\textgreater{} getAddresses()}. To
identify members of a type held singularly or plurally it might help if
a system that understands natural language pluralisation such as Ruby on
Rails were investigated. Unions were also considered as a simpler
solution, resembling \texttt{address\textbar{}addresses.*}. It was
decided that until the usefulness is better demonstrated, with no
obvious best solution, it is simplest to handle plurals outside of the
JSONPath language by expecting the programmer to register two selection
specifications against the same handler function.

In the below example types may not be easily inferred from ancestor
keys.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \StringTok{"name"}\NormalTok{: }\StringTok{"..."}
\NormalTok{,  }\StringTok{"residence"}\NormalTok{: \{}
      \StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} 
   \NormalTok{\}}
\NormalTok{,  }\StringTok{"employer"}\NormalTok{:\{}
      \StringTok{"name"}\NormalTok{: }\StringTok{"..."}
   \NormalTok{,  }\StringTok{"premises"}\NormalTok{:[}
         \NormalTok{\{ }\StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} \NormalTok{\}}
      \NormalTok{,  \{ }\StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} \NormalTok{\}}
      \NormalTok{,  \{ }\StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} \NormalTok{\}}
      \NormalTok{]}
   \NormalTok{,  }\StringTok{"registeredOffice"}\NormalTok{:\{}
         \StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."}
      \NormalTok{\}}
   \NormalTok{\}}
\NormalTok{\}  }
\end{Highlighting}
\end{Shaded}

Here, the keys which map onto addresses are named by the relationship
between the parent and child nodes rather than by the type of the child.
The type classification problem could be solved using an ontology with
`address' subtypes `residence', `premises', and `office' but this
solution feels quite heavyweight for a simple selection language.
Instead the idea of \emph{duck typing} was imported from Python, as
named in a 2000 usenet discussion:

\begin{quote}
In other words, don't check whether it IS-a duck: check whether it
QUACKS-like-a duck, WALKS-like-a duck, etc, etc, depending on exactly
what subset of duck-like behaviour you need (Martelli 2000)
\end{quote}

An address `duck-definition' for the above JSON would say that any
object which has number, street, and town properties is an address.
Applied to JSON, duck typing takes an individualistic approach by
deriving type from the node itself rather than the situation in which it
is found. As discussed in section \ref{jsonpathxpath}, JSONPath's syntax
is designed to resemble the equivalent Javascript accessors but
Javascript has no syntax for a value-free list of object keys. The
closest available Javascript notation is that for object literals so a
derivative duck-type syntax was created by omitting the values,
quotation marks, and commas. The address type described above would be
written as \texttt{\{number street town\}}. Field order is insignificant
so \texttt{\{a b\}} and \texttt{\{b a\}} are equivalent.

It is difficult to generalise but when selecting items it is often
useful if subtypes, nodes which are covariant with the given type, are
also matched. We may consider that there is a root duck type
\texttt{\{\}} which matches any node, that we create a sub-duck-type if
we add to the list of required fields, and a super-duck-type if we
remove from it. Because in OOP extended classes may add new fields, this
idea of the attribute list expanding for a sub-type applies neatly to
resources marshaled from an OO representation. To conform to a duck-type
a node must have all of the required fields but could also have any
others.

\subsection{Importing CSS4's explicit capturing to
JSONPath}\label{importing-css4s-explicit-capturing-to-jsonpath}

JSONPath naturally expresses a `contained in' relationship using the dot
notation but no provision is made for the inverse `containing'
relationship. \emph{Cascading Style Sheets}, CSS, the web's styling
language, has historically shared this restriction but a proposal for
extended selectors which is currently at Editor's Draft stage (Etemad
and Atkins 2013) introduces an elegant solution. Rather than add an
explicit `containing' relationship, the draft observes that CSS has
previously always selected the element conforming to the right-most of
the selector terms, allowing only the deepest mentioned element to be
styled. This restriction is lifted by allowing terms to be prefixed with
\texttt{\$} in order to make them explicitly capturing; a selector
without an explicit capturing term continues to work as before. The CSS
selector \texttt{form.important input.mandatory} selects mandatory
inputs inside important forms but
\texttt{\$form.important input.mandatory} selects important forms with
mandatory fields.

CSS4 selector capturing will be incorporated into this project's
JSONPath implementation. By duplicating a syntax which the majority of
web developers should become familiar with over the next few years the
learning curve should appear more gradual. Taking on this feature, the
selector \texttt{person.\$address.town} would identify an address node
with a town child, or \texttt{\$people.\{name, dob\}} can be used to
locate the same people array repeatedly whenever a new person is added
to it. Javascript frameworks such as d3.js and Angular are designed to
work with whole models as they change. Consequently, the interface they
present converses more fluently with collections than individual
entities. If we are downloading data to use with these libraries the
integration is more convenient with explicit capturing because we can
hand over the collection as it expands.

\subsection{Parsing the JSON response}\label{parsing-the-json-response}

While SAX parsers provide an unappealing interface to application
developers, as a starting point to handle low-level parsing in
higher-level libraries they work very well -- most XML DOM parsers are
built in this way. The pre-existing Clarinet project (Job 2011) is well
tested, liberally licenced, and compact, meeting our needs perfectly.
The name of this project, Oboe.js, was chosen in tribute to the value
delivered by Clarinet, itself named after the \textbf{SAX}ophone.

\subsection{API design}\label{api-design}

Everything that Oboe is designed to do can already be achieved by
combining a SAX parser with imperatively coded node selection. This has
not been widely adopted because it requires verbose, difficult
programming in a style which is unfamiliar to most programmers. With
this in mind it is a high priority to design a public API for Oboe which
is concise, simple, and resembles other commonly used tools. If Oboe's
API is made similar to common tools a lesser modification should be
required to switch existing projects to streaming HTTP.

For some common use cases it should be possible to create an API which
is a close enough equivalent to popular tools that it can be used as a
direct drop-in replacement. Although used in this way no progressive
loading would be enacted, when refactoring towards a goal the first step
is often to create a new expression of the same logic (Martin 2008,
212). By giving basic support for non-progressive downloading the door
is open for apps to incrementally refactor towards a progressive
expression. Allowing adoption as a series of small, easily manageable
steps rather than a single leap is especially helpful for teams working
under Scrum because all work must be self-contained and fit within a
fairly short timeframe.

jQuery is by far the most popular library for AJAX today. The basic call
style for making a GET request is as follows:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{jQuery}\NormalTok{.}\FunctionTok{ajax}\NormalTok{(}\StringTok{"resources/shortMessage.txt"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{done}\NormalTok{(}\KeywordTok{function}\NormalTok{( text ) \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\StringTok{"Got the text:"}\NormalTok{, text ); }
   \NormalTok{\}).}
   \NormalTok{.}\FunctionTok{fail}\NormalTok{(}\KeywordTok{function}\NormalTok{() \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\StringTok{"the request failed"} \NormalTok{);      }
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

The jQuery API is callback-based, it does not wrap asynchronously
retrieved content in event objects, and event types are expressed by the
name of the method used to add the listener. These names, \texttt{done}
and \texttt{fail}, follow generic phrasing and are common to all
asynchronous functionality that jQuery provides. Promoting brevity, the
methods are chainable so that several listeners may be added from one
statement. Although Javascript supports exception throwing, for
asynchronous failures a fail event is used instead. Exceptions are not
applicable to non-blocking I/O because at the time of the failure the
call which provoked the exception will already have been popped from the
stack.

\texttt{jQuery.ajax} is overloaded so that the parameter may be an
object, allowing more detailed information to be given:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{jQuery}\NormalTok{.}\FunctionTok{ajax}\NormalTok{(\{ }\StringTok{"url"}\NormalTok{:}\StringTok{"resources/shortMessage.txt"}\NormalTok{,}
              \StringTok{"accepts"}\NormalTok{: }\StringTok{"text/plain"}\NormalTok{,}
              \StringTok{"headers"}\NormalTok{: \{ }\StringTok{"X-USER-ID"}\NormalTok{: }\StringTok{"123ABC"} \NormalTok{\}}
           \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

This pattern of passing arguments as object literals is common in
Javascript for functions which take a large number of parameters,
particularly if some are optional. This avoids having to pad unprovided
optional arguments in the middle of the list with null values and,
because the purpose of the values is given at the call site, avoids an
anti-pattern where a call may only be understood after counting the
position of the arguments.

Taking on this style while extending it to incorporate progressive
parsing, we arrive at the following API:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/people.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{node}\NormalTok{( }\StringTok{"person.name"}\NormalTok{, }\KeywordTok{function}\NormalTok{(name) \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"There is somebody called"}\NormalTok{, name);   }
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{done}\NormalTok{( }\KeywordTok{function}\NormalTok{( wholeJson ) \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"That is everyone!"}\NormalTok{);}
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{fail}\NormalTok{( }\KeywordTok{function}\NormalTok{() \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"There might may be more people but"}\NormalTok{,}
                  \StringTok{"we don't know who they are yet."}\NormalTok{);}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

In jQuery the whole content is given back at once so usually only one
\texttt{done} handler is added to a request. Under Oboe each separately
addressed area of interest inside the JSON resource requires its own
handler so it is helpful to provide a shortcut style for adding several
selector-handler pairs at a time.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/people.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{node}\NormalTok{(\{  }
      \StringTok{"person.name"}\NormalTok{: }\KeywordTok{function}\NormalTok{(personName, path, ancestors) \{}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"You will hear about"}\NormalTok{, name, }\StringTok{"..."}\NormalTok{);}
      \NormalTok{\},}
      \StringTok{"person.address.town"}\NormalTok{: }\KeywordTok{function}\NormalTok{(townName, path, ancestors) \{}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"...they live in"}\NormalTok{, townName);}
      \NormalTok{\}}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Note the \texttt{path} and \texttt{ancestors} parameters in the example
above. These provide additional information regarding the context in
which the identified node was found. Consider the following JSON:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{ }
   \StringTok{"event"}\NormalTok{: }\StringTok{"Mens' 100m sprint"}\NormalTok{,}
   \StringTok{"date"}\NormalTok{: }\StringTok{"5 Aug 2012"}\NormalTok{,}
   \StringTok{"medalWinners"}\NormalTok{: \{}
      \StringTok{"gold"}\NormalTok{:     \{}\StringTok{"name"}\NormalTok{: }\StringTok{"Bolt"}\NormalTok{,    }\StringTok{"time"}\NormalTok{: }\StringTok{"9.63s"}\NormalTok{\},}
      \StringTok{"silver"}\NormalTok{:   \{}\StringTok{"name"}\NormalTok{: }\StringTok{"Blake"}\NormalTok{,   }\StringTok{"time"}\NormalTok{: }\StringTok{"9.75s"}\NormalTok{\},}
      \StringTok{"bronze"}\NormalTok{:   \{}\StringTok{"name"}\NormalTok{: }\StringTok{"Gatlin"}\NormalTok{,  }\StringTok{"time"}\NormalTok{: }\StringTok{"9.79s"}\NormalTok{\}}
   \NormalTok{\}}
\NormalTok{\}  }
\end{Highlighting}
\end{Shaded}

In this JSON we may extract the runners using the pattern
\texttt{\{name time\}} or \texttt{medalWinners.*} but nodes alone are
insufficient because their location communicates information which is as
important as their content. The \texttt{path} parameter provides the
location as an array of strings plotting a descent from the JSON root to
the found node. For example, Bolt has path
\texttt{{[}'medalWinners', 'gold'{]}}. Similarly, the \texttt{ancestors}
array lists the ancestors starting with the JSON root node and ending at
the immediate parent of the found node. For all but the root node, which
in any case has no ancestors, the nodes given by the ancestor list will
have been only partially parsed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/someJson.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{node}\NormalTok{( }\StringTok{"medalWinners.*"}\NormalTok{, }\KeywordTok{function}\NormalTok{(person, path) \{}
      \KeywordTok{let} \NormalTok{metal = }\FunctionTok{lastOf}\NormalTok{(path);}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{person}\NormalTok{.}\FunctionTok{name}\NormalTok{, }\StringTok{"won the"}\NormalTok{, metal, }
        \StringTok{"medal with a time of "}\NormalTok{, }\OtherTok{person}\NormalTok{.}\FunctionTok{time} \NormalTok{);}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Being loosely typed, Javascript does not enforce that ternary callbacks
are used as selection handlers. Before a callback is made the
application programmers must have provided a JSONPath selector
specifying the locations in the document that they are interested in.
The programmer will already be aware enough of the node location so for
most JSON formats the content alone will be sufficient, the API
purposefully orders the callback parameters so that in most cases a
unary function can be given.

Under Node.js the code style is more obviously event-based. Listeners
are normally added using an \texttt{.on} method where the event name is
a string given as the first argument. Adopting this style, Oboe's API
design also allows events to be added as:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/someJson.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{on}\NormalTok{( }\StringTok{"node"}\NormalTok{, }\StringTok{"medalWinners.*"}\NormalTok{, }\KeywordTok{function}\NormalTok{(person) \{}
   
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\StringTok{"Well done"}\NormalTok{, }\OtherTok{person}\NormalTok{.}\FunctionTok{name} \NormalTok{);}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

While allowing both styles creates an API which is larger than it needs
to be, the dual interface is designed to encourage adoption on the
client and server side. The two styles are similar enough that a person
familiar with one should be able to work with the other without
difficulty. Implementing the duplicative parts of the API should require
only a minimal degree of extra coding because they may be expressed in
common and specialised using partial completion. Because \texttt{'!'} is
the JSONPath for the root of the document, for some callback \texttt{c},
\texttt{.done(c)} is a equal to \texttt{.node('!', c)}. Likewise,
\texttt{.node} is easily expressible as a partial completion of
\texttt{.on} with \texttt{'node'}.

When making PUT, POST or PATCH requests the API allows the body to be
given as an object and serialises it as JSON because it is expected that
REST services which emit JSON will also accept it.

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doPost}\NormalTok{(}\StringTok{"http://example.com/people"}\NormalTok{, \{}
   \StringTok{"body"}\NormalTok{: \{}
      \StringTok{"name"}\NormalTok{:}\StringTok{"Arnold"}\NormalTok{, }\StringTok{"location"}\NormalTok{:}\StringTok{"Sealands"}
   \NormalTok{\}}
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

\subsection{Earlier callbacks when paths are found prior to
nodes}\label{earlier-callbacks-when-paths-are-found-prior-to-nodes}

Following the project's aim of giving callbacks as early as possible,
sometimes useful work can be done when a node is known to exist but
before we have the contents of the node. Under Oboe each node found in
the JSON document can potentially trigger notifications at two stages:
when it is first addressed and when it is complete. The API facilitates
this by providing a \texttt{path} event following much the same style as
\texttt{node}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"events.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{path}\NormalTok{( }\StringTok{"medalWinners"}\NormalTok{, }\KeywordTok{function}\NormalTok{() \{}
      \CommentTok{// We don"t know the winners yet but we know we have some }
      \CommentTok{// so let's start drawing the table:    }
      \OtherTok{gui}\NormalTok{.}\FunctionTok{showMedalTable}\NormalTok{();}
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{node}\NormalTok{( }\StringTok{"medalWinners.*"}\NormalTok{, }\KeywordTok{function}\NormalTok{(person, path) \{    }
      \KeywordTok{let} \NormalTok{metal = }\FunctionTok{lastOf}\NormalTok{(path);}
      \OtherTok{gui}\NormalTok{.}\FunctionTok{addPersonToMedalTable}\NormalTok{(person, metal);}
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{fail}\NormalTok{( }\KeywordTok{function}\NormalTok{()\{}
      \CommentTok{// That didn"t work. Revert!}
      \OtherTok{gui}\NormalTok{.}\FunctionTok{hideMedalTable}\NormalTok{();}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Implementing path notifications requires little extra code, only that
JSONPath expressions can be evaluated when items are found in addition
to when they are completed.

\subsection{Choice of streaming data
transport}\label{choice-of-streaming-data-transport}

As discussed in section \ref{browserstreamingframeworks}, current
techniques to provide streaming over HTTP encourage a dichotomous split
of traffic as either stream or download. This split is not a necessary
consequence of the technologies used and streaming may instead be viewed
as the most efficient means of downloading. Streaming services
implemented using push pages or websockets are not REST. Under these
frameworks a stream has a URL but the data in the stream is not
addressable. This is similar to STREST, the \emph{Service Trampled REST}
anti-pattern (Cragg 2006) in which HTTP URLs are viewed as locating
endpoints for services rather than the actual resources. Being
unaddressable, the data in the stream is also uncacheable: an event
which is streamed live cannot later, when it is historic, be retrieved
from a cache which was populated by the stream. Like SOAP, these
frameworks use HTTP as the underlying transport but do not follow HTTP's
principled design.

Although Oboe is not designed for live events, it is interesting to
speculate whether it could be used as a REST-compatible bridge to unify
live-ongoing feeds with ordinary REST resources. Consider a REST service
which gives per-constituency results for UK general elections. If
historic results are requested the data is delivered in JSON format much
as usual. Requesting the results for the current year on the night of
the election, an incomplete JSON with the constituencies known so far
would be immediately sent, followed by the remainder dispatched
individually as the results are called. When all results are known the
JSON would finally close leaving a complete resource. A few days later,
somebody wishing to fetch the results would use the \emph{same URL for
the historic data as was used on the night for the live data}. This is
possible because the URL refers only to the data that is required, not
to whether it is current or historic. Because it eventually forms a
complete HTTP response, the data that was streamed is not incompatible
with HTTP caching and a cache which saw the data while it was live could
later serve it from cache as historic. More sophisticated caches located
between client and service would recognise when a new request has the
same URL as an already ongoing request, serve the response received so
far, and then continue by giving both inbound requests the content as it
arrives from the already established outbound request. Hence, the
resource would be cacheable even while the election results are
streaming and a service would only have to provide one stream to serve
the same live data to multiple users fronted by the same cache. An
application developer programming with Oboe would not have to handle
live and historic data as separate cases because the node and path
events they receive are the same. Without branching, the code which
displays results as they are announced would automatically be able to
show historic data.

Taking this idea one step further, Oboe might be used for infinite data
which intentionally never completes. In principle this is not
incompatible with HTTP caching although more research would have to be
done into how well current caches handle requests which do not finish. A
REST service which provides infinite length resources would have to
confirm that it is delivering to a streaming client, perhaps with a
request header. Otherwise, if a non-streaming REST client were to use
the service it would try to get `all' of the data and never complete its
task.

Supporting only XHR as a transport unfortunately means that on older
browsers which do not fire progress events (section
\ref{xhrsandstreaming}) a progressive conceptualisation of the data
transfer is not possible. Streaming workarounds such as push tables will
not be used because they would result in a client which is unable to
connect to the majority of REST services. Degrading gracefully, the best
compatible behaviour is to wait until the document completes and then
interpret the whole content as if it were streamed. Because nothing is
done until the request is complete the callbacks will be fired later
than on a more capable platform but will have the same content and be in
the same order. By reverting to non-progressive AJAX on legacy
platforms, an application author will not have to write special cases
and the performance should be no worse than with traditional AJAX
libraries such as jQuery. On legacy browsers Oboe could not be used to
receive live data -- in the election night example no constituencies
would be shown until they had all been called.

One benefit of a unified model for streamed and finite-size content is
that it allows a simpler security model. Because the demands of the
transport are different, streaming security is usually implemented
separately from other HTTP requests. Schneier often argues that
``complexity is the worst enemy of security'' (Schneier 2000 Software
Complexity and Security) and in one online debate paints a buildings
analogy (Schneier and Harris 2013):

\begin{quote}
More specifically, simplicity tends to completely remove potential
avenues of attack. An easy example might be to think of a building.
Adding a new door is an additional complexity, and requires additional
security to secure that door. This leads to an analysis of door
materials, lock strength, and so on. The same building without that door
is inherently more secure, and requires no analysis or assumptions about
how it will be secured. Of course, this isn't to say that buildings with
doors are insecure, only that it takes more work to secure them. And it
takes more work to secure a building with ten doors than with one door.
\end{quote}

Unifying two means of data transfer into a single model is analogous to
a building having only one entrance. A better level of security should
be possible given the same effort taken to secure it.

Node's standard HTTP library provides a view of the response as a
standard ReadableStream so there will be no problems programming to a
streaming interpretation of HTTP. In Node because all streams provide a
common API regardless of their origin allowing arbitrary sources to be
read is no extra work. Although Oboe is intended primarily as a REST
client, under Node it will be capable of reading data from any source.
Oboe might be used to read from a local file, an ftp server, a
cryptography source, or the process's standard input.

\subsection{Handling transport
failures}\label{handling-transport-failures}

Oboe cannot know the correct behaviour when a connection is lost so this
decision is left to the containing application. Generally on request
failure one of two behaviours are expected: if the actions performed in
response to data so far remain valid in the absence of a full
transmission their effects will be kept and a new request made for just
the missed part; alternatively, if all the data is required for the
actions to be valid, the application should take an optimistic locking
approach and perform rollback.

\subsection{Oboe.js as a
micro-library}\label{oboe.js-as-a-micro-library}

HTTP traffic is often compressed using gzip so that it transfers more
quickly, particularly for entropy-sparse text formats such as
Javascript. When measuring a library's download footprint it usually
makes more sense to compare post-compression. For the sake of adoption
smaller is better because site creators are sensitive to the download
size of their sites. Javascript micro-libraries are listed at
\href{http://microjs.com}{microjs.com}, which includes this project. A
library qualifies as being \emph{micro} if it is delivered in 5kb or
less, 5120 bytes, but micro-libraries also tend to follow the ethos that
it is better for an application developer to gather together several
tiny, simple libraries than find a complex one which aims to solve many
problems. As well as being small, a micro-library should impose as few
restrictions as possible on its use and be agnostic as to which other
libraries or programming styles it will be combined with, echoing the
UNIX philosophy for small, easily combined programs (McIlroy 1978).

\begin{quote}
This is the Unix philosophy:\\Do one thing and do it well.\\Write
programs to work together.\\Write programs to handle text streams,
because that is a universal interface.
\end{quote}

\section{Implementation}\label{implementation}

\subsection{Componentisation of the
project}\label{componentisation-of-the-project}

\begin{figure}[htbp]
\centering
\includegraphics{images/overallDesign.png}
\caption{\textbf{Major components of Oboe.js illustrating program flow
from HTTP transport to application callbacks.} UML facet/receptacle
notation is used to show the flow of events and event names are given in
capitals. For clarity events are depicted as transferring directly
between publisher and subscriber but this is actually performed through
an intermediary. \label{overallDesign}}
\end{figure}

Oboe's architecture describes a fairly linear pipeline visiting a small
number of tasks between receiving HTTP content and notifying application
callbacks. The internal componentisation is designed primarily so that
automated testing can provide a high degree of confidence regarding the
correct working of the library. A local event bus facilitates
communication inside an Oboe instance and most components interact
solely by using this bus: receiving events, processing them, and
publishing further events in response. The use of an event bus removes
the need for each unit to locate other units before it may listen to
their output, giving a highly decoupled shape to the library in which
each part knows the events it requires but not who publishes them. Once
everything is wired into the bus no central control is required and the
larger behaviours emerge as a consequence of the interactions between
finer ones.

\subsection{Design for automated
testing}\label{design-for-automated-testing}

\begin{figure}[htbp]
\centering
\includegraphics{images/testPyramid.png}
\caption{\textbf{The test pyramid}. Many tests specify the low-level
components, fewer on their composed behaviours, and fewer still on a
whole-system level. \label{testpyramid}}
\end{figure}

80\% of the code written for this project is test specification. Because
the correct behaviour of a composition requires the correct behaviour of
its components, the majority are \emph{unit tests}. The general style of
a unit test is to plug the item under test into a mock event bus and
check that when it receives certain input events the expected output
events are consequently published.

The \emph{Component tests} step back from examining individual
components to a position where their behaviour in composition may be
examined. Because the compositions are quite simple there are fewer
component tests than unit tests. The component tests do not take account
of how the composition is drawn and predominantly examine the behaviour
of the library through its public API. One exception is that the
streamingXHR component is switched for a stub so that HTTP traffic can
be simulated.

At the apex of the test pyramid are a small number of \emph{integration
tests}. These verify Oboe as a black box without any knowledge of, or
access to, the internals, using the same API as is exposed to
application programmers. These tests are the most expensive to write but
a small number are necessary in order to verify that Oboe works
correctly end-to-end. HTTP traffic cannot be faked without access to the
internals so before these tests are performed a corresponding REST
service is started. This test service is written using Node and returns
known content progressively according to predefined timings, somewhat
emulating a slow internet connection. The integration tests particularly
verify behaviours where platform differences could cause
inconsistencies. For example, the test URL \texttt{/tenSlowNumbers}
writes out the first ten natural numbers as a JSON array at a rate of
four per second. The test registers a JSONPath selector that matches the
numbers against a callback that aborts the HTTP request on seeing the
fifth. The correct behaviour is to get no sixth callback, even when
running on a platform lacking support for XHR2 where all ten will have
already been downloaded.

Confidently black-box testing a stateful unit is difficult. Because of
side-effects and hidden state we can only rely on inductive reasoning to
say that similar future calls won't later result in different
behaviours. Building up the parse result from SAX events is a fairly
complex process which cannot be implemented efficiently using wholly
side-effect free Javascript. To promote testability the state is
delegated to a simple state-storing unit. The intricate logic may then
be expressed as a separately tested set of side-effect free functions
which transition between one state and the next. For whichever results
the functions give while under test, uninfluenced by state one may be
confident that they will later yield the same result if given the same
input. The separate unit to maintain the state has exactly one
responsibility, to hold the incremental parse output between function
calls, and is trivial to test. This approach slightly breaks with the
object oriented principle of encapsulation by hiding state behind the
logic which acts on it but the departure will be justified if a more
testable codebase promotes greater reliability.

To enhance testability Oboe has also embraced dependency injection.
Components do not instantiate their dependencies but rather rely on them
being passed in by an inversion of control container during the wiring
phase. For example, the network component which hides browser
differences does not know how to create the underlying XHR that it
adapts. Undoubtedly, by not instantiating its own transport this
component presents a less friendly interface: its data source is no
longer a hidden implementation detail but exposed as a part of its API
as the responsibility of the caller. This disadvantage is mitigated by
the interface being purely internal. Dependency injection allows the
tests to be written more simply because it is easy to substitute the
real XHR for a stub. Unit tests should test exactly one unit; were the
streaming HTTP object to create its own transport, the XHR would also be
under test, plus whichever external service it connects to. Because
Javascript allows redefinition of built in types the stubbing could have
also been done by overwriting the XHR constructor to return a mock.
However this is to be avoided as it opens up the possibility of changes
to the environment leaking between test cases.

\subsection{Running the tests}\label{running-the-tests}

The Grunt task runner (Alman 2012) is used to automate routine tasks
such as executing the tests and building, configured so that the unit
and component tests run automatically whenever a change is made to a
source file or specification. As well as executing correctly, the
project is required not to surpass a certain size so this also checked
on every save. Because Oboe is a small, tightly focused project the
majority of the programming time is spent refactoring already working
code. Running tests on save provides quick feedback so that mistakes are
found before the programmer is thinking about the next context. Agile
practitioners emphasise the importance of tests that execute quickly
(Martin 2008 p.314:T9) -- Oboe's 220 unit and component tests run in
less than a second so discovering programming mistakes is nearly
instant. If the ``content of any medium is always another medium''
(McLuhan 1964 p.8), we might say that the content of programming is the
process that is realised by its execution. A person working in a
physical medium sees the thing they are making but the programmer does
usually not see their program's execution simultaneously as they create.
Conway notes that an artisan works by transform-in-place ``start with
the working material in place and you step by step transform it into its
final form,'' but software is created through proxies. He attempts to
close this gap by merging programming with the results of programming
(Conway 2004 pp.8-9). If we bring together the medium and the message by
viewing the result of code while we write it, we can build in a series
of small, iterative, correct steps and programming can be more
explorative and expressive. Running the tests subtly, automatically
hundreds of times per day isn't merely convenient, this build process
noticeably improved the quality of the project's programming.

Integration tests are not run on save. They intentionally simulate a
slow network so by the time they complete a programmer will have already
context-switched to the next micro-task. Oboe's source is version
controlled using git and hosted on Github. The integration tests are
used as the final check before a branch in git is merged into the
master.

\subsection{Packaging to a single distributable
file}\label{packaging-to-a-single-distributable-file}

As an interpreted language Javascript may be run without any prior
compilation. Directly running the files that are open in the editor is
convenient while programming but unless a project is written as a single
file in practice some build phase is required to create an easily
distributable form. Dependency managers have not yet become standard for
client-side web development so dependant libraries are usually manually
downloaded. For a developer wishing to include Oboe in their own project
a single file is much more convenient than the multi-file raw source. If
they are not using a similar build process on their site, a single file
is also faster to transfer to their users, mostly because the HTTP
overhead is of constant size per request.

Javascript files are interpreted in series by the browser so load-time
dependencies must precede dependants. If several valid Javascript files
are concatenated in the same order as delivered to the browser the
joined version is functionally equivalent to the individual files. This
is a common technique so that code can be written and debugged as many
files but distributed as one. Several tools exist to automate this stage
of the build process that topologically sort the dependency graph before
concatenation in order to find a suitable script order.

Early in the project Require.js (Burke 2011) was chosen for this task.
Javascript doesn't have a built in import statement; Require adds one
from inside the language as an asynchronous \texttt{require} function.
Calls to \texttt{require} AJAX in and execute the imported source,
passing any exported items to the given callback. For non-trivial
applications loading each dependency individually over AJAX is intended
only for debugging because making so many requests is slow. For
efficient delivery Require provides the \texttt{optimise} command which
concatenates an application into a single file by using static analysis
to deduce a workable source order. Because the \texttt{require} function
may be called from anywhere, this is undecidable in the general case so
when a safe concatenation order cannot be found Require falls back to
lazy loading. In practice this isn't a problem because imports are
generally not subject to branching. For larger webapps lazy loading is
actually a feature because it speeds up the initial page load. The
technique of \emph{Asynchronous Module Definition}, AMD intentionally
imports rarely-loaded modules in response to events; by resisting static
analysis the dependant Javascript will not be downloaded until it is
needed. AMD is mostly of interest to applications with a central hub but
also some rarely used parts. For example, most visits to online banking
will not need to create standing orders so it is better if this part is
loaded on-demand rather than increase the initial page load time.

Require's \texttt{optimise} was originally chosen to automate the
creation of a combined Javascript file for Oboe. Oboe would not benefit
from AMD because everybody who uses it will need all of the library but
using Require to find a working source order would avoid having to
manually implement one. Unfortunately this was not feasible. Even after
optimisation, Require's design necessitates that calls to the
\texttt{require} function are left in the code and that the Require
run-time component is available to handle them. At more than 5k gzipped
this would have more than doubled Oboe's download footprint. With about
15 source files and a fairly sparse dependency graph, finding a working
order on paper proved a simpler task than integrating with tools
offering to automate the process. After finding a Grunt plugin analogous
to the unix \texttt{cat} command it was trivial to create a build
process which produces a distributable library while requiring no
dependency management code to be loaded at run-time.

For future consideration there is Browserify (Browserling Inc. 2012).
This library reverses the `browser first' Javascript mindset by viewing
Node as the primary target for Javascript development and adapting the
browser environment to match. Browserify converts applications written
for Node into a single file packaged for delivery to a web browser.
Significantly, other than adaptors wrapping browser APIs in the call
style of their Node equivalents, Browserify leaves no trace of itself in
the final Javascript. When run on browsers supporting progress events
Browserify's HTTP adaptor\footnote{\url{https://github.com/substack/http-browserify}}
presents XHRs using Node's streaming interface so it should be capable
of adapting the Node version of Oboe to run under modern browsers.

Javascript source can be made significantly smaller by
\emph{minification} techniques such as reducing scoped symbols to a
single character or deleting the comments. For Oboe the popular minifier
library Uglify (Bazon 2010) was chosen. Uglify performs only surface
optimisations, concentrating mostly on producing compact syntax by
manipulating the code's abstract syntax tree. Google Closure Compiler
(Google 2009), a more sophisticated optimiser which leverages a deeper
understanding of the program, would be an alternative option.
Unfortunately, proving equivalence in highly dynamic languages is often
impossible and Closure Compiler is only safe given a well-advised subset
of Javascript. It delivers no reasonable guarantee of equivalence if
code is not written as the Closure team expected. Integration tests
would catch any such failures but for the time being it was decided that
even constrained by micro-library size limits, a slightly larger file is
a worthwhile tradeoff for a safer build process.

\subsection{Styles of programming}\label{styles-of-programming}

Oboe does not follow any single paradigm and is written as a mix of
procedural, functional and object-oriented programming styles. Classical
object orientation is used only so far as the library exposes an OO
public API. Although Javascript supports them, classes and constructors
are not used, nor is there any inheritance or notable polymorphism.
Closures form the primary means of data storage and hiding. Most
entities do not give a Javascript object on instantiation, they are
constructed as a set of event handlers attached to the central bus
which, as inner-functions inside the same outer function, share access
to values caught in a common closure. From outside the closure the
values are not only private as would be seen in a Java-style OO model,
they are inherently unaddressable.

Although not following an established object-oriented metamodel, the
high-level componentisation hasn't departed very far from how the
project might be divided following that style and OO design patterns
have influenced the layout considerably. If we wished to think in terms
of the OO paradigm we might say that values trapped inside closures are
private attributes and that the handlers registered on the event bus are
public methods. In this regard the high-level internal design of Oboe
can be discussed using the terms from a more standard object oriented
metamodel.

Even where it creates a larger final deliverable, short functions that
can be combined to form longer ones have been generally preferred.
Writing a program using short functions reduces the size of the minimum
testable unit and because each test specifies a very small unit of
functionality, encourages the writing of very simple unit tests. When
the tests are simple there is less room for unanticipated cases to hide.
Due to pressures on code size a general purpose functional library was
not chosen, one was created containing only the necessary functions
(\hyperref[headerux5ffunctional]{functional.js}, Appendix
p.\pageref{src_functional}). Functional programming in Javascript is
known to be slower than other styles, particularly in Firefox which
lacks optimisations such as Lambda Lifting (Guo 2013) but the effect
should be insignificant, particularly when considered alongside the
performance advantages that streaming I/O offers. Because of its
single-threaded execution model, in the browser any Javascript is run
during script execution frames, interlaced with frames for other
concurrent concerns. To minimise the impact on other concerns such as
rendering it is important that no task occupies the CPU for very long.
Since most monitors refresh at 60Hz, about 16ms is a fair target for the
maximum duration of a browser script frame. In Node no limit can be
implied from a display but any CPU-hogging task degrades the
responsiveness of concurrent work. Switching tasks is cheap so
effectively sharing the CPU prefers many small execution frames over a
few larger ones. Whether running in a browser or server, the bottleneck
is more often I/O than processing speed; providing no task contiguously
holds the CPU for an unusually long time an application can usually be
considered fast enough. Oboe's progressive model favours sharing because
it naturally splits the work over many execution frames which by a
non-progressive mode would be performed during a single frame. Although
the overall CPU time will be higher, Oboe should share the processor
more cooperatively and because of better I/O management the overall
system responsiveness should be improved.

\subsection{Incrementally building the parsed
content}\label{incrementally-building-the-parsed-content}

As shown in figure \ref{overallDesign} on page \pageref{overallDesign},
there is an \emph{incremental content builder} and \emph{ascent tracer}
which handle SAX events from the Clarinet JSON parser. By presenting to
the controller a simpler interface than is provided by Clarinet, taken
together these might be considered as an Adaptor pattern, albeit
modified to be event-driven rather than call-driven: we receive six
event types and in response emit from a vocabulary of two,
\texttt{NODE\_FOUND} and \texttt{PATH\_FOUND}. The events received from
Clarinet are low level, reporting the sequence of tokens in the markup;
those emitted are at a much higher level of abstraction, reporting the
JSON nodes and paths as they are discovered. Testing a JSONPath
expression for a match against any particular node requires the node
itself, the path to the node, and the ancestor nodes. For each newly
found item in the JSON this information is delivered as the payload of
the two event types emitted by the content builder. When the callback
adaptors receive these events they have the information required to test
registered patterns for matches and notify application callbacks if
required.

\begin{figure}[htbp]
\centering
\includegraphics{images/ascent.png}
\caption{\textbf{List representation of an ascent rising from leaf to
root through a JSON tree.} Note the special ROOT value which represents
the location of the pathless root node. The ROOT value is an object,
taking advantage of object uniqueness to ensure that its location is
unequal to all others. \label{ascent}}
\end{figure}

The path to the current node is maintained as a singly linked list in
which each item holds the node and the field name that links to the node
from its parent. The list and the items it contains are immutable,
enforced in newer Javascript engines by using frozen objects.\footnote{See
  \url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global/_Objects/Object/freeze}.
  Although older engines don't provide any ability to create immutable
  objects, we can be fairly certain that the code does not mutate these
  objects or the tests would fail with attempts to modify in
  environments which are able to enforce it.} The list is arranged as an
ascent with the current node at the near end and the root at the far
end. Although paths are typically written as a \emph{descent}, ordering
as an \emph{ascent} is more efficient because every SAX event can be
processed in constant time by adding to or removing from the head of the
list. For familiarity, where paths are passed to application callbacks
they are first reversed and converted to arrays.

For each Clarinet event the builder provides a corresponding handler
which, working from the current ascent, returns the next ascent after
the event has been applied. For example, the \texttt{openobject} and
\texttt{openarray} event types are handled by adding a new item at the
head of the ascent but for \texttt{closeobject} and \texttt{closearray}
one is removed. Over the course of parsing a JSON resource the ascent
will in this way be manipulated to visit every node, allowing each to be
tested against the registered JSONPath expressions. Internally, the
builder's handlers for SAX events are declared as the combination of a
smaller number of basic reusable parts. Several of Clarinet's event
types differ only by the type of the node that they announce but Oboe is
largely unconcerned regarding a JSON node's type. On picking up
\texttt{openobject} and \texttt{openarray} events, both pass through to
the same \texttt{nodeFound} function, differing only in the type of the
node which is first created. Similarly, Clarinet emits a \texttt{value}
event when a string or number is found in the markup. Because primitive
nodes are always leaves the builder treats them as a node which
instantaneously starts and ends, handled programmatically as the
composition of the \texttt{nodeFound} and \texttt{nodeFinished}
functions.

Although the builder functions are stateless and side-effect free,
between SAX events the current ascent needs to be stored. This is
handled by the ascent tracker which serves as a holder for this data.
Starting with the ascent initialised as the empty list, on receiving a
SAX event it passes the ascent to the handler and stores the result so
that when the next SAX event is received the updated ascent can be given
to the next handler.

Linked lists were chosen for the ascents in preference to the more
conventional approach of using native Javascript arrays for several
reasons. A program is easier to test and debug given immutable data but
employing the native Arrays without mutating would be very expensive
because on each new path the whole array would have to be copied. During
debugging, unpicking a stack trace holding immutable data requires less
mental stress because every value revealed is the value that has always
occupied that space and the programmer does not have to project along
the time axis by imagining which values were in the same space earlier
or might be there later. The lack of side effects means that new
commands may be tried during a pause in execution without worrying about
breaking the working of the program. In terms of speed, array-type
structures are poorly suited to frequent growing and shrinking so for
tracking ascents whose length changes with every event received, arrays
are relatively unperformant. Taking into account the receiver of the
ascent data, lists are also a convenient format for the JSONPath engine
to match against as will be discussed in the next section. The
Javascript file \hyperref[headerux5flists]{lists.js} (Appendix
p.\pageref{src_lists}) implements various list functions: \texttt{cons},
\texttt{head}, \texttt{tail}, \texttt{map}, \texttt{foldR},
\texttt{all}, \texttt{without} as well as providing conversions to and
from arrays.

\subsection{Oboe JSONPath
implementation}\label{oboe-jsonpath-implementation}

With the initial commit the JSONPath implementation was little more than
a series of regular expressions\footnote{JSONPath compiler from the
  first commit can be found at line 159 here:
  \url{https://github.com/jimhigson/oboe.js/blob/a17db7accc3a371853a2a0fd755153b10994c91e/src/main/progressive.js}\#L159
  for contrast, the current source can be found
  \hyperref[jsonPath.js]{in the appendix} on page \pageref{src_jsonPath}
  or at
  \url{https://github.com/jimhigson/oboe.js/blob/master/src/jsonPath.js}}
but has slowly evolved into a featureful and efficient implementation. A
total rewriting was possible because the correct behaviour is well
defined by test specifications\footnote{The current tests are viewable
  at
  \url{https://github.com/jimhigson/oboe.js/blob/master/test/specs/jsonPath.unit.spec.js}
  and
  \url{https://github.com/jimhigson/oboe.js/blob/master/test/specs/jsonPathTokens.unit.spec.js}}.
The JSONPath compiler exposes a single higher-order function. This
function takes the JSONPath as a string and, proving it is a valid
expression, returns a function which tests for matches to the pattern.
The type is difficult to express in Javascript but expressed as Haskell
would be:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{String} \OtherTok{->} \DataTypeTok{Ascent} \OtherTok{->} \DataTypeTok{JsonPathMatchResult}
\end{Highlighting}
\end{Shaded}

The match result is either a hit or a miss. If a hit, the return value
is the node captured by the match. Should the pattern have an explicitly
capturing clause the node corresponding to that clause is captured,
otherwise it is the node at the head of the ascent. Implementation as a
higher-order function was chosen even though it might have been simpler
to create a first-order version as seen in the original JSONPath
implementation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{String}\NormalTok{, }\DataTypeTok{Ascent}\NormalTok{) }\OtherTok{->} \DataTypeTok{JsonPathMatchResult}
\end{Highlighting}
\end{Shaded}

This version was rejected because the pattern string would be freshly
reinterpreted on each evaluation, repeating computation unnecessarily.
Because a pattern is registered once but then evaluated perhaps hundreds
of times per JSON file the most pressing performance consideration is
for matching to execute quickly. The extra time needed to compile a
pattern when new application callbacks are registered is relatively
insignificant because it is performed much less often.

The compilation is performed by recursively examining the left-most side
of the string for a JSONPath clause. For each clause type there is a
function which tests ascents for that clause, for example by checking
the field name; by partial completion the field name function would be
specialised to match against one particular name. Having generated a
function to match against the left-most clause, compilation continues
recursively by passing itself the remaining unparsed right-side of the
string, which repeats until the terminal case where there is nothing
left to parse. On each recursive call the clause function generated
wraps the result from the last recursive call, resulting ultimately in a
concentric series of clause functions. The order of these functions
mirrors the ordering of paths as an ascent, so that the outermost
function matches against the node at the near end of the ascent, and the
innermost against the far end. When evaluated against an ascent, each
clause function examines the head of the list and, if it matches, passes
the list onto the next function. A special clause function,
\texttt{skip1} is used for the \texttt{.} (parent) syntax and places no
condition on the head of the list, unconditionally passing the tail on
to the next clause, thus moving matching on to the parent node.
Similarly, there is a function \texttt{skipMany} which maps onto the
\texttt{..} (ancestor) syntax and recursively consumes the minimum
number of ascent items necessary for the next clause to match or fails
if this cannot be done. In this way, we peel off layers from the ascent
as we move through the function list until we either exhaust the
functions, indicating a match, or cannot continue, indicating a fail.

This JSONPath implementation allows the compilation of complex
expressions into an executable form by combining many very simple
functions. As an example, the pattern
\texttt{!.\$person..\{height tShirtSize\}} once compiled would resemble
the Javascript functional representation below:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{statementExpr}\NormalTok{(             }\CommentTok{// outermost wrapper, added when JSONPath }
                           \CommentTok{//    is zero-length }
   \FunctionTok{duckTypeClause}\NormalTok{(         }\CommentTok{// token 5, \{height tShirtSize\}}
      \FunctionTok{skipMany}\NormalTok{(            }\CommentTok{// token 4, '..', ancestor relationship }
         \FunctionTok{capture}\NormalTok{(          }\CommentTok{// token 3, '$' from '$person'}
            \FunctionTok{nameClause}\NormalTok{(    }\CommentTok{// token 3, 'person' from '$person'}
               \FunctionTok{skip1}\NormalTok{(      }\CommentTok{// token 2, '.', parent relationship}
                  \NormalTok{rootExpr }\CommentTok{// token 1, '!', matches only the root}
               \NormalTok{) }
            \StringTok{'person'} \NormalTok{)}
         \NormalTok{)}
   \NormalTok{), [}\StringTok{'height'}\NormalTok{, }\StringTok{'tShirtSize'}\NormalTok{])}
\NormalTok{)      }
\end{Highlighting}
\end{Shaded}

Because the matching is implemented using a side-effect free subset of
Javascript it would be safe to use a functional cache. As well as saving
time by avoiding repeated execution this could potentially also save
memory because where two JSONPath strings contain a common left side
they could share the inner part of their functional expression. Given
the patterns \texttt{!.animals.mammals.human} and
\texttt{!.animals.mammals.cats}, the JSONPath engine will currently
create two identical evaluators for \texttt{!.animals.mammals}.
Likewise, while evaluating several sibling elements against a pattern
that requires matches at multiple depths in the JSON hierarchy, the same
JSONPath term evaluator\\will be tested many times against the parent
element, always with the same result. Although Javascript doesn't come
with functional caching, it can be added using the language itself,
probably the best known example being \texttt{memoize} from
Underscore.js (Ashkenas 2008). It is likely however that hashing the
function parameters would be slower than performing the matching.
Although the parameters are all immutable and could in theory be hashed
by object identity, in practice there is no way to access an object ID
from inside the language so any hash function for a node parsed out of
JSON would have to walk the entire subtree rooted from that node,
requiring time proportional to the size of the tree. Current Javascript
implementations also make it difficult to manage caches in general from
inside the language because there is no way to occupy only spare memory.
Weak references are proposed in the ECMAScript 6th edition draft
(Harmony 2013) but currently only experimentally supported\footnote{At
  time of writing, Firefox is the only engine supporting WeakHashMap by
  default. In Chome it is implemented but not available to Javascript
  unless explicitly enabled by a browser flag.
  \url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global/_Objects/WeakMap}
  retrieved 11th October 2013}. If the hashing problem were solved the
WeakHashMap would be ideal for adding functional caching in future.

Functions describing the tokenisation of the JSONPath language are given
their own source file and tested independently of the compilation.
Regular expressions are used because they are the simplest form able to
express the clause patterns. Each regular expression starts with
\texttt{\^{}} so that they only match at the head of the string, the `y'
flag would be a more elegant alternative but as of now this lacks wider
browser support\footnote{\url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular/_Expressions}}.
By verifying the tokenisation functions through their own tests it is
simpler to create thorough specification because the tests may focus on
the tokenisation more clearly without having to observe its results
though another layer. For JSONPath matching we might consider the unit
test layer of the test pyramid (figure \ref{testpyramid},
p.\pageref{testpyramid}) to be split into two further sub-layers.
Arguably, the upper of these sub-layers is not a unit test because it is
verifying more than one unit, the tokeniser and the compiler, and there
is some redundancy since the tokenisation is tested both independently
and through a proxy. A more purist approach would stub out the tokeniser
functions before testing the compiled JSONPath expressions. This would
certainly be a desirable if a general purpose compiler generator were
being implemented but since the aim of the code is to work with only one
language, removing the peculiarities of the language from the test would
only decrease their effectiveness as an indicator of correct
interpretation.

One limitation is that Oboe currently only supports selections which are
decidable at the time that the candidate node is discovered. This
forbids some seemingly simple selections such as \emph{the last element
of the array} because when an element is found, without looking ahead
and possibly finding an array closing token we cannot know if our node
is the last element. Removing this restriction would require a fairly
substantial rewrite of the JSONPath engine. One strategy would be to
take an event-driven approach to the matching. At present matching is
triggered by events but the tests themselves are expressed
synchronously. Under an event-driven matching implementation, instead of
returning a value, each JSONPath term evaluator would be given a
callback to pass the result to. Under most circumstances it should be
able to decide if a match has taken place at the time that it is called,
handing the result immediately to the callback. However, for cases where
more of the document must be revealed before a match can be decided the
term evaluators would have the option of listening to the parse until
further document nodes are revealed, replying later when the necessary
information is available. Luckily, a language with just the selectors
that we able to evaluate when nodes are found is powerful enough to
handle most cases so until a strong need is demonstrated the selector
language will be kept in its curernt, relatively simple form.

\subsection{Differences in the working of programs that can be easily
written using
Oboe.js}\label{differences-in-the-working-of-programs-that-can-be-easily-written-using-oboe.js}

Because of assumptions implicit in either technique, a program written
using Oboe.js will perform subtly different actions from one written
using more conventional libraries, even if the programmer means to
express the same thing. Consider the two examples below in which Node.js
is used to read a local JSON file and write to the console.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{( }\OtherTok{fs}\NormalTok{.}\FunctionTok{createReadStream}\NormalTok{( }\StringTok{"/home/me/secretPlans.json"} \NormalTok{) )}
   \NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{"node"}\NormalTok{, \{}
      \StringTok{"schemes.*"}\NormalTok{: }\KeywordTok{function}\NormalTok{(scheme)\{}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Aha!"}\NormalTok{, scheme);}
      \NormalTok{\},}
      \StringTok{"plottings.*"}\NormalTok{: }\KeywordTok{function}\NormalTok{(deviousPlot)\{}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Hmmm!,"} \NormalTok{deviousPlot);}
      \NormalTok{\}   }
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{"done"}\NormalTok{, }\KeywordTok{function}\NormalTok{()\{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"*twiddles mustache*"}\NormalTok{);}
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{"fail"}\NormalTok{, }\KeywordTok{function}\NormalTok{()\{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Drat! Foiled again!"}\NormalTok{);   }
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{fs}\NormalTok{.}\FunctionTok{readFile}\NormalTok{(}\StringTok{"/home/me/secretPlans.json"}\NormalTok{, }\KeywordTok{function}\NormalTok{( err, plansJson )\{     }
   \KeywordTok{if}\NormalTok{( err ) \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Drat! Foiled again!"}\NormalTok{);}
      \KeywordTok{return}\NormalTok{;}
   \NormalTok{\}}
   \KeywordTok{var} \NormalTok{plans = }\OtherTok{JSON}\NormalTok{.}\FunctionTok{parse}\NormalTok{(err, plansJson);}
   
   \OtherTok{plans}\NormalTok{.}\OtherTok{schemes}\NormalTok{.}\FunctionTok{forEach}\NormalTok{(}\KeywordTok{function}\NormalTok{( scheme )\{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Aha!"}\NormalTok{, scheme);   }
   \NormalTok{\});   }
   \OtherTok{plans}\NormalTok{.}\OtherTok{plottings}\NormalTok{.}\FunctionTok{forEach}\NormalTok{(}\KeywordTok{function}\NormalTok{(deviousPlot)\{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Hmmm!"}\NormalTok{, deviousPlot);}
   \NormalTok{\});}
      
   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"*twiddles mustache*"}\NormalTok{);   }
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

While the behaviours intended by the programmer are similar, some
accidental side-behaviours differ between the two. It is likely that
most programmers would not think of these differences as they write so
it is important that they are not destructive. In the first example the
order of the output for schemes and plans will match their order in the
JSON, whereas for the second scheming is always done before plotting.
The error behaviours are also different -- the first prints until it has
an error, the second prints if there are no errors. In the second
example it is \emph{almost mandatory} to check for errors before
starting the output whereas in the first it feels most natural to
register the error listener at the end of the chained calls. It is
unusual in describing a system's desirable behaviour to state the
reaction to abnormal cases first so I find that the Oboe example follows
the more natural ordering.

Considering the code style that is encouraged, the first example takes a
more declarative form by specifying the items of interest using patterns
whereas the second is more imperative by explicitly looping through the
items. If several levels of selection were required, such as
\texttt{schemes.*.steps.*}, other than a longer JSONPath pattern the
first example would not grow in complexity whereas the second would
require nested looping. The cyclic complexity of programming using Oboe
would stay roughly constant whereas using programmatic drill-down it
increases linearly with the number of levels that must be traversed.

\section{Conclusion}\label{conclusion}

\subsection{Benchmarking vs non-progressive
REST}\label{benchmarking-vs-non-progressive-rest}

I feel it is important to experimentally answer the question, \emph{is
this way actually any faster?} To measure performance the Oboe
repository contains a small benchmarking suite that runs under Node.js.
One of the advantages of incremental parsing suggested in the
introduction was a perceptual improvement in speed. The experiments do
not directly gauge user perception because it would require subjective
judgement and human participants, an undertaking large enough to be a
project in itself. In lieu of perceptual experiments the benchmarks
measure the time taken to provide the first output. This correlates with
how quickly the first interface elements may be drawn and should be a
good proxy indicator of perceptual speed. Node is used to host the tests
because it is a minimalist platform and should give repeatable results
whereas browsers may be running any number of simultaneous background
tasks and are less predictable. Node also has the advantage that small
changes in memory use are not overwhelmed by a memory hungry
environment.

The benchmark involves two node processes, one acting as a REST client
and the other as a REST server, mimicking a service backed by a
relational database. Relational database client libraries pass data from
a result cursor one tuple at a time to be used by the application, the
service simulates this by writing out forty tuples as JSON objects, one
every ten milliseconds. Half the tuples contain a URL to a further
resource which will also be fetched so that an aggregation can be
created. To simulate real network conditions, Apple's \emph{Network Line
Conditioner} was used with the presets \emph{3G, Average Case} and
\emph{Cable modem} to represent poor and good internet connections
respectively. Three client versions were implemented using JSON.parse
DOM-style parsing, Clarinet SAX-style parsing and Oboe. Memory was
measured on the client using Node's built in memory reporting tool,
\texttt{process.memoryusage()} and the largest figure reported during
each run is taken. The test server and client can be found in the
project's \texttt{benchmark} directory, or in the appendix on pages
\ref{src_benchmarkClient} and \ref{src_benchmarkServer}.

\begin{longtable}[c]{@{}llrrr@{}}
\hline\noalign{\medskip}
Client Strategy & Network & First output & Total time & Max. Memory
\\\noalign{\medskip}
\hline\noalign{\medskip}
Oboe.js & Good & 40ms & 804ms & 6.2Mb
\\\noalign{\medskip}
Oboe.js & Poor & 60ms & 1,526ms & 6.2Mb
\\\noalign{\medskip}
JSON.parse & Good & 984ms & 1,064ms & 9,0Mb
\\\noalign{\medskip}
JSON.parse & Poor & 2550ms & 2,609ms & 8.9Mb
\\\noalign{\medskip}
Clarinet & Good & 34ms & 781ms & 5.5Mb
\\\noalign{\medskip}
Clarinet & Poor & 52ms & 1,510ms & 5.5Mb
\\\noalign{\medskip}
\hline
\end{longtable}

In comparison with JSON.parse, Oboe shows a dramatic improvement of
about 96\% regarding the time taken for the first output to be produced
and a smaller but significant improvement of about 40\% in the total
time required to create the aggregation. Oboe's aggregation on a good
network is about 15\% slower than Clarinet; since Oboe depends on
Clarinet for parsing it could not be faster but I had hoped for the gap
to be smaller.

Clarinet is known to be slower than JSON.parse for input which is
already held in memory (Job 2012) but when reading from a stream this is
more than offset by the ability to parse progressively. Compared to
JSON.parse, the extra computation time needed by Oboe and Clarinet is
shown to be relatively insignificant in comparison to the advantage of
better I/O management. Reacting earlier using slower handlers is shown
to be faster overall than reacting later with quicker ones. I feel that
this vindicates a project focus on efficient management of I/O over
faster algorithms.

Oboe shows an unexpected improvement in terms of memory usage compared
to JSON.parse. It is not clear why this would be but it may be
attributable to the large dependency tree brought in by the get-json
(NPM 2013) library used in the JSON.parse client version. As expected,
Clarinet has the smallest memory usage because it never stores a
complete version of the parsed JSON. Clarinet's memory usage remains
roughly constant as the parsed resource increases in size while the
other two will rise linearly. Node is popular on RaspberryPi type
devices with constrained RAM and Clarinet might be preferable to Oboe
where code clarity is less important than a small memory footprint.

\subsection{Comparative developer
ergonomics}\label{comparative-developer-ergonomics}

Writing less code is not in itself a guarantee of a better developer
ergonomics but it is a good indicator so long as the program isn't
forced to be overly terse. The table below reports the quantity of code
required to implement the benchmark REST client under each strategy.
Each version is written in the most natural expression for the library
used.

\begin{longtable}[c]{@{}lrr@{}}
\hline\noalign{\medskip}
Strategy & Code Required (lines) & Code required (chars)
\\\noalign{\medskip}
\hline\noalign{\medskip}
Oboe.js & 3 & 64
\\\noalign{\medskip}
JSON.parse & 5 & 102
\\\noalign{\medskip}
Clarinet & 30 & lots!
\\\noalign{\medskip}
\hline
\end{longtable}

Oboe was the shortest:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(DB_URL).}\FunctionTok{node}\NormalTok{(}\StringTok{'\{id url\}.url'}\NormalTok{, }\KeywordTok{function}\NormalTok{(url)\{}
   \FunctionTok{oboe}\NormalTok{(url).}\FunctionTok{node}\NormalTok{(}\StringTok{'name'}\NormalTok{, }\KeywordTok{function}\NormalTok{(name)\{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(name);               }
   \NormalTok{\});      }
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Non-progressive parsing with JSON.parse was slightly longer, requiring a
loop and an if statement, both necessary to drill down into the results.
The code below is shortened by using get-json package which combines
parsing implicitly with the download:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{getJson}\NormalTok{(DB_URL, }\KeywordTok{function}\NormalTok{(err, records) \{}
   \OtherTok{records}\NormalTok{.}\OtherTok{data}\NormalTok{.}\FunctionTok{forEach}\NormalTok{( }\KeywordTok{function}\NormalTok{( record )\{}
      \KeywordTok{if}\NormalTok{( }\OtherTok{record}\NormalTok{.}\FunctionTok{url} \NormalTok{) \{}
         \FunctionTok{getJson}\NormalTok{(}\OtherTok{record}\NormalTok{.}\FunctionTok{url}\NormalTok{, }\KeywordTok{function}\NormalTok{(err, record) \{}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\OtherTok{record}\NormalTok{.}\FunctionTok{name}\NormalTok{);}
         \NormalTok{\});}
      \NormalTok{\}}
   \NormalTok{\});}
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

This version is tightly coupled with the JSON format that it reads. We
can see this in the fragments \texttt{records.data},
\texttt{record.url}, and \texttt{record.name} which will only work if
they find the desired subtree at exactly the anticipated location. The
code might be said to contain a description of the format that it is for
rather than a description of what is required from the format. The Oboe
version describes the format only so far as is needed to identify the
desired parts; the remainder of the JSON could change and the code would
continue to work. I believe this demonstrates a greater tolerance to
changing formats and that this would be useful when programming against
evolving services.

The Clarinet version of the code is too long to include here but may be
seen \hyperref[headerux5fbenchmarkClient]{in the appendix}, on page
\pageref{src_benchmarkClient}. By using SAX directly the code is more
verbose and its purpose is obfuscated. A person looking at this source
would find it difficult to deduce what is being done without considering
it for some time. The functions receiving SAX events must handle several
different cases and so tend to have generic parameter names such as
`key' or `value' which represent the token type. By contrast, Oboe and
JSON.parse both allow names such as `record' or `url' which are chosen
according to the semantics of the value. This naming aids
understandability because it allows the programmer to think in terms of
the domain model rather than working on the level of serialisation
artifacts.

\subsection{Performance under various Javascript
engines}\label{performance-under-various-javascript-engines}

The file \texttt{oboe.performance.spec.js}\footnote{In git repository,
  \href{https://github.com/jimhigson/oboe.js/blob/master/test/specs/oboe.performance.spec.js}{test/specs/oboe.performance.spec.js}}
contains a benchmark which concentrates on measuring the performance of
Oboe's pattern matching. This test registers a complex pattern which
intentionally uses all features from the JSONPath language and then
fetches a JSON file containing approximately 800 nodes, 100 of which
will match. Although actual HTTP is used, it is over an unthrottled
connection to localhost so network delay should be negligible. The tests
were executed on a relatively low-powered Macbook Air laptop running OS
X 10.7.5, except for Chrome Mobile which was tested on an iPhone 5 with
iOS 7.0.2. Test cases requiring Microsoft Windows were performed inside
a VirtualBox virtual machine. Curl is a simple download tool that writes
the resource to stdout without any parsing and is included as a
baseline.

\begin{longtable}[c]{@{}lrr@{}}
\hline\noalign{\medskip}
Platform & Total Time & Throughput (nodes/ms)
\\\noalign{\medskip}
\hline\noalign{\medskip}
Curl & 42ms & \emph{unparsed, n/a}
\\\noalign{\medskip}
Chrome 31.0.1650.34 & 84ms & 9.57
\\\noalign{\medskip}
Node.js v0.10.1 & 172ms & 4.67
\\\noalign{\medskip}
Chrome 30.0.1599 & 202ms & 3.98
\\\noalign{\medskip}
Safari 6.0.5 & 231ms & 3.48
\\\noalign{\medskip}
IE 10.0.0 (Windows 8) & 349ms & 2.30
\\\noalign{\medskip}
Chrome Mobile iOS 30.0.1599 & 431ms & 1.86
\\\noalign{\medskip}
Firefox 24.0.0 & 547ms & 1.47
\\\noalign{\medskip}
IE 8.0.0 (Windows XP) & 3,048ms & 0.26
\\\noalign{\medskip}
\hline
\end{longtable}

We can see that Firefox is slower than other modern browsers despite
normally being quite fast. This is probably explicable by SpiderMonkey,
the Mozilla just-in-time Javascript compiler being poor at optimising
functional Javascript (Guo 2013). The JSON nodes are not of a common
type so many of the library's internal callsites are not monomorphic
which is also optimised poorly (Guo 2013). When the test was later
repeated with a simpler pattern Firefox showed by far the largest
improvement, indicating that the functional JSONPath matching accounts
for Firefox's lower than expected performance.

During the project version 31 of Chrome was released that performed more
than twice as quickly as version 30 due to an updated version of the v8
Javascript engine. Node also uses v8 and should catch up when it is next
updated. This reflects Javascript engine writers targeting functional
optimisation now that functional Javascript is becoming a more popular
style.

Of these results I find only the performance under old versions of
Internet Explorer poor enough to be concerning. Since this platform
forbids progressively interpreting the XHR response an improvement over
the traditional model was known not to be possible but I did not expect
the performance to degrade by so much. Adding three seconds to a REST
call will unacceptably impair the user experience of a webapp so it
might be reasonable to conclude that for complex use cases Oboe is
currently unsuited to legacy platforms. If we desired to improve
performance on older platforms one solution might be to create a
simpler, non-progressive implementation of the Oboe API for selective
delivery to older browsers. However, I would argue that the time spent
writing a basic legacy version would be better employed waiting for
these moribund platforms to die.

For an imperative language coded in a functional style the compiler may
not optimise as effectively as if a functional language were used. This
is especially the case for a highly dynamic language in which
everything, even the basic built-in types, are mutable. Presenting a
convenient API to application developers means passing eagerly evaluated
parameters to application callbacks even when the parameters are of
secondary importance, such as the path and ancestor arrays that are
created for every matching node, and will be predominantly ignored.
Under a functional language these could be lazily evaluated without
requiring any special effort by the application programmer. The choice
of Javascript gives a very large number of client- and server-side
applications that may potentially adopt the library. However,
server-side Oboe would be very amicable to implementation using a purer
functional language and it would be interesting to see how much faster
it could be.

\subsection{Status as a micro-library}\label{status-as-a-micro-library}

The file \texttt{oboe-browser.min.js} is the minified, built version of
Oboe ready to be sent to web browsers and can be found in the project's
\texttt{dist} directory. The size fluctuates as commits are made but
after gzip it comes to about 4800 bytes; close to but comfortably under
the 5120 byte limit. At roughly the size of a small image the download
footprint of Oboe should not discourage adoption.

\subsection{Potential future work}\label{potential-future-work}

Although all network traffic can be viewed as a stream, the most obvious
future expansion would be to create a matching server-side component
that provides an intuitive interface for writing JSON streams. So far,
sending streaming JSON has required that the resource be written out
using programmer-assembled strings but this approach is error prone and
would scale badly as messages become more complex. A server-side library
for stream writing would allow Oboe to be used as a REST-compatible
streaming solution for situations which currently employ push tables or
Websockets. This would provide a form of REST streaming that operates
according to the principled design of HTTP rather than by sidestepping
it.

Although JSON is particularly well suited, there is nothing about Oboe
that precludes working with other tree-shaped formats. If there is
demand, an XML/XPATH version seems like an obvious expansion. This could
be implemented by allowing resource formats to be added using plugins
which would allow programmers to create a progressive interpretation of
any resource type. As a minimum, a plug-in would require a SAX-like
parser and a DSL for node selection.

Oboe stores all parsed nodes for the duration of its lifetime so despite
being similar to a SAX parser in terms of being progressive, it consumes
as much memory as a DOM parser. The nodes remain held so that all
possible JSONPath expressions may later be tested. However, in most
cases memory could be freed if the parsed content were stored only so
far as is required to test against the patterns which have actually been
registered. For selectors which match near the root this would allow
large subtrees to be pruned, particularly after the patterns have
matched and the nodes have already been handed back to the application.
Likewise, the current implementation takes a rather brute force approach
when examining nodes for pattern matches by checking every registered
JSONPath expression against every node parsed from the JSON. For many
expressions we should be able to say that there will be no matches
inside a particular JSON subtree, either because we have already matched
or because the the subtree's ancestors invariably imply failure. A more
sophisticated implementation might subdue provably unsatisfiable
handlers until the SAX parser leaves an unmatchable subtree.

\subsection{Summing up}\label{summing-up}

The community reaction to Oboe has been overwhelmingly positive with
several projects already adopting it and reporting performance gains
which are large enough to be obvious. While some attention may be
required for optimisation under Firefox, this project meets all of its
intended aims, presenting a REST client library which in the best case
allows the network to be used much more efficiently and in the worse
case is very close to the previous best solution, at least when used
with capable platforms. At the same time the produced solution requires
less code, is less tightly coupled to JSON format specifics, and because
of the declarative style I believe is easier to use than the previous
simplest solution.

\hyperdef{}{appendixux5fhttpux5flimits}{\section{Appendix i: Limits to
number of simultaneous connections under various HTTP
clients}\label{appendixux5fhttpux5flimits}}

\begin{longtable}[c]{@{}ll@{}}
\hline\noalign{\medskip}
\begin{minipage}[b]{0.21\columnwidth}\raggedright
HTTP Client
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\raggedright
connection limit per server
\end{minipage}
\\\noalign{\medskip}
\hline\noalign{\medskip}
\begin{minipage}[t]{0.21\columnwidth}\raggedright
Firefox
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
6
\end{minipage}
\\\noalign{\medskip}
\begin{minipage}[t]{0.21\columnwidth}\raggedright
Internet Explorer
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
4
\end{minipage}
\\\noalign{\medskip}
\begin{minipage}[t]{0.21\columnwidth}\raggedright
Chrome / Chromium
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
32 sockets per proxy, 6 sockets per destination host, 256 sockets per
process
\end{minipage}
\\\noalign{\medskip}
\hline
\end{longtable}

\url{https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest}

\url{http://msdn.microsoft.com/de-de/magazine/ee330731.aspx}\#http11\_max\_con

\url{http://dev.chromium.org/developers/design-documents/network-stack}\#TOC-Connection-Management

\section{Appendix ii: Oboe.js source code
listing}\label{appendix-ii-oboe.js-source-code-listing}

\subsection{ascent.js}\label{headerux5fascent}

\label{src_ascent}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * Get a new key->node mapping}
\CommentTok{ * }
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String|Number\}}\CommentTok{ key}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Object|Array|String|Number|null\}}\CommentTok{ node a value found in the json}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{namedNode}\NormalTok{(key, node) \{}
   \KeywordTok{return} \NormalTok{\{}\DataTypeTok{key}\NormalTok{:key, }\DataTypeTok{node}\NormalTok{:node\};}
\NormalTok{\}}

\CommentTok{/** get the key of a namedNode */}
\KeywordTok{var} \NormalTok{keyOf = }\FunctionTok{attr}\NormalTok{(}\StringTok{'key'}\NormalTok{);}

\CommentTok{/** get the node from a namedNode */}
\KeywordTok{var} \NormalTok{nodeOf = }\FunctionTok{attr}\NormalTok{(}\StringTok{'node'}\NormalTok{);}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{clarinetListenerAdaptor.js}\label{headerux5fclarinetListenerAdaptor}

\label{src_clarinetListenerAdaptor}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{/** }
\CommentTok{ * A bridge used to assign stateless functions to listen to clarinet.}
\CommentTok{ * }
\CommentTok{ * As well as the parameter from clarinet, each callback will also be passed}
\CommentTok{ * the result of the last callback.}
\CommentTok{ * }
\CommentTok{ * This may also be used to clear all listeners by assigning zero handlers:}
\CommentTok{ * }
\CommentTok{ *    clarinetListenerAdaptor( clarinet, \{\} )}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{clarinetListenerAdaptor}\NormalTok{(clarinetParser, handlers)\{}
    
   \KeywordTok{var} \NormalTok{state;}

   \OtherTok{clarinet}\NormalTok{.}\OtherTok{EVENTS}\NormalTok{.}\FunctionTok{forEach}\NormalTok{(}\KeywordTok{function}\NormalTok{(eventName)\{}
 
      \KeywordTok{var} \NormalTok{handlerFunction = handlers[eventName];}
      
      \NormalTok{clarinetParser[}\StringTok{'on'}\NormalTok{+eventName] = handlerFunction && }
                                       \KeywordTok{function}\NormalTok{(param) \{}
                                          \NormalTok{state = }\FunctionTok{handlerFunction}\NormalTok{( state, param);}
                                       \NormalTok{\};}
   \NormalTok{\});}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{events.js}\label{headerux5fevents}

\label{src_events}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file declares some constants to use as names for event types.}
\CommentTok{ */}

\KeywordTok{var} \CommentTok{// the events which are never exported are kept as }
    \CommentTok{// the smallest possible representation, in numbers:}
    \NormalTok{_S = }\DecValTok{0}\NormalTok{,}

    \CommentTok{// fired whenever a node is found in the JSON:}
    \NormalTok{NODE_FOUND    = _S++,}
    \CommentTok{// fired whenever a path is found in the JSON:      }
    \NormalTok{PATH_FOUND    = _S++,   }
    
    \NormalTok{NODE_MATCHED  = }\StringTok{'node'}\NormalTok{,}
    \NormalTok{PATH_MATCHED  = }\StringTok{'path'}\NormalTok{,}
         
    \NormalTok{FAIL_EVENT    = }\StringTok{'fail'}\NormalTok{,    }
    \NormalTok{ROOT_FOUND    = _S++,    }
    \NormalTok{HTTP_START    = }\StringTok{'start'}\NormalTok{,}
    \NormalTok{STREAM_DATA   = _S++,}
    \NormalTok{STREAM_END    = _S++,}
    \NormalTok{ABORTING      = _S++;}
    
\KeywordTok{function} \FunctionTok{errorReport}\NormalTok{(statusCode, body, error) \{}
   \KeywordTok{try}\NormalTok{\{}
      \KeywordTok{var} \NormalTok{jsonBody = }\OtherTok{JSON}\NormalTok{.}\FunctionTok{parse}\NormalTok{(body);}
   \NormalTok{\}}\KeywordTok{catch}\NormalTok{(e)\{\}}

   \KeywordTok{return} \NormalTok{\{}
      \DataTypeTok{statusCode}\NormalTok{:statusCode,}
      \DataTypeTok{body}\NormalTok{:body,}
      \DataTypeTok{jsonBody}\NormalTok{:jsonBody,}
      \DataTypeTok{thrown}\NormalTok{:error}
   \NormalTok{\};}
\NormalTok{\}    }
\end{Highlighting}
\end{Shaded}

\pagebreak

\hyperdef{}{headerux5ffunctional}{\subsection{functional.js}\label{headerux5ffunctional}}

\label{src_functional}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/** }
\CommentTok{ * Partially complete a function.}
\CommentTok{ * }
\CommentTok{ * Eg: }
\CommentTok{ *    var add3 = partialComplete( function add(a,b)\{return a+b\}, 3 );}
\CommentTok{ *    }
\CommentTok{ *    add3(4) // gives 7}
\CommentTok{ *    }
\CommentTok{ *    }
\CommentTok{ *    function wrap(left, right, cen)\{return left + " " + cen + " " + right;\}}
\CommentTok{ *    }
\CommentTok{ *    var pirateGreeting = partialComplete( wrap , "I'm", ", a mighty pirate!" );}
\CommentTok{ *    }
\CommentTok{ *    pirateGreeting("Guybrush Threepwood"); }
\CommentTok{ *                         // gives "I'm Guybrush Threepwood, a mighty pirate!"}
\CommentTok{ */}
\KeywordTok{var} \NormalTok{partialComplete = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{( fn, boundArgs ) \{}

      \KeywordTok{return} \FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{( callArgs ) \{}
               
         \KeywordTok{return} \OtherTok{fn}\NormalTok{.}\FunctionTok{apply}\NormalTok{(}\KeywordTok{this}\NormalTok{, }\OtherTok{boundArgs}\NormalTok{.}\FunctionTok{concat}\NormalTok{(callArgs));}
      \NormalTok{\}); }
   \NormalTok{\}),}

\CommentTok{/**}
\CommentTok{ * Compose zero or more functions:}
\CommentTok{ * }
\CommentTok{ *    compose(f1, f2, f3)(x) = f1(f2(f3(x))))}
\CommentTok{ * }
\CommentTok{ * The last (inner-most) function may take more than one parameter:}
\CommentTok{ * }
\CommentTok{ *    compose(f1, f2, f3)(x,y) = f1(f2(f3(x,y))))}
\CommentTok{ */}
   \NormalTok{compose = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(fns) \{}

      \KeywordTok{var} \NormalTok{fnsList = }\FunctionTok{arrayAsList}\NormalTok{(fns);}
   
      \KeywordTok{function} \FunctionTok{next}\NormalTok{(params, curFn) \{  }
         \KeywordTok{return} \NormalTok{[}\FunctionTok{apply}\NormalTok{(params, curFn)];   }
      \NormalTok{\}}
      
      \KeywordTok{return} \FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(startParams)\{}
        
         \KeywordTok{return} \FunctionTok{foldR}\NormalTok{(next, startParams, fnsList)[}\DecValTok{0}\NormalTok{];}
      \NormalTok{\});}
   \NormalTok{\}),}

\CommentTok{/**}
\CommentTok{ * Call a list of functions with the same args until one returns a }
\CommentTok{ * truthy result. Similar to the || operator.}
\CommentTok{ * }
\CommentTok{ * So:}
\CommentTok{ *      lazyUnion([f1,f2,f3 ... fn])( p1, p2 ... pn )}
\CommentTok{ *      }
\CommentTok{ * Is equivalent to: }
\CommentTok{ *      apply([p1, p2 ... pn], f1) || }
\CommentTok{ *      apply([p1, p2 ... pn], f2) || }
\CommentTok{ *      apply([p1, p2 ... pn], f3) ... apply(fn, [p1, p2 ... pn])  }
\CommentTok{ *  }
\CommentTok{ * }\KeywordTok{@returns}\CommentTok{ the first return value that is given that is truthy.}
\CommentTok{ */}
   \NormalTok{lazyUnion = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(fns) \{}

      \KeywordTok{return} \FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(params)\{}
   
         \KeywordTok{var} \NormalTok{maybeValue;}
   
         \KeywordTok{for} \NormalTok{(}\KeywordTok{var} \NormalTok{i = }\DecValTok{0}\NormalTok{; i < }\FunctionTok{len}\NormalTok{(fns); i++) \{}
   
            \NormalTok{maybeValue = }\FunctionTok{apply}\NormalTok{(params, fns[i]);}
   
            \KeywordTok{if}\NormalTok{( maybeValue ) \{}
               \KeywordTok{return} \NormalTok{maybeValue;}
            \NormalTok{\}}
         \NormalTok{\}}
      \NormalTok{\});}
   \NormalTok{\});   }

\CommentTok{/**}
\CommentTok{ * This file declares various pieces of functional programming.}
\CommentTok{ * }
\CommentTok{ * This isn't a general purpose functional library, to keep things small it}
\CommentTok{ * has just the parts useful for Oboe.js.}
\CommentTok{ */}


\CommentTok{/**}
\CommentTok{ * Call a single function with the given arguments array.}
\CommentTok{ * Basically, a functional-style version of the OO-style Function#apply for }
\CommentTok{ * when we don't care about the context ('this') of the call.}
\CommentTok{ * }
\CommentTok{ * The order of arguments allows partial completion of the arguments array}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{apply}\NormalTok{(args, fn) \{}
   \KeywordTok{return} \OtherTok{fn}\NormalTok{.}\FunctionTok{apply}\NormalTok{(}\KeywordTok{undefined}\NormalTok{, args);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Define variable argument functions but cut out all that tedious messing about }
\CommentTok{ * with the arguments object. Delivers the variable-length part of the arguments}
\CommentTok{ * list as an array.}
\CommentTok{ * }
\CommentTok{ * Eg:}
\CommentTok{ * }
\CommentTok{ * var myFunction = varArgs(}
\CommentTok{ *    function( fixedArgument, otherFixedArgument, variableNumberOfArguments )\{}
\CommentTok{ *       console.log( variableNumberOfArguments );}
\CommentTok{ *    \}}
\CommentTok{ * )}
\CommentTok{ * }
\CommentTok{ * myFunction('a', 'b', 1, 2, 3); // logs [1,2,3]}
\CommentTok{ * }
\CommentTok{ * var myOtherFunction = varArgs(function( variableNumberOfArguments )\{}
\CommentTok{ *    console.log( variableNumberOfArguments );}
\CommentTok{ * \})}
\CommentTok{ * }
\CommentTok{ * myFunction(1, 2, 3); // logs [1,2,3]}
\CommentTok{ * }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{varArgs}\NormalTok{(fn)\{}

   \KeywordTok{var} \NormalTok{numberOfFixedArguments = }\OtherTok{fn}\NormalTok{.}\FunctionTok{length} \NormalTok{-}\DecValTok{1}\NormalTok{;}
         
   \KeywordTok{return} \KeywordTok{function}\NormalTok{()\{}
   
      \KeywordTok{var} \NormalTok{numberOfVariableArguments = }\OtherTok{arguments}\NormalTok{.}\FunctionTok{length} \NormalTok{- numberOfFixedArguments,}
      
          \NormalTok{argumentsToFunction = }\OtherTok{Array}\NormalTok{.}\OtherTok{prototype}\NormalTok{.}\OtherTok{slice}\NormalTok{.}\FunctionTok{call}\NormalTok{(arguments);}
          
      \CommentTok{// remove the last n elements from the array and append it onto the end of}
      \CommentTok{// itself as a sub-array}
      \OtherTok{argumentsToFunction}\NormalTok{.}\FunctionTok{push}\NormalTok{( }
         \OtherTok{argumentsToFunction}\NormalTok{.}\FunctionTok{splice}\NormalTok{(numberOfFixedArguments, numberOfVariableArguments)}
      \NormalTok{);   }
      
      \KeywordTok{return} \OtherTok{fn}\NormalTok{.}\FunctionTok{apply}\NormalTok{( }\KeywordTok{this}\NormalTok{, argumentsToFunction );}
   \NormalTok{\}       }
\NormalTok{\}}


\CommentTok{/**}
\CommentTok{ * Swap the order of parameters to a binary function}
\CommentTok{ * }
\CommentTok{ * A bit like this flip: http://zvon.org/other/haskell/Outputprelude/flip_f.html}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{flip}\NormalTok{(fn)\{}
   \KeywordTok{return} \KeywordTok{function}\NormalTok{(a, b)\{}
      \KeywordTok{return} \FunctionTok{fn}\NormalTok{(b,a);}
   \NormalTok{\}}
\NormalTok{\}}


\CommentTok{/**}
\CommentTok{ * Create a function which is the intersection of two other functions.}
\CommentTok{ * }
\CommentTok{ * Like the && operator, if the first is truthy, the second is never called,}
\CommentTok{ * otherwise the return value from the second is returned.}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{lazyIntersection}\NormalTok{(fn1, fn2) \{}

   \KeywordTok{return} \KeywordTok{function} \NormalTok{(param) \{}
                                                              
      \KeywordTok{return} \FunctionTok{fn1}\NormalTok{(param) && }\FunctionTok{fn2}\NormalTok{(param);}
   \NormalTok{\};   }
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * A function which does nothing}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{noop}\NormalTok{()\{\}}

\KeywordTok{function} \FunctionTok{functor}\NormalTok{(val)\{}
   \KeywordTok{return} \KeywordTok{function}\NormalTok{()\{}
      \KeywordTok{return} \NormalTok{val;}
   \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{incrementalContentBuilder.js}\label{headerux5fincrementalContentBuilder}

\label{src_incrementalContentBuilder}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/** }
\CommentTok{ * This file provides various listeners which can be used to build up}
\CommentTok{ * a changing ascent based on the callbacks provided by Clarinet. It listens}
\CommentTok{ * to the low-level events from Clarinet and emits higher-level ones.}
\CommentTok{ *  }
\CommentTok{ * The building up is stateless so to track a JSON file}
\CommentTok{ * clarinetListenerAdaptor.js is required to store the ascent state}
\CommentTok{ * between calls.}
\CommentTok{ */}



\CommentTok{/** }
\CommentTok{ * A special value to use in the path list to represent the path 'to' a root }
\CommentTok{ * object (which doesn't really have any path). This prevents the need for }
\CommentTok{ * special-casing detection of the root object and allows it to be treated }
\CommentTok{ * like any other object. We might think of this as being similar to the }
\CommentTok{ * 'unnamed root' domain ".", eg if I go to }
\CommentTok{ * http://en.wikipedia.org./wiki/En/Main_page the dot after 'org' deliminates }
\CommentTok{ * the unnamed root of the DNS.}
\CommentTok{ * }
\CommentTok{ * This is kept as an object to take advantage that in Javascript's OO objects }
\CommentTok{ * are guaranteed to be distinct, therefore no other object can possibly clash }
\CommentTok{ * with this one. Strings, numbers etc provide no such guarantee. }
\CommentTok{ **/}
\KeywordTok{var} \NormalTok{ROOT_PATH = \{\};}


\CommentTok{/**}
\CommentTok{ * Create a new set of handlers for clarinet's events, bound to the emit }
\CommentTok{ * function given.  }
\CommentTok{ */} 
\KeywordTok{function} \FunctionTok{incrementalContentBuilder}\NormalTok{( emit ) \{}


   \KeywordTok{function} \FunctionTok{arrayIndicesAreKeys}\NormalTok{( possiblyInconsistentAscent, newDeepestNode) \{}
   
      \CommentTok{/* for values in arrays we aren't pre-warned of the coming paths }
\CommentTok{         (Clarinet gives no call to onkey like it does for values in objects) }
\CommentTok{         so if we are in an array we need to create this path ourselves. The }
\CommentTok{         key will be len(parentNode) because array keys are always sequential }
\CommentTok{         numbers. */}

      \KeywordTok{var} \NormalTok{parentNode = }\FunctionTok{nodeOf}\NormalTok{( }\FunctionTok{head}\NormalTok{( possiblyInconsistentAscent));}
      
      \KeywordTok{return}      \FunctionTok{isOfType}\NormalTok{( Array, parentNode)}
               \NormalTok{?}
                  \FunctionTok{pathFound}\NormalTok{(  possiblyInconsistentAscent, }
                              \FunctionTok{len}\NormalTok{(parentNode), }
                              \NormalTok{newDeepestNode}
                  \NormalTok{)}
               \NormalTok{:  }
                  \CommentTok{// nothing needed, return unchanged}
                  \NormalTok{possiblyInconsistentAscent }
               \NormalTok{;}
   \NormalTok{\}}
                 
   \KeywordTok{function} \FunctionTok{nodeFound}\NormalTok{( ascent, newDeepestNode ) \{}
      
      \KeywordTok{if}\NormalTok{( !ascent ) \{}
         \CommentTok{// we discovered the root node,}
         \FunctionTok{emit}\NormalTok{( ROOT_FOUND, newDeepestNode);}
                    
         \KeywordTok{return} \FunctionTok{pathFound}\NormalTok{( ascent, ROOT_PATH, newDeepestNode);         }
      \NormalTok{\}}

      \CommentTok{// we discovered a non-root node}
                 
      \KeywordTok{var} \NormalTok{arrayConsistentAscent  = }\FunctionTok{arrayIndicesAreKeys}\NormalTok{( ascent, newDeepestNode),      }
          \NormalTok{ancestorBranches       = }\FunctionTok{tail}\NormalTok{( arrayConsistentAscent),}
          \NormalTok{previouslyUnmappedName = }\FunctionTok{keyOf}\NormalTok{( }\FunctionTok{head}\NormalTok{( arrayConsistentAscent));}
          
      \FunctionTok{appendBuiltContent}\NormalTok{( }
         \NormalTok{ancestorBranches, }
         \NormalTok{previouslyUnmappedName, }
         \NormalTok{newDeepestNode }
      \NormalTok{);}
                                                                                                         
      \KeywordTok{return} \FunctionTok{cons}\NormalTok{( }
               \FunctionTok{namedNode}\NormalTok{( previouslyUnmappedName, newDeepestNode ), }
               \NormalTok{ancestorBranches}
      \NormalTok{);                                                                          }
   \NormalTok{\}}


   \CommentTok{/**}
\CommentTok{    * Add a new value to the object we are building up to represent the}
\CommentTok{    * parsed JSON}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{appendBuiltContent}\NormalTok{( ancestorBranches, key, node )\{}
     
      \FunctionTok{nodeOf}\NormalTok{( }\FunctionTok{head}\NormalTok{( ancestorBranches))[key] = node;}
   \NormalTok{\}}

     
   \CommentTok{/**}
\CommentTok{    * For when we find a new key in the json.}
\CommentTok{    * }
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String|Number|Object\}}\CommentTok{ newDeepestName the key. If we are in an }
\CommentTok{    *    array will be a number, otherwise a string. May take the special }
\CommentTok{    *    value ROOT_PATH if the root node has just been found}
\CommentTok{    *    }
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String|Number|Object|Array|Null|undefined\}}\CommentTok{ [maybeNewDeepestNode] }
\CommentTok{    *    usually this won't be known so can be undefined. Can't use null }
\CommentTok{    *    to represent unknown because null is a valid value in JSON}
\CommentTok{    **/}  
   \KeywordTok{function} \FunctionTok{pathFound}\NormalTok{(ascent, newDeepestName, maybeNewDeepestNode) \{}

      \KeywordTok{if}\NormalTok{( ascent ) \{ }\CommentTok{// if not root}
      
         \CommentTok{// If we have the key but (unless adding to an array) no known value}
         \CommentTok{// yet. Put that key in the output but against no defined value:      }
         \FunctionTok{appendBuiltContent}\NormalTok{( ascent, newDeepestName, maybeNewDeepestNode );}
      \NormalTok{\}}
   
      \KeywordTok{var} \NormalTok{ascentWithNewPath = }\FunctionTok{cons}\NormalTok{( }
                                 \FunctionTok{namedNode}\NormalTok{( newDeepestName, }
                                            \NormalTok{maybeNewDeepestNode), }
                                 \NormalTok{ascent}
                              \NormalTok{);}
     
      \FunctionTok{emit}\NormalTok{( PATH_FOUND, ascentWithNewPath);}
 
      \KeywordTok{return} \NormalTok{ascentWithNewPath;}
   \NormalTok{\}}


   \CommentTok{/**}
\CommentTok{    * For when the current node ends}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{nodeFinished}\NormalTok{( ascent ) \{}

      \FunctionTok{emit}\NormalTok{( NODE_FOUND, ascent);}
                          
      \CommentTok{// pop the complete node and its path off the list:                                    }
      \KeywordTok{return} \FunctionTok{tail}\NormalTok{( ascent);}
   \NormalTok{\}      }
                 
   \KeywordTok{return} \NormalTok{\{ }

      \DataTypeTok{openobject }\NormalTok{: }\KeywordTok{function} \NormalTok{(ascent, firstKey) \{}

         \KeywordTok{var} \NormalTok{ascentAfterNodeFound = }\FunctionTok{nodeFound}\NormalTok{(ascent, \{\});         }

         \CommentTok{/* It is a perculiarity of Clarinet that for non-empty objects it}
\CommentTok{            gives the first key with the openobject event instead of}
\CommentTok{            in a subsequent key event.}
\CommentTok{                      }
\CommentTok{            firstKey could be the empty string in a JSON object like }
\CommentTok{            \{'':'foo'\} which is technically valid.}
\CommentTok{            }
\CommentTok{            So can't check with !firstKey, have to see if has any }
\CommentTok{            defined value. */}
         \KeywordTok{return} \FunctionTok{defined}\NormalTok{(firstKey)}
         \NormalTok{?          }
            \CommentTok{/* We know the first key of the newly parsed object. Notify that }
\CommentTok{               path has been found but don't put firstKey permanently onto }
\CommentTok{               pathList yet because we haven't identified what is at that key }
\CommentTok{               yet. Give null as the value because we haven't seen that far }
\CommentTok{               into the json yet */}
            \FunctionTok{pathFound}\NormalTok{(ascentAfterNodeFound, firstKey)}
         \NormalTok{:}
            \NormalTok{ascentAfterNodeFound}
         \NormalTok{;}
      \NormalTok{\},}
    
      \DataTypeTok{openarray}\NormalTok{: }\KeywordTok{function} \NormalTok{(ascent) \{}
         \KeywordTok{return} \FunctionTok{nodeFound}\NormalTok{(ascent, []);}
      \NormalTok{\},}

      \CommentTok{// called by Clarinet when keys are found in objects               }
      \DataTypeTok{key}\NormalTok{: pathFound,}
      
      \CommentTok{/* Emitted by Clarinet when primitive values are found, ie Strings,}
\CommentTok{         Numbers, and null.}
\CommentTok{         Because these are always leaves in the JSON, we find and finish the }
\CommentTok{         node in one step, expressed as functional composition: */}
      \DataTypeTok{value}\NormalTok{: }\FunctionTok{compose}\NormalTok{( nodeFinished, nodeFound ),}
      
      \CommentTok{// we make no distinction in how we handle object and arrays closing.}
      \CommentTok{// For both, interpret as the end of the current node.}
      \DataTypeTok{closeobject}\NormalTok{: nodeFinished,}
      \DataTypeTok{closearray}\NormalTok{: nodeFinished}
   \NormalTok{\};}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{instanceApi.js}\label{headerux5finstanceApi}

\label{src_instanceApi}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{instanceApi}\NormalTok{(emit, on, un, jsonPathCompiler)\{}

   \KeywordTok{var} \NormalTok{oboeApi,}
       \NormalTok{addDoneListener = }\FunctionTok{partialComplete}\NormalTok{(}
                              \NormalTok{addNodeOrPathListenerApi, }
                              \StringTok{'node'}\NormalTok{, }\StringTok{'!'}\NormalTok{);}
                              
   \KeywordTok{function} \FunctionTok{addPathOrNodeCallback}\NormalTok{( type, pattern, callback ) \{}
   
      \KeywordTok{var} 
          \NormalTok{compiledJsonPath = }\FunctionTok{jsonPathCompiler}\NormalTok{( pattern ),}
                
          \NormalTok{underlyingEvent = \{}\DataTypeTok{node}\NormalTok{:NODE_FOUND, }\DataTypeTok{path}\NormalTok{:PATH_FOUND\}[type],}
          
          \NormalTok{safeCallback = }\FunctionTok{protectedCallback}\NormalTok{(callback);               }
          
      \FunctionTok{on}\NormalTok{( underlyingEvent, }\KeywordTok{function} \FunctionTok{handler}\NormalTok{( ascent )\{ }
 
         \KeywordTok{var} \NormalTok{maybeMatchingMapping = }\FunctionTok{compiledJsonPath}\NormalTok{( ascent );}
     
         \CommentTok{/* Possible values for maybeMatchingMapping are now:}

\CommentTok{            false: }
\CommentTok{               we did not match }
\CommentTok{  }
\CommentTok{            an object/array/string/number/null: }
\CommentTok{               we matched and have the node that matched.}
\CommentTok{               Because nulls are valid json values this can be null.}
\CommentTok{  }
\CommentTok{            undefined: }
\CommentTok{               we matched but don't have the matching node yet.}
\CommentTok{               ie, we know there is an upcoming node that matches but we }
\CommentTok{               can't say anything else about it. }
\CommentTok{         */}
         \KeywordTok{if}\NormalTok{( maybeMatchingMapping !== }\KeywordTok{false} \NormalTok{) \{                                 }

            \KeywordTok{if}\NormalTok{( !}\FunctionTok{notifyCallback}\NormalTok{(safeCallback, }\FunctionTok{nodeOf}\NormalTok{(maybeMatchingMapping), ascent) ) \{}
            
               \FunctionTok{un}\NormalTok{(underlyingEvent, handler);}
            \NormalTok{\}}
         \NormalTok{\}}
      \NormalTok{\});   }
   \NormalTok{\}   }
   
   \KeywordTok{function} \FunctionTok{notifyCallback}\NormalTok{(callback, node, ascent) \{}
      \CommentTok{/* }
\CommentTok{         We're now calling back to outside of oboe where the Lisp-style }
\CommentTok{         lists that we are using internally will not be recognised }
\CommentTok{         so convert to standard arrays. }
\CommentTok{   }
\CommentTok{         Also, reverse the order because it is more common to list paths }
\CommentTok{         "root to leaf" than "leaf to root" }
\CommentTok{      */}
            
      \KeywordTok{var} \NormalTok{descent     = }\FunctionTok{reverseList}\NormalTok{(ascent),}
      
          \CommentTok{// To make a path, strip off the last item which is the special}
          \CommentTok{// ROOT_PATH token for the 'path' to the root node}
          \NormalTok{path       = }\FunctionTok{listAsArray}\NormalTok{(}\FunctionTok{tail}\NormalTok{(}\FunctionTok{map}\NormalTok{(keyOf,descent))),}
          \NormalTok{ancestors  = }\FunctionTok{listAsArray}\NormalTok{(}\FunctionTok{map}\NormalTok{(nodeOf, descent)),}
          \NormalTok{keep       = }\KeywordTok{true}\NormalTok{;}
          
      \OtherTok{oboeApi}\NormalTok{.}\FunctionTok{forget} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
         \NormalTok{keep = }\KeywordTok{false}\NormalTok{;}
      \NormalTok{\};           }
      
      \FunctionTok{callback}\NormalTok{( node, path, ancestors );         }
            
      \KeywordTok{delete} \OtherTok{oboeApi}\NormalTok{.}\FunctionTok{forget}\NormalTok{;}
      
      \KeywordTok{return} \NormalTok{keep;          }
   \NormalTok{\}}
      
   \KeywordTok{function} \FunctionTok{protectedCallback}\NormalTok{( callback ) \{}
      \KeywordTok{return} \KeywordTok{function}\NormalTok{() \{}
         \KeywordTok{try}\NormalTok{\{      }
            \OtherTok{callback}\NormalTok{.}\FunctionTok{apply}\NormalTok{(oboeApi, arguments);   }
         \NormalTok{\}}\KeywordTok{catch}\NormalTok{(e)  \{}
         
            \CommentTok{// An error occured during the callback, publish it on the event bus }
            \FunctionTok{emit}\NormalTok{(FAIL_EVENT, }\FunctionTok{errorReport}\NormalTok{(}\KeywordTok{undefined}\NormalTok{, }\KeywordTok{undefined}\NormalTok{, e));}
         \NormalTok{\}      }
      \NormalTok{\}   }
   \NormalTok{\}}

   \CommentTok{/** }
\CommentTok{    * a version of on which first wraps the callback with}
\CommentTok{    * protection against errors being thrown}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{safeOn}\NormalTok{( eventName, callback )\{}
      \FunctionTok{on}\NormalTok{(eventName, }\FunctionTok{protectedCallback}\NormalTok{(callback));}
      \KeywordTok{return} \NormalTok{oboeApi;}
   \NormalTok{\}}
      
   \CommentTok{/**}
\CommentTok{    * Add several listeners at a time, from a map}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{addListenersMap}\NormalTok{(eventId, listenerMap) \{}
   
      \KeywordTok{for}\NormalTok{( }\KeywordTok{var} \NormalTok{pattern }\KeywordTok{in} \NormalTok{listenerMap ) \{}
         \FunctionTok{addPathOrNodeCallback}\NormalTok{(eventId, pattern, listenerMap[pattern]);}
      \NormalTok{\}}
   \NormalTok{\}    }
      
   \CommentTok{/**}
\CommentTok{    * implementation behind .onPath() and .onNode()}
\CommentTok{    */}       
   \KeywordTok{function} \FunctionTok{addNodeOrPathListenerApi}\NormalTok{( eventId, jsonPathOrListenerMap, callback )\{}
   
      \KeywordTok{if}\NormalTok{( }\FunctionTok{isString}\NormalTok{(jsonPathOrListenerMap) ) \{}
         \FunctionTok{addPathOrNodeCallback}\NormalTok{( }
            \NormalTok{eventId, }
            \NormalTok{jsonPathOrListenerMap,}
            \NormalTok{callback}
         \NormalTok{);}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         \FunctionTok{addListenersMap}\NormalTok{(eventId, jsonPathOrListenerMap);}
      \NormalTok{\}}
      
      \KeywordTok{return} \NormalTok{oboeApi; }\CommentTok{// chaining}
   \NormalTok{\}}
      
   \CommentTok{/**}
\CommentTok{    * implementation behind oboe().on()}
\CommentTok{    */}       
   \KeywordTok{var} \NormalTok{addListener = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{( eventId, parameters )\{}

      \KeywordTok{if}\NormalTok{( oboeApi[eventId] ) \{}
      
         \CommentTok{// event has some special handling:}
         \FunctionTok{apply}\NormalTok{(parameters, oboeApi[eventId]);}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
      
         \CommentTok{// the even has no special handling, add it directly to}
         \CommentTok{// the event bus:         }
         \KeywordTok{var} \NormalTok{listener = parameters[}\DecValTok{0}\NormalTok{]; }
         \FunctionTok{on}\NormalTok{(eventId, listener);}
      \NormalTok{\}}
      
      \KeywordTok{return} \NormalTok{oboeApi;}
   \NormalTok{\});   }
   
   \CommentTok{// some interface methods are only filled in after we recieve}
   \CommentTok{// values and are noops before that:          }
   \FunctionTok{on}\NormalTok{(ROOT_FOUND, }\KeywordTok{function}\NormalTok{(root) \{}
      \OtherTok{oboeApi}\NormalTok{.}\FunctionTok{root} \NormalTok{= }\FunctionTok{functor}\NormalTok{(root);   }
   \NormalTok{\});}
   
   \FunctionTok{on}\NormalTok{(HTTP_START, }\KeywordTok{function}\NormalTok{(_statusCode, headers) \{}
      \OtherTok{oboeApi}\NormalTok{.}\FunctionTok{header} \NormalTok{= }
         \KeywordTok{function}\NormalTok{(name) \{}
            \KeywordTok{return} \NormalTok{name ? headers[name] }
                        \NormalTok{: headers}
                        \NormalTok{;}
         \NormalTok{\}}
   \NormalTok{\});}
      
   \CommentTok{/**}
\CommentTok{    * Construct and return the public API of the Oboe instance to be }
\CommentTok{    * returned to the calling application}
\CommentTok{    */}       
   \KeywordTok{return} \NormalTok{oboeApi = \{}
      \DataTypeTok{on    }\NormalTok{:  addListener,   }
      \DataTypeTok{done  }\NormalTok{:  addDoneListener,       }
      \DataTypeTok{node  }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(addNodeOrPathListenerApi, }\StringTok{'node'}\NormalTok{),}
      \DataTypeTok{path  }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(addNodeOrPathListenerApi, }\StringTok{'path'}\NormalTok{),      }
      \DataTypeTok{start }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(safeOn, HTTP_START),}
      \CommentTok{// fail doesn't use safeOn because that could lead to non-terminating loops}
      \DataTypeTok{fail  }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(on, FAIL_EVENT),}
      \DataTypeTok{abort }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(emit, ABORTING),}
      \DataTypeTok{header}\NormalTok{:  noop,}
      \DataTypeTok{root  }\NormalTok{:  noop}
   \NormalTok{\};   }
\NormalTok{\}   }
   
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{instanceController.js}\label{headerux5finstanceController}

\label{src_instanceController}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file implements a light-touch central controller for an instance }
\CommentTok{ * of Oboe which provides the methods used for interacting with the instance }
\CommentTok{ * from the calling app.}
\CommentTok{ */}
 
 
\KeywordTok{function} \FunctionTok{instanceController}\NormalTok{(  emit, on, }
                              \NormalTok{clarinetParser, contentBuilderHandlers) \{}
                                
   \FunctionTok{on}\NormalTok{(STREAM_DATA,         }
      \KeywordTok{function} \NormalTok{(nextDrip) \{}
         \CommentTok{// callback for when a bit more data arrives from the streaming XHR         }
          
         \KeywordTok{try} \NormalTok{\{}
            
            \OtherTok{clarinetParser}\NormalTok{.}\FunctionTok{write}\NormalTok{(nextDrip);            }
         \NormalTok{\} }\KeywordTok{catch}\NormalTok{(e) \{ }
            \CommentTok{/* we don't have to do anything here because we always assign}
\CommentTok{               a .onerror to clarinet which will have already been called }
\CommentTok{               by the time this exception is thrown. */}                
         \NormalTok{\}}
      \NormalTok{\}}
   \NormalTok{);}
   
   \CommentTok{/* At the end of the http content close the clarinet parser.}
\CommentTok{      This will provide an error if the total content provided was not }
\CommentTok{      valid json, ie if not all arrays, objects and Strings closed properly */}
   \FunctionTok{on}\NormalTok{(STREAM_END, }\OtherTok{clarinetParser}\NormalTok{.}\OtherTok{close}\NormalTok{.}\FunctionTok{bind}\NormalTok{(clarinetParser));}
   

   \CommentTok{/* If we abort this Oboe's request stop listening to the clarinet parser. }
\CommentTok{      This prevents more tokens being found after we abort in the case where }
\CommentTok{      we aborted during processing of an already filled buffer. */}
   \FunctionTok{on}\NormalTok{( ABORTING, }\KeywordTok{function}\NormalTok{() \{}
      \FunctionTok{clarinetListenerAdaptor}\NormalTok{(clarinetParser, \{\});}
   \NormalTok{\});   }

   \FunctionTok{clarinetListenerAdaptor}\NormalTok{(clarinetParser, contentBuilderHandlers);}
  
   \CommentTok{// react to errors by putting them on the event bus}
   \OtherTok{clarinetParser}\NormalTok{.}\FunctionTok{onerror} \NormalTok{= }\KeywordTok{function}\NormalTok{(e) \{          }
      \FunctionTok{emit}\NormalTok{(}
         \NormalTok{FAIL_EVENT, }
         \FunctionTok{errorReport}\NormalTok{(}\KeywordTok{undefined}\NormalTok{, }\KeywordTok{undefined}\NormalTok{, e)}
      \NormalTok{);}
      
      \CommentTok{// note: don't close clarinet here because if it was not expecting}
      \CommentTok{// end of the json it will throw an error}
   \NormalTok{\};   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{jsonPath.js}\label{headerux5fjsonPath}

\label{src_jsonPath}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * The jsonPath evaluator compiler used for Oboe.js. }
\CommentTok{ * }
\CommentTok{ * One function is exposed. This function takes a String JSONPath spec and }
\CommentTok{ * returns a function to test candidate ascents for matches.}
\CommentTok{ * }
\CommentTok{ *  String jsonPath -> (List ascent) -> Boolean|Object}
\CommentTok{ *}
\CommentTok{ * This file is coded in a pure functional style. That is, no function has }
\CommentTok{ * side effects, every function evaluates to the same value for the same }
\CommentTok{ * arguments and no variables are reassigned.}
\CommentTok{ */}  
\CommentTok{// the call to jsonPathSyntax injects the token syntaxes that are needed }
\CommentTok{// inside the compiler}
\KeywordTok{var} \NormalTok{jsonPathCompiler = }\FunctionTok{jsonPathSyntax}\NormalTok{(}\KeywordTok{function} \NormalTok{(pathNodeSyntax, }
                                                \NormalTok{doubleDotSyntax, }
                                                \NormalTok{dotSyntax,}
                                                \NormalTok{bangSyntax,}
                                                \NormalTok{emptySyntax ) \{}

   \KeywordTok{var} \NormalTok{CAPTURING_INDEX = }\DecValTok{1}\NormalTok{;}
   \KeywordTok{var} \NormalTok{NAME_INDEX = }\DecValTok{2}\NormalTok{;}
   \KeywordTok{var} \NormalTok{FIELD_LIST_INDEX = }\DecValTok{3}\NormalTok{;}

   \KeywordTok{var} \NormalTok{headKey = }\FunctionTok{compose}\NormalTok{(keyOf, head);}
                   
   \CommentTok{/**}
\CommentTok{    * Create an evaluator function for a named path node, expressed in the}
\CommentTok{    * JSONPath like:}
\CommentTok{    *    foo}
\CommentTok{    *    ["bar"]}
\CommentTok{    *    [2]   }
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{nameClause}\NormalTok{(previousExpr, detection ) \{}
     
      \KeywordTok{var} \NormalTok{name = detection[NAME_INDEX],}
            
          \NormalTok{matchesName = ( !name || name == }\StringTok{'*'} \NormalTok{) }
                           \NormalTok{?  always}
                           \NormalTok{:  }\KeywordTok{function}\NormalTok{(ascent)\{}\KeywordTok{return} \FunctionTok{headKey}\NormalTok{(ascent) == name\};}
     

      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(matchesName, previousExpr);}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * Create an evaluator function for a a duck-typed node, expressed like:}
\CommentTok{    * }
\CommentTok{    *    \{spin, taste, colour\}}
\CommentTok{    *    .particle\{spin, taste, colour\}}
\CommentTok{    *    *\{spin, taste, colour\}}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{duckTypeClause}\NormalTok{(previousExpr, detection) \{}

      \KeywordTok{var} \NormalTok{fieldListStr = detection[FIELD_LIST_INDEX];}

      \KeywordTok{if} \NormalTok{(!fieldListStr) }
         \KeywordTok{return} \NormalTok{previousExpr; }\CommentTok{// don't wrap at all, return given expr as-is      }

      \KeywordTok{var} \NormalTok{hasAllrequiredFields = }\FunctionTok{partialComplete}\NormalTok{(}
                                    \NormalTok{hasAllProperties, }
                                    \FunctionTok{arrayAsList}\NormalTok{(}\OtherTok{fieldListStr}\NormalTok{.}\FunctionTok{split}\NormalTok{(}\OtherTok{/}\BaseNTok{\textbackslash{}W}\FloatTok{+}\OtherTok{/}\NormalTok{))}
                                 \NormalTok{),}
                                 
          \NormalTok{isMatch =  }\FunctionTok{compose}\NormalTok{( }
                        \NormalTok{hasAllrequiredFields, }
                        \NormalTok{nodeOf, }
                        \NormalTok{head}
                     \NormalTok{);}

      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(isMatch, previousExpr);}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * Expression for $, returns the evaluator function}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{capture}\NormalTok{( previousExpr, detection ) \{}

      \CommentTok{// extract meaning from the detection      }
      \KeywordTok{var} \NormalTok{capturing = !!detection[CAPTURING_INDEX];}

      \KeywordTok{if} \NormalTok{(!capturing)          }
         \KeywordTok{return} \NormalTok{previousExpr; }\CommentTok{// don't wrap at all, return given expr as-is      }
      
      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(previousExpr, head);}
            
   \NormalTok{\}            }
      
   \CommentTok{/**}
\CommentTok{    * Create an evaluator function that moves onto the next item on the }
\CommentTok{    * lists. This function is the place where the logic to move up a }
\CommentTok{    * level in the ascent exists. }
\CommentTok{    * }
\CommentTok{    * Eg, for JSONPath ".foo" we need skip1(nameClause(always, [,'foo']))}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{skip1}\NormalTok{(previousExpr) \{}
   
   
      \KeywordTok{if}\NormalTok{( previousExpr == always ) \{}
         \CommentTok{/* If there is no previous expression this consume command }
\CommentTok{            is at the start of the jsonPath.}
\CommentTok{            Since JSONPath specifies what we'd like to find but not }
\CommentTok{            necessarily everything leading down to it, when running}
\CommentTok{            out of JSONPath to check against we default to true */}
         \KeywordTok{return} \NormalTok{always;}
      \NormalTok{\}}

      \CommentTok{/** return true if the ascent we have contains only the JSON root,}
\CommentTok{       *  false otherwise}
\CommentTok{       */}
      \KeywordTok{function} \FunctionTok{notAtRoot}\NormalTok{(ascent)\{}
         \KeywordTok{return} \FunctionTok{headKey}\NormalTok{(ascent) != ROOT_PATH;}
      \NormalTok{\}}
      
      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(}
               \CommentTok{/* If we're already at the root but there are more }
\CommentTok{                  expressions to satisfy, can't consume any more. No match.}

\CommentTok{                  This check is why none of the other exprs have to be able }
\CommentTok{                  to handle empty lists; skip1 is the only evaluator that }
\CommentTok{                  moves onto the next token and it refuses to do so once it }
\CommentTok{                  reaches the last item in the list. */}
               \NormalTok{notAtRoot,}
               
               \CommentTok{/* We are not at the root of the ascent yet.}
\CommentTok{                  Move to the next level of the ascent by handing only }
\CommentTok{                  the tail to the previous expression */} 
               \FunctionTok{compose}\NormalTok{(previousExpr, tail) }
      \NormalTok{);}
                                                                                                               
   \NormalTok{\}   }
   
   \CommentTok{/**}
\CommentTok{    * Create an evaluator function for the .. (double dot) token. Consumes}
\CommentTok{    * zero or more levels of the ascent, the fewest that are required to find}
\CommentTok{    * a match when given to previousExpr.}
\CommentTok{    */}   
   \KeywordTok{function} \FunctionTok{skipMany}\NormalTok{(previousExpr) \{}

      \KeywordTok{if}\NormalTok{( previousExpr == always ) \{}
         \CommentTok{/* If there is no previous expression this consume command }
\CommentTok{            is at the start of the jsonPath.}
\CommentTok{            Since JSONPath specifies what we'd like to find but not }
\CommentTok{            necessarily everything leading down to it, when running}
\CommentTok{            out of JSONPath to check against we default to true */}            
         \KeywordTok{return} \NormalTok{always;}
      \NormalTok{\}}
          
      \KeywordTok{var} 
          \CommentTok{// In JSONPath .. is equivalent to !.. so if .. reaches the root}
          \CommentTok{// the match has succeeded. Ie, we might write ..foo or !..foo}
          \CommentTok{// and both should match identically.}
          \NormalTok{terminalCaseWhenArrivingAtRoot = }\FunctionTok{rootExpr}\NormalTok{(),}
          \NormalTok{terminalCaseWhenPreviousExpressionIsSatisfied = previousExpr, }
          \NormalTok{recursiveCase = }\FunctionTok{skip1}\NormalTok{(skipManyInner),}
          
          \NormalTok{cases = }\FunctionTok{lazyUnion}\NormalTok{(}
                     \NormalTok{terminalCaseWhenArrivingAtRoot}
                  \NormalTok{,  terminalCaseWhenPreviousExpressionIsSatisfied}
                  \NormalTok{,  recursiveCase}
                  \NormalTok{);                        }
            
      \KeywordTok{function} \FunctionTok{skipManyInner}\NormalTok{(ascent) \{}
      
         \KeywordTok{if}\NormalTok{( !ascent ) \{}
            \CommentTok{// have gone past the start, not a match:         }
            \KeywordTok{return} \KeywordTok{false}\NormalTok{;}
         \NormalTok{\}      }
                                                        
         \KeywordTok{return} \FunctionTok{cases}\NormalTok{(ascent);}
      \NormalTok{\}}
      
      \KeywordTok{return} \NormalTok{skipManyInner;}
   \NormalTok{\}      }
   
   \CommentTok{/**}
\CommentTok{    * Generate an evaluator for ! - matches only the root element of the json}
\CommentTok{    * and ignores any previous expressions since nothing may precede !. }
\CommentTok{    */}   
   \KeywordTok{function} \FunctionTok{rootExpr}\NormalTok{() \{}
      
      \KeywordTok{return} \KeywordTok{function}\NormalTok{(ascent)\{}
         \KeywordTok{return} \FunctionTok{headKey}\NormalTok{(ascent) == ROOT_PATH;}
      \NormalTok{\};}
   \NormalTok{\}   }
         
   \CommentTok{/**}
\CommentTok{    * Generate a statement wrapper to sit around the outermost }
\CommentTok{    * clause evaluator.}
\CommentTok{    * }
\CommentTok{    * Handles the case where the capturing is implicit because the JSONPath}
\CommentTok{    * did not contain a '$' by returning the last node.}
\CommentTok{    */}   
   \KeywordTok{function} \FunctionTok{statementExpr}\NormalTok{(lastClause) \{}
      
      \KeywordTok{return} \KeywordTok{function}\NormalTok{(ascent) \{}
   
         \CommentTok{// kick off the evaluation by passing through to the last clause}
         \KeywordTok{var} \NormalTok{exprMatch = }\FunctionTok{lastClause}\NormalTok{(ascent);}
                                                     
         \KeywordTok{return} \NormalTok{exprMatch === }\KeywordTok{true} \NormalTok{? }\FunctionTok{head}\NormalTok{(ascent) : exprMatch;}
      \NormalTok{\};}
   \NormalTok{\}      }
                          
   \CommentTok{/**}
\CommentTok{    * For when a token has been found in the JSONPath input.}
\CommentTok{    * Compiles the parser for that token and returns in combination with the}
\CommentTok{    * parser already generated.}
\CommentTok{    * }
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ exprs  a list of the clause evaluator generators for}
\CommentTok{    *                          the token that was found}
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ parserGeneratedSoFar the parser already found}
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Array\}}\CommentTok{ detection the match given by the regex engine when }
\CommentTok{    *                          the feature was found}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{expressionsReader}\NormalTok{( exprs, parserGeneratedSoFar, detection ) \{}
                     
      \CommentTok{// if exprs is zero-length foldR will pass back the }
      \CommentTok{// parserGeneratedSoFar as-is so we don't need to treat }
      \CommentTok{// this as a special case}
      
      \KeywordTok{return}   \FunctionTok{foldR}\NormalTok{( }
                  \KeywordTok{function}\NormalTok{( parserGeneratedSoFar, expr )\{}
         
                     \KeywordTok{return} \FunctionTok{expr}\NormalTok{(parserGeneratedSoFar, detection);}
                  \NormalTok{\}, }
                  \NormalTok{parserGeneratedSoFar, }
                  \NormalTok{exprs}
               \NormalTok{);                     }

   \NormalTok{\}}

   \CommentTok{/** }
\CommentTok{    *  If jsonPath matches the given detector function, creates a function which}
\CommentTok{    *  evaluates against every clause in the clauseEvaluatorGenerators. The}
\CommentTok{    *  created function is propagated to the onSuccess function, along with}
\CommentTok{    *  the remaining unparsed JSONPath substring.}
\CommentTok{    *  }
\CommentTok{    *  The intended use is to create a clauseMatcher by filling in}
\CommentTok{    *  the first two arguments, thus providing a function that knows}
\CommentTok{    *  some syntax to match and what kind of generator to create if it}
\CommentTok{    *  finds it. The parameter list once completed is:}
\CommentTok{    *  }
\CommentTok{    *    (jsonPath, parserGeneratedSoFar, onSuccess)}
\CommentTok{    *  }
\CommentTok{    *  onSuccess may be compileJsonPathToFunction, to recursively continue }
\CommentTok{    *  parsing after finding a match or returnFoundParser to stop here.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{generateClauseReaderIfTokenFound} \NormalTok{(}
     
                        \NormalTok{tokenDetector, clauseEvaluatorGenerators,}
                         
                        \NormalTok{jsonPath, parserGeneratedSoFar, onSuccess) \{}
                        
      \KeywordTok{var} \NormalTok{detected = }\FunctionTok{tokenDetector}\NormalTok{(jsonPath);}

      \KeywordTok{if}\NormalTok{(detected) \{}
         \KeywordTok{var} \NormalTok{compiledParser = }\FunctionTok{expressionsReader}\NormalTok{(}
                                 \NormalTok{clauseEvaluatorGenerators, }
                                 \NormalTok{parserGeneratedSoFar, }
                                 \NormalTok{detected}
                              \NormalTok{),}
         
             \NormalTok{remainingUnparsedJsonPath = }\OtherTok{jsonPath}\NormalTok{.}\FunctionTok{substr}\NormalTok{(}\FunctionTok{len}\NormalTok{(detected[}\DecValTok{0}\NormalTok{]));                }
                               
         \KeywordTok{return} \FunctionTok{onSuccess}\NormalTok{(remainingUnparsedJsonPath, compiledParser);}
      \NormalTok{\}         }
   \NormalTok{\}}
                 
   \CommentTok{/**}
\CommentTok{    * Partially completes generateClauseReaderIfTokenFound above. }
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{clauseMatcher}\NormalTok{(tokenDetector, exprs) \{}
        
      \KeywordTok{return}   \FunctionTok{partialComplete}\NormalTok{( }
                  \NormalTok{generateClauseReaderIfTokenFound, }
                  \NormalTok{tokenDetector, }
                  \NormalTok{exprs }
               \NormalTok{);}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * clauseForJsonPath is a function which attempts to match against }
\CommentTok{    * several clause matchers in order until one matches. If non match the}
\CommentTok{    * jsonPath expression is invalid and an error is thrown.}
\CommentTok{    * }
\CommentTok{    * The parameter list is the same as a single clauseMatcher:}
\CommentTok{    * }
\CommentTok{    *    (jsonPath, parserGeneratedSoFar, onSuccess)}
\CommentTok{    */}     
   \KeywordTok{var} \NormalTok{clauseForJsonPath = }\FunctionTok{lazyUnion}\NormalTok{(}

      \FunctionTok{clauseMatcher}\NormalTok{(pathNodeSyntax   , }\FunctionTok{list}\NormalTok{( capture, }
                                             \NormalTok{duckTypeClause, }
                                             \NormalTok{nameClause, }
                                             \NormalTok{skip1 ))}
                                                     
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(doubleDotSyntax  , }\FunctionTok{list}\NormalTok{( skipMany))}
       
       \CommentTok{// dot is a separator only (like whitespace in other languages) but }
       \CommentTok{// rather than make it a special case, use an empty list of }
       \CommentTok{// expressions when this token is found}
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(dotSyntax        , }\FunctionTok{list}\NormalTok{() )  }
                                                                                      
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(bangSyntax       , }\FunctionTok{list}\NormalTok{( capture,}
                                             \NormalTok{rootExpr))}
                                                          
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(emptySyntax      , }\FunctionTok{list}\NormalTok{( statementExpr))}
   
   \NormalTok{,  }\KeywordTok{function} \NormalTok{(jsonPath) \{}
         \KeywordTok{throw} \FunctionTok{Error}\NormalTok{(}\StringTok{'"'} \NormalTok{+ jsonPath + }\StringTok{'" could not be tokenised'}\NormalTok{)      }
      \NormalTok{\}}
   \NormalTok{);}


   \CommentTok{/**}
\CommentTok{    * One of two possible values for the onSuccess argument of }
\CommentTok{    * generateClauseReaderIfTokenFound.}
\CommentTok{    * }
\CommentTok{    * When this function is used, generateClauseReaderIfTokenFound simply }
\CommentTok{    * returns the compiledParser that it made, regardless of if there is }
\CommentTok{    * any remaining jsonPath to be compiled.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{returnFoundParser}\NormalTok{(_remainingJsonPath, compiledParser)\{ }
      \KeywordTok{return} \NormalTok{compiledParser }
   \NormalTok{\}     }
              
   \CommentTok{/**}
\CommentTok{    * Recursively compile a JSONPath expression.}
\CommentTok{    * }
\CommentTok{    * This function serves as one of two possible values for the onSuccess }
\CommentTok{    * argument of generateClauseReaderIfTokenFound, meaning continue to}
\CommentTok{    * recursively compile. Otherwise, returnFoundParser is given and}
\CommentTok{    * compilation terminates.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{compileJsonPathToFunction}\NormalTok{( uncompiledJsonPath, }
                                       \NormalTok{parserGeneratedSoFar ) \{}

      \CommentTok{/**}
\CommentTok{       * On finding a match, if there is remaining text to be compiled}
\CommentTok{       * we want to either continue parsing using a recursive call to }
\CommentTok{       * compileJsonPathToFunction. Otherwise, we want to stop and return }
\CommentTok{       * the parser that we have found so far.}
\CommentTok{       */}
      \KeywordTok{var} \NormalTok{onFind =      uncompiledJsonPath}
                     \NormalTok{?  compileJsonPathToFunction }
                     \NormalTok{:  returnFoundParser;}
                   
      \KeywordTok{return}   \FunctionTok{clauseForJsonPath}\NormalTok{( }
                  \NormalTok{uncompiledJsonPath, }
                  \NormalTok{parserGeneratedSoFar, }
                  \NormalTok{onFind}
               \NormalTok{);                              }
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * This is the function that we expose to the rest of the library.}
\CommentTok{    */}
   \KeywordTok{return} \KeywordTok{function}\NormalTok{(jsonPath)\{}
        
      \KeywordTok{try} \NormalTok{\{}
         \CommentTok{// Kick off the recursive parsing of the jsonPath }
         \KeywordTok{return} \FunctionTok{compileJsonPathToFunction}\NormalTok{(jsonPath, always);}
         
      \NormalTok{\} }\KeywordTok{catch}\NormalTok{( e ) \{}
         \KeywordTok{throw} \FunctionTok{Error}\NormalTok{( }\StringTok{'Could not compile "'} \NormalTok{+ jsonPath + }
                      \StringTok{'" because '} \NormalTok{+ }\OtherTok{e}\NormalTok{.}\FunctionTok{message}
         \NormalTok{);}
      \NormalTok{\}}
   \NormalTok{\}}

\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{jsonPathSyntax.js}\label{headerux5fjsonPathSyntax}

\label{src_jsonPathSyntax}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var} \NormalTok{jsonPathSyntax = (}\KeywordTok{function}\NormalTok{() \{}
 
   \KeywordTok{var}
   
   \CommentTok{/** }
\CommentTok{    * Export a regular expression as a simple function by exposing just }
\CommentTok{    * the Regex#exec. This allows regex tests to be used under the same }
\CommentTok{    * interface as differently implemented tests, or for a user of the}
\CommentTok{    * tests to not concern themselves with their implementation as regular}
\CommentTok{    * expressions.}
\CommentTok{    * }
\CommentTok{    * This could also be expressed point-free as:}
\CommentTok{    *   Function.prototype.bind.bind(RegExp.prototype.exec),}
\CommentTok{    *   }
\CommentTok{    * But that's far too confusing! (and not even smaller once minified }
\CommentTok{    * and gzipped)}
\CommentTok{    */}
       \NormalTok{regexDescriptor = }\KeywordTok{function} \FunctionTok{regexDescriptor}\NormalTok{(regex) \{}
            \KeywordTok{return} \OtherTok{regex}\NormalTok{.}\OtherTok{exec}\NormalTok{.}\FunctionTok{bind}\NormalTok{(regex);}
       \NormalTok{\}}
       
   \CommentTok{/**}
\CommentTok{    * Join several regular expressions and express as a function.}
\CommentTok{    * This allows the token patterns to reuse component regular expressions}
\CommentTok{    * instead of being expressed in full using huge and confusing regular}
\CommentTok{    * expressions.}
\CommentTok{    */}       
   \NormalTok{,   jsonPathClause = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{( componentRegexes ) \{}

            \CommentTok{// The regular expressions all start with ^ because we }
            \CommentTok{// only want to find matches at the start of the }
            \CommentTok{// JSONPath fragment we are inspecting           }
            \OtherTok{componentRegexes}\NormalTok{.}\FunctionTok{unshift}\NormalTok{(}\OtherTok{/}\FloatTok{^}\OtherTok{/}\NormalTok{);}
            
            \KeywordTok{return}   \FunctionTok{regexDescriptor}\NormalTok{(}
                        \FunctionTok{RegExp}\NormalTok{(}
                           \OtherTok{componentRegexes}\NormalTok{.}\FunctionTok{map}\NormalTok{(}\FunctionTok{attr}\NormalTok{(}\StringTok{'source'}\NormalTok{)).}\FunctionTok{join}\NormalTok{(}\StringTok{''}\NormalTok{)}
                        \NormalTok{)}
                     \NormalTok{);}
       \NormalTok{\})}
       
   \NormalTok{,   possiblyCapturing =           }\OtherTok{/}\FloatTok{(\textbackslash{}$?)}\OtherTok{/}
   \NormalTok{,   namedNode =                   }\OtherTok{/}\FloatTok{(}\BaseNTok{[}\FloatTok{\textbackslash{}w}\BaseNTok{-_]}\FloatTok{+|\textbackslash{}*)}\OtherTok{/}
   \NormalTok{,   namePlaceholder =             }\OtherTok{/}\FloatTok{()}\OtherTok{/}
   \NormalTok{,   nodeInArrayNotation =         }\OtherTok{/}\FloatTok{\textbackslash{}[}\OtherTok{"}\FloatTok{(}\BaseNTok{[}\FloatTok{^}\BaseNTok{"]}\FloatTok{+)}\OtherTok{"}\FloatTok{\textbackslash{}]}\OtherTok{/}
   \NormalTok{,   numberedNodeInArrayNotation = }\OtherTok{/}\FloatTok{\textbackslash{}[(}\BaseNTok{\textbackslash{}d}\FloatTok{+|\textbackslash{}*)\textbackslash{}]}\OtherTok{/}
   \NormalTok{,   fieldList =                      }\OtherTok{/\{}\FloatTok{(}\BaseNTok{[}\FloatTok{\textbackslash{}w}\BaseNTok{ ]}\FloatTok{*?)}\OtherTok{\}/}
   \NormalTok{,   optionalFieldList =           }\OtherTok{/}\FloatTok{(?}\OtherTok{:\{}\FloatTok{(}\BaseNTok{[}\FloatTok{\textbackslash{}w}\BaseNTok{ ]}\FloatTok{*?)}\OtherTok{\}}\FloatTok{)?}\OtherTok{/}
    

       \CommentTok{//   foo or *                  }
   \NormalTok{,   jsonPathNamedNodeInObjectNotation   = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{namedNode, }
                                                \NormalTok{optionalFieldList}
                                             \NormalTok{)}
                                             
       \CommentTok{//   ["foo"]   }
   \NormalTok{,   jsonPathNamedNodeInArrayNotation    = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{nodeInArrayNotation, }
                                                \NormalTok{optionalFieldList}
                                             \NormalTok{)  }

       \CommentTok{//   [2] or [*]       }
   \NormalTok{,   jsonPathNumberedNodeInArrayNotation = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{numberedNodeInArrayNotation, }
                                                \NormalTok{optionalFieldList}
                                             \NormalTok{)}

       \CommentTok{//   \{a b c\}      }
   \NormalTok{,   jsonPathPureDuckTyping              = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{namePlaceholder, }
                                                \NormalTok{fieldList}
                                             \NormalTok{)}
   
       \CommentTok{//   ..}
   \NormalTok{,   jsonPathDoubleDot                   = }\FunctionTok{jsonPathClause}\NormalTok{(}\OtherTok{/}\FloatTok{\textbackslash{}.\textbackslash{}.}\OtherTok{/}\NormalTok{)                  }
   
       \CommentTok{//   .}
   \NormalTok{,   jsonPathDot                         = }\FunctionTok{jsonPathClause}\NormalTok{(}\OtherTok{/}\FloatTok{\textbackslash{}.}\OtherTok{/}\NormalTok{)                    }
   
       \CommentTok{//   !}
   \NormalTok{,   jsonPathBang                        = }\FunctionTok{jsonPathClause}\NormalTok{(}
                                                \NormalTok{possiblyCapturing, }
                                                \OtherTok{/!/}
                                             \NormalTok{)  }
   
       \CommentTok{//   nada!}
   \NormalTok{,   emptyString                         = }\FunctionTok{jsonPathClause}\NormalTok{(}\OtherTok{/}\FloatTok{$}\OtherTok{/}\NormalTok{)                     }
   
   \NormalTok{;}
   
  
   \CommentTok{/* We export only a single function. When called, this function injects }
\CommentTok{      into another function the descriptors from above.             }
\CommentTok{    */}
   \KeywordTok{return} \KeywordTok{function} \NormalTok{(fn)\{      }
      \KeywordTok{return} \FunctionTok{fn}\NormalTok{(      }
         \FunctionTok{lazyUnion}\NormalTok{(}
            \NormalTok{jsonPathNamedNodeInObjectNotation}
         \NormalTok{,  jsonPathNamedNodeInArrayNotation}
         \NormalTok{,  jsonPathNumberedNodeInArrayNotation}
         \NormalTok{,  jsonPathPureDuckTyping }
         \NormalTok{)}
      \NormalTok{,  jsonPathDoubleDot}
      \NormalTok{,  jsonPathDot}
      \NormalTok{,  jsonPathBang}
      \NormalTok{,  emptyString }
      \NormalTok{);}
   \NormalTok{\}; }

\NormalTok{\}());}
\end{Highlighting}
\end{Shaded}

\pagebreak

\hyperdef{}{headerux5flists}{\subsection{lists.js}\label{headerux5flists}}

\label{src_lists}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * Like cons in Lisp}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{cons}\NormalTok{(x, xs) \{}
   
   \CommentTok{/* Internally lists are linked 2-element Javascript arrays.}
\CommentTok{    }
\CommentTok{      So that lists are all immutable we Object.freeze in newer }
\CommentTok{      Javascript runtimes.}
\CommentTok{      }
\CommentTok{      In older engines freeze should have been polyfilled as the }
\CommentTok{      identity function. */}
   \KeywordTok{return} \OtherTok{Object}\NormalTok{.}\FunctionTok{freeze}\NormalTok{([x,xs]);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * The empty list}
\CommentTok{ */}
\KeywordTok{var} \NormalTok{emptyList = }\KeywordTok{null}\NormalTok{,}

\CommentTok{/**}
\CommentTok{ * Get the head of a list.}
\CommentTok{ * }
\CommentTok{ * Ie, head(cons(a,b)) = a}
\CommentTok{ */}
    \NormalTok{head = }\FunctionTok{attr}\NormalTok{(}\DecValTok{0}\NormalTok{),}

\CommentTok{/**}
\CommentTok{ * Get the tail of a list.}
\CommentTok{ * }
\CommentTok{ * Ie, head(cons(a,b)) = a}
\CommentTok{ */}
    \NormalTok{tail = }\FunctionTok{attr}\NormalTok{(}\DecValTok{1}\NormalTok{);}


\CommentTok{/** }
\CommentTok{ * Converts an array to a list }
\CommentTok{ * }
\CommentTok{ *    asList([a,b,c])}
\CommentTok{ * }
\CommentTok{ * is equivalent to:}
\CommentTok{ *    }
\CommentTok{ *    cons(a, cons(b, cons(c, emptyList))) }
\CommentTok{ **/}
\KeywordTok{function} \FunctionTok{arrayAsList}\NormalTok{(inputArray)\{}

   \KeywordTok{return} \FunctionTok{reverseList}\NormalTok{( }
      \OtherTok{inputArray}\NormalTok{.}\FunctionTok{reduce}\NormalTok{(}
         \FunctionTok{flip}\NormalTok{(cons),}
         \NormalTok{emptyList }
      \NormalTok{)}
   \NormalTok{);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * A varargs version of arrayAsList. Works a bit like list}
\CommentTok{ * in LISP.}
\CommentTok{ * }
\CommentTok{ *    list(a,b,c) }
\CommentTok{ *    }
\CommentTok{ * is equivalent to:}
\CommentTok{ * }
\CommentTok{ *    cons(a, cons(b, cons(c, emptyList)))}
\CommentTok{ */}
\KeywordTok{var} \NormalTok{list = }\FunctionTok{varArgs}\NormalTok{(arrayAsList);}

\CommentTok{/**}
\CommentTok{ * Convert a list back to a js native array}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{listAsArray}\NormalTok{(list)\{}

   \KeywordTok{return} \FunctionTok{foldR}\NormalTok{( }\KeywordTok{function}\NormalTok{(arraySoFar, listItem)\{}
      
      \OtherTok{arraySoFar}\NormalTok{.}\FunctionTok{unshift}\NormalTok{(listItem);}
      \KeywordTok{return} \NormalTok{arraySoFar;}
           
   \NormalTok{\}, [], list );}
   
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Map a function over a list }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{map}\NormalTok{(fn, list) \{}

   \KeywordTok{return} \NormalTok{list}
            \NormalTok{? }\FunctionTok{cons}\NormalTok{(}\FunctionTok{fn}\NormalTok{(}\FunctionTok{head}\NormalTok{(list)), }\FunctionTok{map}\NormalTok{(fn,}\FunctionTok{tail}\NormalTok{(list)))}
            \NormalTok{: emptyList}
            \NormalTok{;}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * foldR implementation. Reduce a list down to a single value.}
\CommentTok{ * }
\CommentTok{ * }\NormalTok{@pram}\CommentTok{ \{Function\} fn     (rightEval, curVal) -> result }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{foldR}\NormalTok{(fn, startValue, list) \{}
      
   \KeywordTok{return} \NormalTok{list }
            \NormalTok{? }\FunctionTok{fn}\NormalTok{(}\FunctionTok{foldR}\NormalTok{(fn, startValue, }\FunctionTok{tail}\NormalTok{(list)), }\FunctionTok{head}\NormalTok{(list))}
            \NormalTok{: startValue}
            \NormalTok{;}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Return a list like the one given but with the first instance equal }
\CommentTok{ * to item removed }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{without}\NormalTok{(list, item) \{}
 
  \KeywordTok{return} \NormalTok{list  }
            \NormalTok{?  ( }\FunctionTok{head}\NormalTok{(list) == item }
                     \NormalTok{? }\FunctionTok{tail}\NormalTok{(list) }
                     \NormalTok{: }\FunctionTok{cons}\NormalTok{(}\FunctionTok{head}\NormalTok{(list), }\FunctionTok{without}\NormalTok{(}\FunctionTok{tail}\NormalTok{(list), item))}
               \NormalTok{) }
            \NormalTok{: emptyList}
            \NormalTok{;}
\NormalTok{\}}

\CommentTok{/** }
\CommentTok{ * Returns true if the given function holds for every item in }
\CommentTok{ * the list, false otherwise }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{all}\NormalTok{(fn, list) \{}
   
   \KeywordTok{return} \NormalTok{!list || }
          \FunctionTok{fn}\NormalTok{(}\FunctionTok{head}\NormalTok{(list)) && }\FunctionTok{all}\NormalTok{(fn, }\FunctionTok{tail}\NormalTok{(list));}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Call every function in a list of functions}
\CommentTok{ * }
\CommentTok{ * This doesn't make any sense if we're doing pure functional because }
\CommentTok{ * it doesn't return anything. Hence, this is only really useful if the}
\CommentTok{ * functions being called have side-effects. }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{applyEach}\NormalTok{(args, list) \{}

   \KeywordTok{if}\NormalTok{( list ) \{  }
      \FunctionTok{apply}\NormalTok{(args, }\FunctionTok{head}\NormalTok{(list))}
      
      \FunctionTok{applyEach}\NormalTok{(args, }\FunctionTok{tail}\NormalTok{(list));}
   \NormalTok{\}}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Reverse the order of a list}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{reverseList}\NormalTok{(list)\{ }

   \CommentTok{// js re-implementation of 3rd solution from:}
   \CommentTok{//    http://www.haskell.org/haskellwiki/99_questions/Solutions/5}
   \KeywordTok{function} \FunctionTok{reverseInner}\NormalTok{( list, reversedAlready ) \{}
      \KeywordTok{if}\NormalTok{( !list ) \{}
         \KeywordTok{return} \NormalTok{reversedAlready;}
      \NormalTok{\}}
      
      \KeywordTok{return} \FunctionTok{reverseInner}\NormalTok{(}\FunctionTok{tail}\NormalTok{(list), }\FunctionTok{cons}\NormalTok{(}\FunctionTok{head}\NormalTok{(list), reversedAlready))}
   \NormalTok{\}}

   \KeywordTok{return} \FunctionTok{reverseInner}\NormalTok{(list, emptyList);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{parseResponseHeaders.browser.js}\label{headerux5fparseResponseHeaders.browser}

\label{src_parseResponseHeaders.browser}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// based on gist https://gist.github.com/monsur/706839}

\CommentTok{/**}
\CommentTok{ * XmlHttpRequest's getAllResponseHeaders() method returns a string of response}
\CommentTok{ * headers according to the format described here:}
\CommentTok{ * http://www.w3.org/TR/XMLHttpRequest/#the-getallresponseheaders-method}
\CommentTok{ * This method parses that string into a user-friendly key/value pair object.}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{parseResponseHeaders}\NormalTok{(headerStr) \{}
   \KeywordTok{var} \NormalTok{headers = \{\};}
   
   \NormalTok{headerStr && }\OtherTok{headerStr}\NormalTok{.}\FunctionTok{split}\NormalTok{(}\StringTok{'\textbackslash{}u000d\textbackslash{}u000a'}\NormalTok{)}
      \NormalTok{.}\FunctionTok{forEach}\NormalTok{(}\KeywordTok{function}\NormalTok{(headerPair)\{}
   
         \CommentTok{// Can't use split() here because it does the wrong thing}
         \CommentTok{// if the header value has the string ": " in it.}
         \KeywordTok{var} \NormalTok{index = }\OtherTok{headerPair}\NormalTok{.}\FunctionTok{indexOf}\NormalTok{(}\StringTok{'\textbackslash{}u003a\textbackslash{}u0020'}\NormalTok{);}
         
         \NormalTok{headers[}\OtherTok{headerPair}\NormalTok{.}\FunctionTok{substring}\NormalTok{(}\DecValTok{0}\NormalTok{, index)] }
                     \NormalTok{= }\OtherTok{headerPair}\NormalTok{.}\FunctionTok{substring}\NormalTok{(index + }\DecValTok{2}\NormalTok{);}
      \NormalTok{\});}
   
   \KeywordTok{return} \NormalTok{headers;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{patternAdapter.js}\label{headerux5fpatternAdapter}

\label{src_patternAdapter}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{patternAdapter}\NormalTok{(bus, jsonPathCompiler) \{}

   \KeywordTok{function} \FunctionTok{addUnderlyingListener}\NormalTok{( matchEventName, predicateEventName, pattern )\{}

      \KeywordTok{var} \NormalTok{compiledJsonPath = }\FunctionTok{jsonPathCompiler}\NormalTok{( pattern );}
   
      \OtherTok{bus}\NormalTok{.}\FunctionTok{on}\NormalTok{(predicateEventName, }\KeywordTok{function} \NormalTok{(ascent) \{}

         \KeywordTok{var} \NormalTok{maybeMatchingMapping = }\FunctionTok{compiledJsonPath}\NormalTok{(ascent);}

         \CommentTok{/* Possible values for maybeMatchingMapping are now:}

\CommentTok{          false: }
\CommentTok{          we did not match }

\CommentTok{          an object/array/string/number/null: }
\CommentTok{          we matched and have the node that matched.}
\CommentTok{          Because nulls are valid json values this can be null.}

\CommentTok{          undefined:}
\CommentTok{          we matched but don't have the matching node yet.}
\CommentTok{          ie, we know there is an upcoming node that matches but we }
\CommentTok{          can't say anything else about it. }
\CommentTok{          */}
         \KeywordTok{if} \NormalTok{(maybeMatchingMapping !== }\KeywordTok{false}\NormalTok{) \{}
             
            \OtherTok{bus}\NormalTok{.}\FunctionTok{emit}\NormalTok{(matchEventName, }\FunctionTok{nodeOf}\NormalTok{(maybeMatchingMapping), ascent);}
         \NormalTok{\}}
      \NormalTok{\}, matchEventName);}
   
   
      \OtherTok{bus}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'removeListener'}\NormalTok{, }\KeywordTok{function}\NormalTok{(removedEventName)\{}
   
         \CommentTok{// if the match even listener is later removed, clean up by removing}
         \CommentTok{// the underlying listener if nothing else is using that pattern:}
      
         \KeywordTok{if}\NormalTok{( removedEventName == matchEventName ) \{}
         
            \KeywordTok{if}\NormalTok{( !}\OtherTok{bus}\NormalTok{.}\FunctionTok{listeners}\NormalTok{( removedEventName )) \{}
               \OtherTok{bus}\NormalTok{.}\FunctionTok{un}\NormalTok{( predicateEventName, matchEventName );}
            \NormalTok{\}}
         \NormalTok{\}}
      \NormalTok{\});   }
   \NormalTok{\}}

   \OtherTok{bus}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'newListener'}\NormalTok{, }\KeywordTok{function}\NormalTok{(matchEventName)\{}

      \KeywordTok{var} \NormalTok{match = }\OtherTok{/}\FloatTok{(}\BaseNTok{\textbackslash{}w}\FloatTok{+)}\OtherTok{:}\FloatTok{(}\OtherTok{.}\FloatTok{*)}\OtherTok{/}\NormalTok{.}\FunctionTok{exec}\NormalTok{(matchEventName),}
          \NormalTok{predicateEventName = match && \{}\DataTypeTok{node}\NormalTok{:NODE_FOUND, }\DataTypeTok{path}\NormalTok{:PATH_FOUND\}[match[}\DecValTok{1}\NormalTok{]];}
                    
      \KeywordTok{if}\NormalTok{( predicateEventName && !}\OtherTok{bus}\NormalTok{.}\FunctionTok{hasListener}\NormalTok{(predicateEventName, matchEventName) ) \{  }
               
         \FunctionTok{addUnderlyingListener}\NormalTok{(}
            \NormalTok{matchEventName,}
            \NormalTok{predicateEventName, }
            \NormalTok{match[}\DecValTok{2}\NormalTok{]}
         \NormalTok{);}
      \NormalTok{\}    }
   \NormalTok{\})}

\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{pubSub.js}\label{headerux5fpubSub}

\label{src_pubSub}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * Isn't this the cutest little pub-sub you've ever seen?}
\CommentTok{ * }
\CommentTok{ * Over time this should be refactored towards a Node-like}
\CommentTok{ *    EventEmitter so that under Node an actual EE acn be used.}
\CommentTok{ *    http://nodejs.org/api/events.html}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{pubSub}\NormalTok{()\{}

   \KeywordTok{var} \NormalTok{listeners = \{\};}
                             
   \KeywordTok{return} \NormalTok{\{}

      \DataTypeTok{on}\NormalTok{:}\KeywordTok{function}\NormalTok{( eventId, fn ) \{}
         
         \NormalTok{listeners[eventId] = }\FunctionTok{cons}\NormalTok{(fn, listeners[eventId]);}

         \KeywordTok{return} \KeywordTok{this}\NormalTok{; }\CommentTok{// chaining}
      \NormalTok{\}, }
    
      \DataTypeTok{emit}\NormalTok{:}\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function} \NormalTok{( eventId, parameters ) \{}
                                             
         \FunctionTok{applyEach}\NormalTok{( }
            \NormalTok{parameters, }
            \NormalTok{listeners[eventId]}
         \NormalTok{);}
      \NormalTok{\}),}
      
      \DataTypeTok{un}\NormalTok{: }\KeywordTok{function}\NormalTok{( eventId, handler ) \{}
         \NormalTok{listeners[eventId] = }\FunctionTok{without}\NormalTok{(listeners[eventId], handler);}
      \NormalTok{\}           }
   \NormalTok{\};}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{publicApi.js}\label{headerux5fpublicApi}

\label{src_publicApi}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// export public API}
\KeywordTok{function} \FunctionTok{apiMethod}\NormalTok{(defaultHttpMethod, arg1, arg2) \{}

   \KeywordTok{if} \NormalTok{(}\OtherTok{arg1}\NormalTok{.}\FunctionTok{url}\NormalTok{) \{}

      \CommentTok{// method signature is:}
      \CommentTok{//    oboe(\{method:m, url:u, body:b, headers:\{...\}\})}

      \KeywordTok{return} \FunctionTok{wire}\NormalTok{(}
         \NormalTok{(}\OtherTok{arg1}\NormalTok{.}\FunctionTok{method} \NormalTok{|| defaultHttpMethod),}
         \OtherTok{arg1}\NormalTok{.}\FunctionTok{url}\NormalTok{,}
         \OtherTok{arg1}\NormalTok{.}\FunctionTok{body}\NormalTok{,}
         \OtherTok{arg1}\NormalTok{.}\FunctionTok{headers}
      \NormalTok{);}
   \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}

      \CommentTok{//  simple version for GETs. Signature is:}
      \CommentTok{//    oboe( url )            }
      \CommentTok{//                                }
      \KeywordTok{return} \FunctionTok{wire}\NormalTok{(}
         \NormalTok{defaultHttpMethod,}
         \NormalTok{arg1, }\CommentTok{// url}
         \NormalTok{arg2  }\CommentTok{// body. Deprecated, use \{url:u, body:b\} instead}
      \NormalTok{);}
   \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{var} \NormalTok{oboe = }\FunctionTok{partialComplete}\NormalTok{(apiMethod, }\StringTok{'GET'}\NormalTok{);}
\CommentTok{// add deprecated methods, to be removed in v2.0.0:}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doGet}    \NormalTok{= oboe;}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doDelete} \NormalTok{= }\FunctionTok{partialComplete}\NormalTok{(apiMethod, }\StringTok{'DELETE'}\NormalTok{);}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doPost}   \NormalTok{= }\FunctionTok{partialComplete}\NormalTok{(apiMethod, }\StringTok{'POST'}\NormalTok{);}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doPut}    \NormalTok{= }\FunctionTok{partialComplete}\NormalTok{(apiMethod, }\StringTok{'PUT'}\NormalTok{);}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doPatch}  \NormalTok{= }\FunctionTok{partialComplete}\NormalTok{(apiMethod, }\StringTok{'PATCH'}\NormalTok{);}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{streamingHttp.browser.js}\label{headerux5fstreamingHttp.browser}

\label{src_streamingHttp.browser}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{httpTransport}\NormalTok{()\{}
   \KeywordTok{return} \KeywordTok{new} \FunctionTok{XMLHttpRequest}\NormalTok{();}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * A wrapper around the browser XmlHttpRequest object that raises an }
\CommentTok{ * event whenever a new part of the response is available.}
\CommentTok{ * }
\CommentTok{ * In older browsers progressive reading is impossible so all the }
\CommentTok{ * content is given in a single call. For newer ones several events}
\CommentTok{ * should be raised, allowing progressive interpretation of the response.}
\CommentTok{ *      }
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ emit a function to pass events to when something happens}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ on a function to use to subscribe to events}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{XMLHttpRequest\}}\CommentTok{ xhr the xhr to use as the transport. Under normal}
\CommentTok{ *          operation, will have been created using httpTransport() above}
\CommentTok{ *          but for tests a stub can be provided instead.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ method one of 'GET' 'POST' 'PUT' 'PATCH' 'DELETE'}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ url the url to make a request to}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String|Object\}}\CommentTok{ data some content to be sent with the request.}
\CommentTok{ *                        Only valid if method is POST or PUT.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Object\}}\CommentTok{ [headers] the http request headers to send                       }
\CommentTok{ */}  
\KeywordTok{function} \FunctionTok{streamingHttp}\NormalTok{(emit, on, xhr, method, url, data, headers) \{}
        
   \KeywordTok{var} \NormalTok{numberOfCharsAlreadyGivenToCallback = }\DecValTok{0}\NormalTok{;}

   \CommentTok{// When an ABORTING message is put on the event bus abort }
   \CommentTok{// the ajax request         }
   \FunctionTok{on}\NormalTok{( ABORTING, }\KeywordTok{function}\NormalTok{()\{}
  
      \CommentTok{// if we keep the onreadystatechange while aborting the XHR gives }
      \CommentTok{// a callback like a successful call so first remove this listener}
      \CommentTok{// by assigning null:}
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{onreadystatechange} \NormalTok{= }\KeywordTok{null}\NormalTok{;}
            
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{abort}\NormalTok{();}
   \NormalTok{\});}

   \CommentTok{/** Given a value from the user to send as the request body, return in}
\CommentTok{    *  a form that is suitable to sending over the wire. Returns either a }
\CommentTok{    *  string, or null.        }
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{validatedRequestBody}\NormalTok{( body ) \{}
      \KeywordTok{if}\NormalTok{( !body )}
         \KeywordTok{return} \KeywordTok{null}\NormalTok{;}
   
      \KeywordTok{return} \FunctionTok{isString}\NormalTok{(body)? body: }\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(body);}
   \NormalTok{\}      }

   \CommentTok{/** }
\CommentTok{    * Handle input from the underlying xhr: either a state change,}
\CommentTok{    * the progress event or the request being complete.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{handleProgress}\NormalTok{() \{}
                        
      \KeywordTok{var} \NormalTok{textSoFar = }\OtherTok{xhr}\NormalTok{.}\FunctionTok{responseText}\NormalTok{,}
          \NormalTok{newText = }\OtherTok{textSoFar}\NormalTok{.}\FunctionTok{substr}\NormalTok{(numberOfCharsAlreadyGivenToCallback);}
      
      
      \CommentTok{/* Raise the event for new text.}
\CommentTok{      }
\CommentTok{         On older browsers, the new text is the whole response. }
\CommentTok{         On newer/better ones, the fragment part that we got since }
\CommentTok{         last progress. */}
         
      \KeywordTok{if}\NormalTok{( newText ) \{}
         \FunctionTok{emit}\NormalTok{( STREAM_DATA, newText );}
      \NormalTok{\} }

      \NormalTok{numberOfCharsAlreadyGivenToCallback = }\FunctionTok{len}\NormalTok{(textSoFar);}
   \NormalTok{\}}
   
   
   \KeywordTok{if}\NormalTok{(}\StringTok{'onprogress'} \KeywordTok{in} \NormalTok{xhr)\{  }\CommentTok{// detect browser support for progressive delivery}
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{onprogress} \NormalTok{= handleProgress;}
   \NormalTok{\}}
   
   \OtherTok{xhr}\NormalTok{.}\FunctionTok{onreadystatechange} \NormalTok{= }\KeywordTok{function}\NormalTok{() \{}
      
      \KeywordTok{switch}\NormalTok{( }\OtherTok{xhr}\NormalTok{.}\FunctionTok{readyState} \NormalTok{) \{}
               
         \KeywordTok{case} \DecValTok{2}\NormalTok{:       }
         
            \FunctionTok{emit}\NormalTok{(}
               \NormalTok{HTTP_START, }
               \OtherTok{xhr}\NormalTok{.}\FunctionTok{status}\NormalTok{,}
               \FunctionTok{parseResponseHeaders}\NormalTok{(}\OtherTok{xhr}\NormalTok{.}\FunctionTok{getAllResponseHeaders}\NormalTok{()) );}
            \KeywordTok{return}\NormalTok{;}
            
         \KeywordTok{case} \DecValTok{4}\NormalTok{:       }
            \CommentTok{// is this a 2xx http code?}
            \KeywordTok{var} \NormalTok{sucessful = }\FunctionTok{String}\NormalTok{(}\OtherTok{xhr}\NormalTok{.}\FunctionTok{status}\NormalTok{)[}\DecValTok{0}\NormalTok{] == }\DecValTok{2}\NormalTok{;}
            
            \KeywordTok{if}\NormalTok{( sucessful ) \{}
               \CommentTok{// In Chrome 29 (not 28) no onprogress is emitted when a response}
               \CommentTok{// is complete before the onload. We need to always do handleInput}
               \CommentTok{// in case we get the load but have not had a final progress event.}
               \CommentTok{// This looks like a bug and may change in future but let's take}
               \CommentTok{// the safest approach and assume we might not have received a }
               \CommentTok{// progress event for each part of the response}
               \FunctionTok{handleProgress}\NormalTok{();}
               
               \FunctionTok{emit}\NormalTok{( STREAM_END );}
            \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            
               \FunctionTok{emit}\NormalTok{( }
                  \NormalTok{FAIL_EVENT, }
                  \FunctionTok{errorReport}\NormalTok{(}
                     \OtherTok{xhr}\NormalTok{.}\FunctionTok{status}\NormalTok{, }
                     \OtherTok{xhr}\NormalTok{.}\FunctionTok{responseText}
                  \NormalTok{)}
               \NormalTok{);}
            \NormalTok{\}}
      \NormalTok{\}}
   \NormalTok{\};}

   \KeywordTok{try}\NormalTok{\{}
   
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{open}\NormalTok{(method, url, }\KeywordTok{true}\NormalTok{);}
   
      \KeywordTok{for}\NormalTok{( }\KeywordTok{var} \NormalTok{headerName }\KeywordTok{in} \NormalTok{headers )\{}
         \OtherTok{xhr}\NormalTok{.}\FunctionTok{setRequestHeader}\NormalTok{(headerName, headers[headerName]);}
      \NormalTok{\}}
      
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{send}\NormalTok{(}\FunctionTok{validatedRequestBody}\NormalTok{(data));}
      
   \NormalTok{\} }\KeywordTok{catch}\NormalTok{( e ) \{}
      \CommentTok{// To keep a consistent interface with Node, we can't emit an event here.}
      \CommentTok{// Node's streaming http adaptor receives the error as an asynchronous}
      \CommentTok{// event rather than as an exception. If we emitted now, the Oboe user}
      \CommentTok{// has had no chance to add a .fail listener so there is no way}
      \CommentTok{// the event could be useful. For both these reasons defer the}
      \CommentTok{// firing to the next JS frame.  }
      \OtherTok{window}\NormalTok{.}\FunctionTok{setTimeout}\NormalTok{(}
         \FunctionTok{partialComplete}\NormalTok{(emit, FAIL_EVENT, }
             \FunctionTok{errorReport}\NormalTok{(}\KeywordTok{undefined}\NormalTok{, }\KeywordTok{undefined}\NormalTok{, e)}
         \NormalTok{)}
      \NormalTok{,  }\DecValTok{0}
      \NormalTok{);}
   \NormalTok{\}            }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{streamingHttp.node.js}\label{headerux5fstreamingHttp.node}

\label{src_streamingHttp.node}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{httpTransport}\NormalTok{()\{}
   \KeywordTok{return} \FunctionTok{require}\NormalTok{(}\StringTok{'http'}\NormalTok{);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * A wrapper around the browser XmlHttpRequest object that raises an }
\CommentTok{ * event whenever a new part of the response is available.}
\CommentTok{ * }
\CommentTok{ * In older browsers progressive reading is impossible so all the }
\CommentTok{ * content is given in a single call. For newer ones several events}
\CommentTok{ * should be raised, allowing progressive interpretation of the response.}
\CommentTok{ *      }
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ emit a function to pass events to when something happens}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ on a function to use to subscribe to events}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{XMLHttpRequest\}}\CommentTok{ http the http implementation to use as the transport. Under normal}
\CommentTok{ *          operation, will have been created using httpTransport() above}
\CommentTok{ *          and therefore be Node's http}
\CommentTok{ *          but for tests a stub may be provided instead.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ method one of 'GET' 'POST' 'PUT' 'PATCH' 'DELETE'}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ contentSource the url to make a request to, or a stream to read from}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String|Object\}}\CommentTok{ data some content to be sent with the request.}
\CommentTok{ *                        Only valid if method is POST or PUT.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Object\}}\CommentTok{ [headers] the http request headers to send                       }
\CommentTok{ */}  
\KeywordTok{function} \FunctionTok{streamingHttp}\NormalTok{(emit, on, http, method, contentSource, data, headers) \{}

   \KeywordTok{function} \FunctionTok{readStreamToEventBus}\NormalTok{(readableStream) \{}
         
      \CommentTok{// use stream in flowing mode   }
      \OtherTok{readableStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'data'}\NormalTok{, }\KeywordTok{function} \NormalTok{(chunk) \{}
                                             
         \FunctionTok{emit}\NormalTok{( STREAM_DATA, }\OtherTok{chunk}\NormalTok{.}\FunctionTok{toString}\NormalTok{() );}
      \NormalTok{\});}
      
      \OtherTok{readableStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'end'}\NormalTok{, }\KeywordTok{function}\NormalTok{() \{}
               
         \FunctionTok{emit}\NormalTok{( STREAM_END );}
      \NormalTok{\});}
   \NormalTok{\}}
   
   \KeywordTok{function} \FunctionTok{readStreamToEnd}\NormalTok{(readableStream, callback)\{}
      \KeywordTok{var} \NormalTok{content = }\StringTok{''}\NormalTok{;}
   
      \OtherTok{readableStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'data'}\NormalTok{, }\KeywordTok{function} \NormalTok{(chunk) \{}
                                             
         \NormalTok{content += }\OtherTok{chunk}\NormalTok{.}\FunctionTok{toString}\NormalTok{();}
      \NormalTok{\});}
      
      \OtherTok{readableStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'end'}\NormalTok{, }\KeywordTok{function}\NormalTok{() \{}
               
         \FunctionTok{callback}\NormalTok{( content );}
      \NormalTok{\});}
   \NormalTok{\}}
   
   \KeywordTok{function} \FunctionTok{fetchHttpUrl}\NormalTok{( url ) \{}
      \KeywordTok{if}\NormalTok{( !}\OtherTok{contentSource}\NormalTok{.}\FunctionTok{match}\NormalTok{(}\OtherTok{/http:}\FloatTok{\textbackslash{}/\textbackslash{}/}\OtherTok{/}\NormalTok{) ) \{}
         \NormalTok{contentSource = }\StringTok{'http://'} \NormalTok{+ contentSource;}
      \NormalTok{\}                           }
                           
      \KeywordTok{var} \NormalTok{parsedUrl = }\FunctionTok{require}\NormalTok{(}\StringTok{'url'}\NormalTok{).}\FunctionTok{parse}\NormalTok{(contentSource); }
   
      \KeywordTok{var} \NormalTok{req = }\OtherTok{http}\NormalTok{.}\FunctionTok{request}\NormalTok{(\{}
         \DataTypeTok{hostname}\NormalTok{: }\OtherTok{parsedUrl}\NormalTok{.}\FunctionTok{hostname}\NormalTok{,}
         \DataTypeTok{port}\NormalTok{: }\OtherTok{parsedUrl}\NormalTok{.}\FunctionTok{port}\NormalTok{, }
         \DataTypeTok{path}\NormalTok{: }\OtherTok{parsedUrl}\NormalTok{.}\FunctionTok{pathname}\NormalTok{,}
         \DataTypeTok{method}\NormalTok{: method,}
         \DataTypeTok{headers}\NormalTok{: headers }
      \NormalTok{\});}
      
      \OtherTok{req}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'response'}\NormalTok{, }\KeywordTok{function}\NormalTok{(res)\{}
         \KeywordTok{var} \NormalTok{statusCode = }\OtherTok{res}\NormalTok{.}\FunctionTok{statusCode}\NormalTok{,}
             \NormalTok{sucessful = }\FunctionTok{String}\NormalTok{(statusCode)[}\DecValTok{0}\NormalTok{] == }\DecValTok{2}\NormalTok{;}
                                                   
         \FunctionTok{emit}\NormalTok{(HTTP_START, }\OtherTok{res}\NormalTok{.}\FunctionTok{statusCode}\NormalTok{, }\OtherTok{res}\NormalTok{.}\FunctionTok{headers}\NormalTok{);                                }
                                
         \KeywordTok{if}\NormalTok{( sucessful ) \{          }
               
            \FunctionTok{readStreamToEventBus}\NormalTok{(res)}
            
         \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \FunctionTok{readStreamToEnd}\NormalTok{(res, }\KeywordTok{function}\NormalTok{(errorBody)\{}
               \FunctionTok{emit}\NormalTok{( }
                  \NormalTok{FAIL_EVENT, }
                  \FunctionTok{errorReport}\NormalTok{( statusCode, errorBody )}
               \NormalTok{);}
            \NormalTok{\});}
         \NormalTok{\}      }
      \NormalTok{\});}
      
      \OtherTok{req}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'error'}\NormalTok{, }\KeywordTok{function}\NormalTok{(e) \{}
         \FunctionTok{emit}\NormalTok{( }
            \NormalTok{FAIL_EVENT, }
            \FunctionTok{errorReport}\NormalTok{(}\KeywordTok{undefined}\NormalTok{, }\KeywordTok{undefined}\NormalTok{, e )}
         \NormalTok{);}
      \NormalTok{\});}
      
      \FunctionTok{on}\NormalTok{( ABORTING, }\KeywordTok{function}\NormalTok{()\{              }
         \OtherTok{req}\NormalTok{.}\FunctionTok{abort}\NormalTok{();}
      \NormalTok{\});}
         
      \KeywordTok{if}\NormalTok{( data ) \{}
         \KeywordTok{var} \NormalTok{body = }\FunctionTok{isString}\NormalTok{(data)? data: }\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(data);}
         \OtherTok{req}\NormalTok{.}\FunctionTok{write}\NormalTok{(body);}
      \NormalTok{\}}
      
      \OtherTok{req}\NormalTok{.}\FunctionTok{end}\NormalTok{();         }
   \NormalTok{\}}
   
   \KeywordTok{if}\NormalTok{( }\FunctionTok{isString}\NormalTok{(contentSource) ) \{}
      \FunctionTok{fetchHttpUrl}\NormalTok{(contentSource);}
   \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
      \CommentTok{// contentsource is a stream}
      \FunctionTok{readStreamToEventBus}\NormalTok{(contentSource);   }
   \NormalTok{\}}

\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{util.js}\label{headerux5futil}

\label{src_util}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file defines some loosely associated syntactic sugar for }
\CommentTok{ * Javascript programming }
\CommentTok{ */}


\CommentTok{/**}
\CommentTok{ * Returns true if the given candidate is of type T}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{isOfType}\NormalTok{(T, maybeSomething)\{}
   \KeywordTok{return} \NormalTok{maybeSomething && }\OtherTok{maybeSomething}\NormalTok{.}\FunctionTok{constructor} \NormalTok{=== T;}
\NormalTok{\}}
\KeywordTok{function} \FunctionTok{pluck}\NormalTok{(key, object)\{}
   \KeywordTok{return} \NormalTok{object[key];}
\NormalTok{\}}

\KeywordTok{var} \NormalTok{attr = }\FunctionTok{partialComplete}\NormalTok{(partialComplete, pluck),}
    \NormalTok{len = }\FunctionTok{attr}\NormalTok{(}\StringTok{'length'}\NormalTok{),    }
    \NormalTok{isString = }\FunctionTok{partialComplete}\NormalTok{(isOfType, String);}

\CommentTok{/** }
\CommentTok{ * I don't like saying this:}
\CommentTok{ * }
\CommentTok{ *    foo !=== undefined}
\CommentTok{ *    }
\CommentTok{ * because of the double-negative. I find this:}
\CommentTok{ * }
\CommentTok{ *    defined(foo)}
\CommentTok{ *    }
\CommentTok{ * easier to read.}
\CommentTok{ */} 
\KeywordTok{function} \FunctionTok{defined}\NormalTok{( value ) \{}
   \KeywordTok{return} \NormalTok{value !== }\KeywordTok{undefined}\NormalTok{;}
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{always}\NormalTok{()\{}\KeywordTok{return} \KeywordTok{true}\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Returns true if object o has a key named like every property in }
\CommentTok{ * the properties array. Will give false if any are missing, or if o }
\CommentTok{ * is not an object.}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{hasAllProperties}\NormalTok{(fieldList, o) \{}

   \KeywordTok{return}      \NormalTok{(o }\KeywordTok{instanceof} \NormalTok{Object) }
            \NormalTok{&&}
               \FunctionTok{all}\NormalTok{(}\KeywordTok{function} \NormalTok{(field) \{         }
                  \KeywordTok{return} \NormalTok{(field }\KeywordTok{in} \NormalTok{o);         }
               \NormalTok{\}, fieldList);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{wire.js}\label{headerux5fwire}

\label{src_wire}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file sits just behind the API which is used to attain a new}
\CommentTok{ * Oboe instance. It creates the new components that are required}
\CommentTok{ * and introduces them to each other.}
\CommentTok{ */}

\KeywordTok{function} \FunctionTok{wire} \NormalTok{(httpMethodName, contentSource, body, headers)\{}

   \KeywordTok{var} \NormalTok{eventBus = }\FunctionTok{pubSub}\NormalTok{();}
               
   \FunctionTok{streamingHttp}\NormalTok{( }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{emit}\NormalTok{, }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{on}\NormalTok{,}
                  \FunctionTok{httpTransport}\NormalTok{(), }
                  \NormalTok{httpMethodName, contentSource, body, headers );                              }
     
   \FunctionTok{instanceController}\NormalTok{( }
               \OtherTok{eventBus}\NormalTok{.}\FunctionTok{emit}\NormalTok{, }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{on}\NormalTok{, }
               \OtherTok{clarinet}\NormalTok{.}\FunctionTok{parser}\NormalTok{(), }
               \FunctionTok{incrementalContentBuilder}\NormalTok{(}\OtherTok{eventBus}\NormalTok{.}\FunctionTok{emit}\NormalTok{) }
   \NormalTok{);}
      
   \KeywordTok{return} \KeywordTok{new} \FunctionTok{instanceApi}\NormalTok{(}\OtherTok{eventBus}\NormalTok{.}\FunctionTok{emit}\NormalTok{, }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{on}\NormalTok{, }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{un}\NormalTok{, jsonPathCompiler);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Appendix iii: Benchmarking}\label{appendix-iii-benchmarking}

\hyperdef{}{headerux5fbenchmarkClient}{\subsection{benchmarkClient.js}\label{headerux5fbenchmarkClient}}

\label{src_benchmarkClient}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{/* call this script from the command line with first argument either}
\CommentTok{    oboe, jsonParse, or clarinet.}
\CommentTok{    }
\CommentTok{   This script won't time the events, I'm using `time` on the command line}
\CommentTok{   to keep things simple.}
\CommentTok{ */}

\FunctionTok{require}\NormalTok{(}\StringTok{'color'}\NormalTok{);}

\KeywordTok{var} \NormalTok{DB_URL = }\StringTok{'http://localhost:4444/db'}\NormalTok{;  }


\KeywordTok{function} \FunctionTok{aggregateWithOboe}\NormalTok{() \{}

   \KeywordTok{var} \NormalTok{oboe = }\FunctionTok{require}\NormalTok{(}\StringTok{'../dist/oboe-node.js'}\NormalTok{);}
   
   \FunctionTok{oboe}\NormalTok{(DB_URL).}\FunctionTok{node}\NormalTok{(}\StringTok{'\{id url\}.url'}\NormalTok{, }\KeywordTok{function}\NormalTok{(url)\{}
           
      \FunctionTok{oboe}\NormalTok{(url).}\FunctionTok{node}\NormalTok{(}\StringTok{'name'}\NormalTok{, }\KeywordTok{function}\NormalTok{(name)\{}
                      
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(name);}
         \KeywordTok{this}\NormalTok{.}\FunctionTok{abort}\NormalTok{();}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{process}\NormalTok{.}\FunctionTok{memoryUsage}\NormalTok{().}\FunctionTok{heapUsed} \NormalTok{);         }
      \NormalTok{\});      }
   \NormalTok{\});                 }
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{aggregateWithJsonParse}\NormalTok{() \{}

   \KeywordTok{var} \NormalTok{getJson = }\FunctionTok{require}\NormalTok{(}\StringTok{'get-json'}\NormalTok{);}

   \FunctionTok{getJson}\NormalTok{(DB_URL, }\KeywordTok{function}\NormalTok{(err, records) \{}
       
      \OtherTok{records}\NormalTok{.}\OtherTok{data}\NormalTok{.}\FunctionTok{forEach}\NormalTok{( }\KeywordTok{function}\NormalTok{( record )\{}
       
         \KeywordTok{var} \NormalTok{url = }\OtherTok{record}\NormalTok{.}\FunctionTok{url}\NormalTok{;}
         
         \FunctionTok{getJson}\NormalTok{(url, }\KeywordTok{function}\NormalTok{(err, record) \{}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\OtherTok{record}\NormalTok{.}\FunctionTok{name}\NormalTok{);}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{process}\NormalTok{.}\FunctionTok{memoryUsage}\NormalTok{().}\FunctionTok{heapUsed} \NormalTok{);}
         \NormalTok{\});}
      \NormalTok{\});}

   \NormalTok{\});   }

\NormalTok{\}}


\KeywordTok{function} \FunctionTok{aggregateWithClarinet}\NormalTok{() \{}

   \KeywordTok{var} \NormalTok{clarinet = }\FunctionTok{require}\NormalTok{(}\StringTok{'clarinet'}\NormalTok{);   }
   \KeywordTok{var} \NormalTok{http = }\FunctionTok{require}\NormalTok{(}\StringTok{'http'}\NormalTok{);}
   \KeywordTok{var} \NormalTok{outerClarinetStream = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{createStream}\NormalTok{();}
   \KeywordTok{var} \NormalTok{outerKey;}
   
   \KeywordTok{var} \NormalTok{outerRequest = }\OtherTok{http}\NormalTok{.}\FunctionTok{request}\NormalTok{(DB_URL, }\KeywordTok{function}\NormalTok{(res) \{}
                              
      \OtherTok{res}\NormalTok{.}\FunctionTok{pipe}\NormalTok{(outerClarinetStream);}
   \NormalTok{\});}
   
   \NormalTok{outerClarinetStream = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{createStream}\NormalTok{();}
      
   \OtherTok{outerRequest}\NormalTok{.}\FunctionTok{end}\NormalTok{();}
      
   \OtherTok{outerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'openobject'}\NormalTok{, }\KeywordTok{function}\NormalTok{( keyName )\{      }
      \KeywordTok{if}\NormalTok{( keyName ) \{}
         \NormalTok{outerKey = keyName;      }
      \NormalTok{\}}
   \NormalTok{\});}
   
   \OtherTok{outerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'key'}\NormalTok{, }\KeywordTok{function}\NormalTok{(keyName)\{}
      \NormalTok{outerKey = keyName;}
   \NormalTok{\});}
   
   \OtherTok{outerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'value'}\NormalTok{, }\KeywordTok{function}\NormalTok{(value)\{}
      \KeywordTok{if}\NormalTok{( outerKey == }\StringTok{'url'} \NormalTok{) \{}
         \FunctionTok{innerRequest}\NormalTok{(value)}
      \NormalTok{\}}
   \NormalTok{\});      }
   
   
   \KeywordTok{function} \FunctionTok{innerRequest}\NormalTok{(url) \{}
      
      \KeywordTok{var} \NormalTok{innerRequest = }\OtherTok{http}\NormalTok{.}\FunctionTok{request}\NormalTok{(url, }\KeywordTok{function}\NormalTok{(res) \{}
                                 
         \OtherTok{res}\NormalTok{.}\FunctionTok{pipe}\NormalTok{(innerClarinetStream);}
      \NormalTok{\});}
      
      \KeywordTok{var} \NormalTok{innerClarinetStream = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{createStream}\NormalTok{();}
      
      \OtherTok{innerRequest}\NormalTok{.}\FunctionTok{end}\NormalTok{();            }
      
      \KeywordTok{var} \NormalTok{innerKey;}
      
      \OtherTok{innerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'openobject'}\NormalTok{, }\KeywordTok{function}\NormalTok{( keyName )\{      }
         \KeywordTok{if}\NormalTok{( keyName ) \{}
            \NormalTok{innerKey = keyName;      }
         \NormalTok{\}}
      \NormalTok{\});}
      
      \OtherTok{innerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'key'}\NormalTok{, }\KeywordTok{function}\NormalTok{(keyName)\{}
         \NormalTok{innerKey = keyName;}
      \NormalTok{\});}
      
      \OtherTok{innerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'value'}\NormalTok{, }\KeywordTok{function}\NormalTok{(value)\{}
         \KeywordTok{if}\NormalTok{( innerKey == }\StringTok{'name'} \NormalTok{) \{}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( value )}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{process}\NormalTok{.}\FunctionTok{memoryUsage}\NormalTok{().}\FunctionTok{heapUsed} \NormalTok{);            }
         \NormalTok{\}}
      \NormalTok{\});            }
   \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{var} \NormalTok{strategies = \{}
   \DataTypeTok{oboe}\NormalTok{:       aggregateWithOboe,}
   \DataTypeTok{jsonParse}\NormalTok{:  aggregateWithJsonParse,}
   \DataTypeTok{clarinet}\NormalTok{:   aggregateWithClarinet}
\NormalTok{\}}

\KeywordTok{var} \NormalTok{strategyName = }\OtherTok{process}\NormalTok{.}\FunctionTok{argv}\NormalTok{[}\DecValTok{2}\NormalTok{];}

\CommentTok{// use any of the above three strategies depending on a command line argument:}
\OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'benchmarking strategy'}\NormalTok{, strategyName);}

\NormalTok{strategies[strategyName]();}

\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{benchmarkServer.js}\label{headerux5fbenchmarkServer}

\label{src_benchmarkServer}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**   }
\CommentTok{ */}

\StringTok{"use strict"}\NormalTok{;}

\KeywordTok{var} \NormalTok{PORT = }\DecValTok{4444}\NormalTok{;}

\KeywordTok{var} \NormalTok{TIME_BETWEEN_RECORDS = }\DecValTok{15}\NormalTok{;}
\CommentTok{// 80 records but only every other one has a URL:}
\KeywordTok{var} \NormalTok{NUMBER_OF_RECORDS = }\DecValTok{80}\NormalTok{;}

\KeywordTok{function} \FunctionTok{sendJsonHeaders}\NormalTok{(res) \{}
   \KeywordTok{var} \NormalTok{JSON_MIME_TYPE = }\StringTok{"application/octet-stream"}\NormalTok{;}
   \OtherTok{res}\NormalTok{.}\FunctionTok{setHeader}\NormalTok{(}\StringTok{"Content-Type"}\NormalTok{, JSON_MIME_TYPE);}
   \OtherTok{res}\NormalTok{.}\FunctionTok{writeHead}\NormalTok{(}\DecValTok{200}\NormalTok{);}
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{serveItemList}\NormalTok{(_req, res) \{}

   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'slow fake db server: send simulated database data'}\NormalTok{);}

   \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\StringTok{'\{"data": ['}\NormalTok{);}

   \KeywordTok{var} \NormalTok{i = }\DecValTok{0}\NormalTok{;}

   \KeywordTok{var} \NormalTok{inervalId = }\FunctionTok{setInterval}\NormalTok{(}\KeywordTok{function} \NormalTok{() \{}

      \KeywordTok{if}\NormalTok{( i % }\DecValTok{2} \NormalTok{== }\DecValTok{0} \NormalTok{) \{}

         \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(\{}
            \StringTok{"id"}\NormalTok{: i,}
            \StringTok{"url"}\NormalTok{: }\StringTok{"http://localhost:4444/item/"} \NormalTok{+ i         }
         \NormalTok{\}));}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(\{}
            \StringTok{"id"}\NormalTok{: i         }
         \NormalTok{\}));      }
      \NormalTok{\}}
      
      \KeywordTok{if} \NormalTok{(i == NUMBER_OF_RECORDS) \{}

         \OtherTok{res}\NormalTok{.}\FunctionTok{end}\NormalTok{(}\StringTok{']\}'}\NormalTok{);}
         
         \FunctionTok{clearInterval}\NormalTok{(inervalId);}
         
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'db server: finished writing to stream'}\NormalTok{);}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\StringTok{','}\NormalTok{);}
      \NormalTok{\}}
      
      \NormalTok{i++;  }

   \NormalTok{\}, TIME_BETWEEN_RECORDS);}
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{serveItem}\NormalTok{(req, res)\{}

   \KeywordTok{var} \NormalTok{id = }\OtherTok{req}\NormalTok{.}\OtherTok{params}\NormalTok{.}\FunctionTok{id}\NormalTok{;}
   
   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'will output fake record with id'}\NormalTok{, id);     }

   \FunctionTok{setTimeout}\NormalTok{(}\KeywordTok{function}\NormalTok{()\{}
      \CommentTok{// the items served are all the same except for the id field.}
      \CommentTok{// this is realistic looking but randomly generated object fro}
      \CommentTok{// <project>/test/json/oneHundredrecords.json   }
      \OtherTok{res}\NormalTok{.}\FunctionTok{end}\NormalTok{(}\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(\{}
         \StringTok{"id"} \NormalTok{: id,}
         \StringTok{"url"}\NormalTok{: }\StringTok{"http://localhost:4444/item/"} \NormalTok{+ id,      }
         \StringTok{"guid"}\NormalTok{: }\StringTok{"046447ee-da78-478c-b518-b612111942a5"}\NormalTok{,}
         \StringTok{"picture"}\NormalTok{: }\StringTok{"http://placehold.it/32x32"}\NormalTok{,}
         \StringTok{"age"}\NormalTok{: }\DecValTok{37}\NormalTok{,}
         \StringTok{"name"}\NormalTok{: }\StringTok{"Humanoid robot number "} \NormalTok{+ id,}
         \StringTok{"company"}\NormalTok{: }\StringTok{"Robotomic"}\NormalTok{,}
         \StringTok{"phone"}\NormalTok{: }\StringTok{"806-587-2379"}\NormalTok{,}
         \StringTok{"email"}\NormalTok{: }\StringTok{"payton@robotomic.com"}
      \NormalTok{\}));}
            
   \NormalTok{\}, TIME_BETWEEN_RECORDS);}

\NormalTok{\}}

\KeywordTok{function} \FunctionTok{routing}\NormalTok{() \{}
   \KeywordTok{var} \NormalTok{Router = }\FunctionTok{require}\NormalTok{(}\StringTok{'node-simple-router'}\NormalTok{),}
       \NormalTok{router = }\FunctionTok{Router}\NormalTok{();}

   \OtherTok{router}\NormalTok{.}\FunctionTok{get}\NormalTok{( }\StringTok{'/db'}\NormalTok{,         serveItemList);}
   \OtherTok{router}\NormalTok{.}\FunctionTok{get}\NormalTok{( }\StringTok{'/item/:id'}\NormalTok{,   serveItem);}
   
   \KeywordTok{return} \NormalTok{router;}
\NormalTok{\}}
      
\KeywordTok{var} \NormalTok{server = }\FunctionTok{require}\NormalTok{(}\StringTok{'http'}\NormalTok{).}\FunctionTok{createServer}\NormalTok{(}\FunctionTok{routing}\NormalTok{()).}\FunctionTok{listen}\NormalTok{(PORT);}

\OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'Benchmark server started on port'}\NormalTok{, }\FunctionTok{String}\NormalTok{(PORT));}
\end{Highlighting}
\end{Shaded}

\section{Bibliography}\label{bibliography}

Ahuvia, Yogev. 2013. ``Design Patterns: Infinite Scrolling: Let's Get To
The Bottom Of This
Http://uxdesign.smashingmagazine.com/2013/05/03/infinite-scrolling-get-bottom/.''
Smashing Magazine.

Alman, Ben. 2012. ``Grunt: The Javascript Task Runner.''
\url{http://gruntjs.com/}.

Ashkenas, Jeremy. 2008. ``Underscore.js: Memoize.''
\url{http://underscorejs.org/\#memoize}.

Bazon, Mihai. 2010. ``UglifyJs.''
\url{https://github.com/mishoo/UglifyJS}.

Bray, Tim, Jean Paoli, C M Sperberg-McQueen, Eve Maler, and FranÃ§ois
Yergeau. 2008. ``Extensible Markup Language (XML) 1.0 (Fifth Edition).''
\url{http://www.w3.org/TR/REC-xml/\#sec-starttags}.

Browserling Inc. 2012. ``Browserify Website.''
\url{http://browserify.org/}.

Burke, James. 2011. ``Require.js.'' \url{http://requirejs.org/}.

Conway, Mel. 2004. \emph{Humanizing Application Building: An
Anthropological Perspective}.
\url{http://melconway.com/Home/pdf/humanize.pdf}.

Cragg, Duncan. 2006. ``Duncan Cragg on Declarative Architectures: STREST
(Service-Trampled REST) Will Break Web 2.0.''
\url{http://duncan-cragg.org/blog/post/strest-service-trampled-rest-will-break-web-20/}.

Douglas, Crockford. 2009. ``JSON: The Fat-free Alternative to XML.''
\url{http://json.org}.

Eberhart, Andreas, and Stefan Fischer. 2002. \emph{Java Tools: Using
XML, EJB, CORBA, Servlets and SOAP}.

ECMA. 1999. ``ECMAScript Language Specification 3rd Edition.''
\url{http://www.ecma-international.org/publications/files/ECMA-ST-ARCH/ECMA-262,\%203rd\%20edition,\%20December\%201999.pdf}.

Etemad, Elika J, and Tab Atkins. 2013. ``Selectors Level 4.''
\url{http://dev.w3.org/csswg/selectors4/}.

Fielding, R. 2000. ``Principled Design of the Modern Web Architecture.''

Fielding, R, J Gettys, J Mogul, H Frystyk, et al. 1999. ``Hypertext
Transfer Protocol -{}- HTTP/1.1: Header Field Definitions.''
\url{http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html\#sec14.5}.

Geelhoed, Erik, Peter Toft, Suzanne Roberts, and Patrick Hyland. 1995.
``To Influence Time Perception.'' Hewlett Packard Labs.
\url{http://www.sigchi.org/chi95/proceedings/shortppr/egd_bdy.htm}.

Gill, Brendan. 2013. ``OpenSignal.''

Goessner, Stefan. 2007. ``JSONPath - XPath for JSON.''
\url{http://goessner.net/articles/JsonPath/}.

Google. 2009. ``Google Closure Compiler.''
\url{https://developers.google.com/closure/compiler/}.

Gudgin, Martin, Marc Hadley, Noah Mendelsohn, Jean-Jacques Moreau,
Henrik Frystyk Nielsen, Anish Karmarkar, and Yves Lafon. 2007. ``SOAP
Version 1.2 Part 1: Messaging Framework (Second Edition).''
\url{http://www.w3.org/TR/soap12-part1/}.

Guo, shu-yu. 2013. ``Two Reasons Functional Style Is Slow in
SpiderMonkey.''
\url{http://rfrn.org//~shu/2013/03/20/two-reasons-functional-style-is-slow-in-spidermonkey.html}.

Harmony. 2013. ``Draft Specification for ES.next (Ecma-262 Edition 6).''
\url{http://wiki.ecmascript.org/doku.php?id=harmony:specification_drafts}.

Job, Nuno. 2011. ``Clarinet - SAX Based Evented Streaming JSON Parser in
JavaScript.'' \url{https://github.com/dscape/clarinet}.

---------. 2012. ``Clarinet - SAX Based Evented Streaming JSON Parser in
JavaScript for the Browser and Nodejs.''
\url{http://writings.nunojob.com/2011/12/clarinet-sax-based-evented-streaming-json-parser-in-javascript-for-the-browser-and-nodejs.html}.

Lea, Tom. 2012. ``Improving Performance on Twitter.com.''
\url{{[}https://blog.twitter.com/2012/improving-performance-twittercom{]}}.

Lieberherr, Karl J, Ignacio Silva-Lepe, and Xiao Cun. 1994. ``Adaptive
Ob Ject-Oriented Programming Using Graph-Based Customization.''
\url{http://www.csg.ci.i.u-tokyo.ac.jp/old-pages/muga/paper/others/gpce_gcse/ap_graf.pdf}.

Martelli, Alex. 2000. ``Discussion of Typing in Python Language, 2000.''
\url{https://groups.google.com/forum/?hl=en/\#!msg/comp.lang.python/CCs2oJdyuzc/NYjla5HKMOIJ}.

Martin, Robert ``Uncle Bob''. 2008. \emph{Clean Code: A Handbook of
Agile Software Craftsmanship}.

McIlroy, Doug. 1978. ``Basics of the Unix Philosophy.''
\url{http://www.faqs.org/docs/artu/ch01s06.html}.

McLuhan, Marshall. 1964. \emph{Understanding Media: The Extensions of
Man}.

Microsoft. 2013. ``LINQ (Language-Integrated Query).''
\url{http://msdn.microsoft.com/en-us/library/vstudio/bb397926.aspx}.

Netty. 2010. ``Netty Project.'' \url{http://netty.io/}.

NPM. 2013. ``Get JSON.'' \url{https://npmjs.org/package/get-json}.

Ogden, Max. 2012. ``Streaming XHR.''
\url{http://maxogden.com/a-proposal-for-streaming-xhr.html}.

Reis, Eric. 2011. \emph{The Lean Startup: How Today's Entrepreneurs Use
Continuous Innovation to Create Radically Successful Businesses.} Crown
Business Publishing.

Ryan, Dahl. 2009. ``Node.js.'' \url{http://nodejs.org/}.

Schneier, Bruce. 2000. ``Crypto-Gram Newsletter.''
\url{https://www.schneier.com/crypto-gram-0003.html\#8}.

Schneier, Bruce, and Sam Harris. 2013. ``To Profile or Not to Profile? -
a Debate Between Sam Harris and Bruce Schneier.''
\url{http://www.samharris.org/blog/item/to-profile-or-not-to-profile}.

Stefanov, Stoyan. 2009. ``Progressive Rendering via Multiple Flushes.''
\url{http://www.phpied.com/progressive-rendering-via-multiple-flushes/}.

van Kesteren, Anne. 2012. ``XMLHttpRequest Level 2 Working Draft.''
\url{http://www.w3.org/TR/XMLHttpRequest2/\#make-progress-notifications}.

van Kesteren, Anne, and Dean Jackson. 2006. ``The XMLHttpRequest
Object.'' \url{http://www.w3.org/TR/2006/WD-XMLHttpRequest-20060405/}.

Whorf, B. L. 1956. ``Language, Thought and Reality (Ed. J. B.
Carroll).'' Cambridge, MA: MIT Press.

Yukihiro, Matsumoto. 2003. ``The Power and Philosophy of Ruby.''
\url{http://www.rubyist.net/~matz/slides/oscon2003/index.html}.

\end{document}
